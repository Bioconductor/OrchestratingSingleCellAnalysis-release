[
["index.html", "Orchestrating Single-Cell Analysis with Bioconductor Welcome", " Orchestrating Single-Cell Analysis with Bioconductor 2019-09-26 Welcome This is the website for “Orchestrating Single-Cell Analysis with Bioconductor”, a book that teaches users some common workflows for the analysis of single-cell RNA-seq data (scRNA-seq). This book will teach you how to make use of cutting-edge Bioconductor tools to process, analyze, visualize, and explore scRNA-seq data. Additionally, it serves as an online companion for the manuscript “Orchestrating Single-Cell Analysis with Bioconductor”. While we focus here on scRNA-seq data, a newer technology that profiles transcriptomes at the single-cell level, many of the tools, conventions, and analysis strategies utilized throughout this book are broadly applicable to other types of assays. By learning the grammar of Bioconductor workflows, we hope to provide you a starting point for the exploration of your own data, whether it be scRNA-seq or otherwise. This book is organized into three parts. In the Preamble, we introduce the book and dive into resources for learning R and Bioconductor (both at a beginner and developer level). Part I ends with a tutorial for a key data infrastructure, the SingleCellExperiment class, that is used throughout Bioconductor for single-cell analysis and in the subsequent section. The second part, Focus Topics, begins with an overview of the framework for analysis of scRNA-seq data, with deeper dives into specific topics are presented in each subsequent chapter. THe third part, Workflows, provides primarily code detailing the analysis of various datasets throughout the book. Finally, the Appendix highlights our contributors. If you would like to cite this work, please use the reference “Orchestrating Single-Cell Analysis with Bioconductor”. The book is written in RMarkdown with bookdown. OSCA is a collaborative effort, supported by various folks from the Bioconductor team who have contributed workflows, fixes, and improvements. This website is free to use, and is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 3.0 License. Version 0.0.1.9999 Built on 2019-09-26 "],
["introduction.html", "Chapter 1 Introduction 1.1 What you will learn 1.2 What you won’t learn 1.3 Who we wrote this for 1.4 Why we wrote this 1.5 Acknowledgements", " Chapter 1 Introduction Bioconductor is an open source, open development software project to provide tools for the analysis and comprehension of high-throughput genomic data. It is based primarily on the R programming language. 1.1 What you will learn The goal of this book is to provide a solid foundation in the usage of Bioconductor tools for single-cell RNA-seq analysis by walking through various steps of typical workflows using example datasets. We strive to tackle key concepts covered in the manuscript, “Orchestrating Single-Cell Analysis with Bioconductor”, with each workflow covering these in varying detail, as well as essential preliminaries that are important for following along with the workflows on your own. 1.1.1 Preliminaries For those unfamiliar with R (and those looking to learn more), we recommend reading the Learning R and More chapter, which first and foremost covers how to get started with R. We point to many great online resources for learning R, as well as related tools that are nice to know for bioinformatic analysis. For advanced users, we also point to some extra resources that go beyond the basics. While we provide an extensive list of learning resources for the interested audience in this chapter, we only ask for some familiarity with R before going to the next section. We then briefly cover getting started with Using R and Bioconductor. Bioconductor, being its own repository, has a unique set of tools, documentation, resources, and practices that benefit from some extra explanation. Data Infrastructure merits a separate chapter. The reason for this is that common data containers are an essential part of Bioconductor workflows because they enable interoperability across packages, allowing for “plug and play” usage of cutting-edge tools. Specifically, here we cover the SingleCellExperiment class in depth, as it has become the working standard for Bioconductor based single-cell analysis packages. Finally, before diving into the various workflows, armed with knowledge about the SingleCellExperiment class, we briefly discuss the datasets that will be used throughout the book in About the Data. 1.1.2 Workflows All workflows begin with data import and subsequent quality control and normalization, going from a raw (count) expression matrix to a clean one. This includes adjusting for experimental factors and possibly even latent factors. Using the clean expression matrix, feature selection strategies can be applied to select the features (genes) driving heterogeneity. Furthermore, these features can then be used to perform dimensionality reduction, which enables downstream analysis that would not otherwise be possible and visualization in 2 or 3 dimensions. From there, the workflows largely focus on differing downstream analyses. Clustering details how to segment a scRNA-seq dataset, and differential expression provides a means to determine what drives the differences between different groups of cells. Integrating datasets walks through merging scRNA-seq datasets, an area of need as the number of scRNA-seq datasets continues to grow and comparisons between datasets must be done. Finally, we touch upon how to work with large scale data, specifically where it becomes impractical or impossible to work with data solely in-memory. As an added bonus, we dedicate a chapter to interactive visualization, which focuses on using the iSEE package to enable active exploration of a single cell experiment’s data. 1.2 What you won’t learn The field of bioinformatic analysis is large and filled with many potential trajectories depending on the biological system being studied and technology being deployed. Here, we only briefly survey some of the many tools available for the analysis of scRNA-seq, focusing on Bioconductor packages. It is impossible to thoroughly review the plethora of tools available through R and Bioconductor for biological analysis in one book, but we hope to provide the means for further exploration on your own. Thus, it goes without saying that you may not learn the optimal workflow for your own data from our examples - while we strive to provide high quality templates, they should be treated as just that - a template from which to extend upon for your own analyses. 1.3 Who we wrote this for We’ve written this book with the interested experimental biologist in mind, and do our best to make few assumptions on previous programming or statistical experience. Likewise, we also welcome more seasoned bioinformaticians who are looking for a starting point from which to dive into single-cell RNA-seq analysis. As such, we welcome any and all feedback for improving this book to help increase accessibility and refine technical details. 1.4 Why we wrote this This book was conceived in the fall of 2018, as single-cell RNA-seq analysis continued its rise in prominence in the field of biology. With its rapid growth, and the ongoing developments within Bioconductor tailored specifically for scRNA-seq, it became apparent that an update to the Orchestrating high-throughput genomic analysis with Bioconductor paper was necessary for the age of single-cell studies. We strive to highlight the fantastic software by people who call Bioconductor home for their tools, and in the process hope to showcase the Bioconductor community at large in continually pushing forward the field of biological analysis. 1.5 Acknowledgements We would like to thank all Bioconductor contributors for their efforts in creating the definitive leading-edge repository of software for biological analysis. It is truly extraordinary to chart the growth of Bioconductor over the years. We are thankful for the wonderful community of scientists and developers alike that together make the Bioconductor community special. We would first and foremost like to thank the Bioconductor core team and the emerging targets subcommittee for commissioning this work, Stephanie Hicks and Raphael Gottardo for their continuous mentorship, and all our contributors to the companion manuscript of this book. We’d also like to thank Garret Grolemund and Hadley Wickham for their book, R for Data Science, from which we drew stylistic and teaching inspiration. We also thank Levi Waldron and Aaron Lun for advice on the code-related aspects of managing the online version of this book. "],
["learning-r-and-more.html", "Chapter 2 Learning R and Bioconductor 2.1 The Benefits of R and Bioconductor 2.2 Learning R Online 2.3 Running R Locally 2.4 Getting Help In (and Out) of R 2.5 Bioconductor Help", " Chapter 2 Learning R and Bioconductor In this chapter, we outline various resources for learning R and Bioconductor. We provide a brief set of instructions for installing R on your own machine, and then cover how to get help for functions, packages, and Bioconductor-specific resources for learning more. 2.1 The Benefits of R and Bioconductor R is a high-level programming language that was initially designed for statistical applications. While there is much to be said about R as a programming language, one of the key advantages of using R is that it is highly extensible through packages. Packages are collections of functions, data, and documentation that extend the capabilities of base R. The ease of development and distribution of packages for R has made it a rich environment for many fields of study and application. One of the primary ways in which packages are distributed is through centralized repositories. The first R repository a user typically runs into is the Comprehensive R Archive Network (CRAN), which hosts over 13,000 packages to date, and is home to many of the most popular R packages. Similar to CRAN, Bioconductor is a repository of R packages as well. However, whereas CRAN is a general purpose repository, Bioconductor focuses on software tailored for genomic analysis. Furthermore, Bioconductor has stricter requirements for a package to be accepted into the repository. Of particular interest to us is the inclusion of high quality documentation and the use of common data infrastructure to promote package interoperability. In order to use these packages from CRAN and Bioconductor, and start programming with R to follow along in these workflows, some knowledge of R is helpful. Here we outline resources to guide you through learning the basics. 2.2 Learning R Online To learn more about programming with R, we highly recommend checking out the online courses offered by Datacamp, which includes both introductory and advanced courses within the R track. Datacamp is all online with many free courses, with videos and a code editor/console that promotes an interactive learning experience. What we like about Datacamp is that it is more focused on topics and programming paradigms that center around data science, which is especially helpful for getting started with R. Beyond just Datacamp, a mainstay resource for learning R is the R for Data Science book. This book illustrates R programming through the exploration of various data science concepts - transformation, visualization, exploration, and more. 2.3 Running R Locally While learning R through online resources is a great way to start with R, as it requires minimal knowledge to start up, at some point, it will be desirable to have a local installation - on your own hardware - of R. This will allow you to install and maintain your own software and code, and furthermore allow you to create a personalized workspace. 2.3.1 Installing R Prior to getting started with this book, some prior programming experience with R is helpful. Check out the Learning R and More chapter for a list of resources to get started with R and other useful tools for bioinformatic analysis. To follow along with the analysis workflows in this book on your personal computer, it is first necessary to install the R programming language. Additionally, we recommend a graphical user interface such as RStudio for programming in R and visualization. RStudio features many helpful tools, such as code completion and an interactive data viewer to name but two. For more details, please see the online book R for Data Science prerequisites section for more information about installing R and using RStudio. 2.3.1.1 For MacOS/Linux Users A special note for MacOS/Linux users: we highly recommend using a package manager to manage your R installation. This differs across different Linux distributions, but for MacOS we highly recommend the Homebrew package manager. Follow the website directions to install homebrew, and install R via the commandline with brew install R, and it will automatically configure your installation for you. Upgrading to new R versions can be done by running brew upgrade. 2.3.2 Installing R &amp; Bioconductor Packages After installing R, the next step is to install R packages. In the R console, you can install packages from CRAN via the install.packages() function. In order to install Bioconductor packages, we will first need the BiocManager package which is hosted on CRAN. This can be done by running: install.packages(&quot;BiocManager&quot;) The BiocManager package makes it easy to install packages from the Bioconductor repository. For example, to install the SingleCellExperiment package, we run: ## the command below is a one-line shortcut for: ## library(BiocManager) ## install(&quot;SingleCellExperiment&quot;) BiocManager::install(&quot;SingleCellExperiment&quot;) Throughout the book, we can load packages via the library() function, which by convention usually comes at the top of scripts to alert readers as to what packages are required. For example, to load the SingleCellExperiment package, we run: library(SingleCellExperiment) Many packages will be referenced throughout the book within the workflows, and similar to the above, can be installed using the BiocManager::install() function. 2.4 Getting Help In (and Out) of R One of the most helpful parts of R is being able to get help inside of R. For example, to get the manual associated with a function, class, dataset, or package, you can prepend the code of interest with a ? to retrieve the relevant help page. For example, to get information about the data.frame() function, the SingleCellExperiment class, the in-built iris dataset, or for the BiocManager package, you can type: ?data.frame ?SingleCellExperiment ?iris ?BiocManager Beyond the R console, there are myriad online resources to get help. The R for Data Science book has a great section dedicated to looking for help outside of R. In particular, Stackoverflow’s R tag is a helpful resource for asking and exploring general R programming questions. 2.5 Bioconductor Help One of the key tenets of Bioconductor software that makes it stand out from CRAN is the required documentation of packages and workflows. In addition, Bioconductor hosts a Bioconductor-specific support site that has grown into a valuable resource of its own, thanks to the work of dedicated volunteers. 2.5.1 Bioconductor Packages Each package hosted on Bioconductor has a dedicated page with various resources. For an example, looking at the scater package page on Bioconductor, we see that it contains: a brief description of the package at the top, in addition to the authors, maintainer, and an associated citation installation instructions that can be cut and paste into your R console documentation - vignettes, reference manual, news Here, the most important information comes from the documentation section. Every package in Bioconductor is required to be submitted with a vignette - a document showcasing basic functionality of the package. Typically, these vignettes have a descriptive title that summarizes the main objective of the vignette. These vignettes are a great resource for learning how to operate the essential functionality of the package. The reference manual contains a comprehensive listing of all the functions available in the package. This is a compilation of each function’s manual, aka help pages, which can be accessed programmatically in the R console via ?&lt;function&gt;. Finally, the NEWS file contains notes from the authors which highlight changes across different versions of the package. This is a great way of tracking changes, especially functions that are added, removed, or deprecated, in order to keep your scripts current with new versions of dependent packages. Below this, the Details section covers finer nuances of the package, mostly relating to its relationship to other packages: upstream dependencies (Depends, Imports, Suggests fields): packages that are imported upon loading the given package downstream dependencies (Depends On Me, Imports Me, Suggests Me): packages that import the given package when loaded For example, we can see that an entry called simpleSingle in the Depends On Me field on the scater page takes us to a step-by-step workflow for low-level analysis of single-cell RNA-seq data. One additional Details entry, the biocViews, is helpful for looking at how the authors annotate their package. For example, for the scater package, we see that it is associated with DataImport, DimensionReduction, GeneExpression, RNASeq, and SingleCell, to name but some of its many annotations. We cover biocViews in more detail. 2.5.2 biocViews To find packages via the Bioconductor website, one useful resource is the BiocViews page, which provides a hierarchically organized view of annotations associated with Bioconductor packages. Under the “Software” label for example (which is comprised of most of the Bioconductor packages), there exist many different views to explore packages. For example, we can inspect based on the associated “Technology”, and explore “Sequencing” associated packages, and furthermore subset based on “RNASeq”. Another area of particular interest is the “Workflow” view, which provides Bioconductor packages that illustrate an analytical workflow. For example, the “SingleCellWorkflow” contains the aforementioned tutorial, encapsulated in the simpleSingleCell package. 2.5.3 Bioconductor Forums The Bioconductor support site contains a Stackoverflow-style question and answer support site that is actively contributed to from both users and package developers. Thanks to the work of dedicated volunteers, there are ample questions to explore to learn more about Bioconductor specific workflows. Another way to connect with the Bioconductor community is through Slack, which hosts various channels dedicated to packages and workflows. The Bioc-community Slack is a great way to stay in the loop on the latest developments happening across Bioconductor, and we recommend exploring the “Channels” section to find topics of interest. "],
["beyond-r-basics.html", "Chapter 3 Beyond R Basics 3.1 Becoming an R Expert 3.2 Becoming an R/Bioconductor Developer 3.3 Nice Companions for R", " Chapter 3 Beyond R Basics Here we briefly outline resources for taking your R programming to the next level, including resources for learning about package development. We also outline some companions to R that are good to know not only for package development, but also for running your own bioinformatic pipelines, enabling you to use a broader array of tools to go from raw data to preprocessed data before working in R. 3.1 Becoming an R Expert A deeper dive into the finer details of the R programming language is provided by the book Advanced R. While targeted at more experienced R users and programmers, this book represents a comprehensive compendium of more advanced concepts, and touches on some of the paradigms used extensively by developers throughout Bioconductor, specifically programming with S4. Eventually, you’ll reach the point where you have your own collection of functions and datasets, and where you will be writing your own packages. Luckily, there’s a guide for just that, with the book R Packages. Packages are great even if just for personal use, and of course, with some polishing, can eventually become available on CRAN or Bioconductor. Furthermore, they are also a great way of putting together code associated with a manuscript, promoting reproducible, accessible computing practices, something we all strive for in our work. For many of the little details that are oft forgotten learning about R, the aptly named What They Forgot to Teach You About R is a great read for learning about the little things such as file naming, maintaining an R installation, and reproducible analysis habits. Finally, we save the most intriguing resource for last - another book for those on the road to becoming an R expert is R Inferno, which dives into many of the unique quirks of R. Warning: this book goes very deep into the painstaking details of R. 3.2 Becoming an R/Bioconductor Developer While learning to use Bioconductor tools is a very welcoming experience, unfortunately there is no central resource for navigating the plethora of gotchas and paradigms associated with developing for Bioconductor. Based on conversations with folks involved in developing for Bioconductor, much of this knowledge is hard won and fairly spread out. This however is beginning to change with more recent efforts led by the Bioconductor team, and while this book represents an earnest effort towards addressing the user perspective, it is currently out of scope to include a deep dive about the developer side. For those looking to get started with developing packages for Bioconductor, it is important to first become acquainted with developing standalone R packages. To this end, the R Packages book provides a deep dive into the details of constructing your own package, as well as details regarding submission of a package to CRAN. For programming practices, With that, some resources that are worth looking into to get started are the BiocWorkshops repository under the Bioconductor Github provides a book composed of workshops that have been hosted by Bioconductor team members and contributors. These workshops center around learning, using, and developing for Bioconductor. A host of topics are also available via the Learn module on the Bioconductor website. Finally, the Bioconductor developers portal contains a bevy of individual resources and guides for experienced R developers. 3.3 Nice Companions for R While not essential for our purposes, many bioinformatic tools for processing raw sequencing data require knowledge beyond just R to install, run, and import their results into R for further analysis. The most important of which are basic knowledge of the Shell/Bash utilities, for working with bioinformatic pipelines and troubleshooting (R package) installation issues. Additionally, for working with packages or software that are still in development and not hosted on an official repository like CRAN or Bioconductor, knowledge of Git - a version control system - and the popular GitHub hosting service is helpful. This enables you to not only work with other people’s code, but also better manage your own code to keep track of changes. 3.3.1 Shell/Bash Datacamp and other interactive online resources such as Codecademy are great places to learn some of these extra skills. We highly recommend learning Shell/Bash, as it is the starting point for most bioinformatic processing pipelines. 3.3.2 Git We would recommend learning Git next, a system for code versioning control which underlies the popular GitHub hosting service, where many of the most popular open source tools are hosted. Learning Git is essential not only for keeping track of your own code, but also for using, managing, and contributing to open source software projects. For a more R centric look at using Git (and Github), we highly recommend checking out Happy Git and Github for the useR. 3.3.3 Other Languages A frequent question that comes up is “What else should I learn besides R?” Firstly, we believe that honing your R skills is first and foremost, and beyond just R, learning Shell/Bash and Git covered in the Nice Companions for R section are already a great start. For those just getting started, these skills should become comfortable in practice before moving on. However, there are indeed benefits to going beyond just R. At a basic level, learning other programming languages helps broaden one’s perspective - similar to learning multiple spoken or written languages, learning about other programming languages (even if only in a cursory manner) helps one identify broader patterns that may be applicable across languages. At an applied level, work within and outside of R has made it ever more friendly now than ever before with multi-lingual setups and teams, enabling the use of the best tool for the job at hand. For example, Python is another popular language used in both data science and a broader array of applications as well. R now supports a native Python interface via the reticulate package, enabling access to tools developed originally in Python such as the popular TensorFlow framework for machine learning applications. C++ is frequently used natively in R as well via Rcpp in packages to massively accelerate computations. Finally, multiple langauges are supported in code documents and reports through R Markdown. "],
["data-infrastructure.html", "Chapter 4 Data Infrastructure 4.1 Prerequisites 4.2 The SingleCellExperiment Class 4.3 A Brief Recap: From se to sce 4.4 The reducedDims Slot 4.5 One More Thing: metadata Slot 4.6 About Spike-Ins 4.7 Working with SingleCellExperiment 4.8 The Centrality of SingleCellExperiment 4.9 Multimodal Data: MultiAssayExperiment", " Chapter 4 Data Infrastructure One of the advantages of using Bioconductor packages is that they utilize common data infrastructures which makes analyses interoperable across various packages. Furthermore, much engineering effort is put into making this infrastructure robust and scalable. Here, we describe the SingleCellExperiment object (or sce in shorthand) in detail to describe how it is constructed, utilized in downstream analysis, and how it stores various types of primary data and metadata. 4.1 Prerequisites The Bioconductor package SingleCellExperiment provides the SingleCellExperiment class for usage. While the package is implicitly installed and loaded when using any package that depends on the SingleCellExperiment class, it can be explicitly installed (and loaded) as follows: BiocManager::install(&#39;SingleCellExperiment&#39;) Additionally, we use some functions from the scater and scran packages, as well as the CRAN package uwot (which conveniently can also be installed through BiocManager). These functions will be accessed through the &lt;package&gt;::&lt;function&gt; convention as needed. BiocManager::install(c(&#39;scater&#39;, &#39;scran&#39;, &#39;uwot&#39;)) For this session, all we will need loaded is the SingleCellExperiment package: library(SingleCellExperiment) 4.2 The SingleCellExperiment Class Overview of the SingleCellExperiment class object 4.2.1 Primary Data: The assays Slot The SingleCellExperiment (sce) object is the basis of single-cell analytical applications based in Bioconductor. The sce object is an S4 object, which in essence provides a more formalized approach towards construction and accession of data compared to other methods available in R. The utility of S4 comes from validity checks that ensure safe data manipulation, and most important for our discussion, from its extensibility through slots. If we imagine the sce object to be a ship, the slots of sce can be thought of as individual cargo boxes - each exists as a separate entity within the sce object. Furthermore, each slot contains data that arrives in its own format. To extend the metaphor, we can imagine that different variations of cargo boxes are required for fruits versus bricks. In the case of sce, certain slots expect numeric matrices, whereas others may expect data frames. To construct a rudimentary sce object, all we need is a single slot: assays slot: contains primary data such as counts in a list, where each entry of the list is in a matrix format, where rows correspond to features (genes) and columns correspond to samples (cells) (Figure 1A, blue box) Let’s start simple by generating three cells worth of count data across ten genes. counts_matrix &lt;- data.frame(cell_1 = rpois(10, 10), cell_2 = rpois(10, 10), cell_3 = rpois(10, 30)) rownames(counts_matrix) &lt;- paste0(&quot;gene_&quot;, 1:10) counts_matrix &lt;- as.matrix(counts_matrix) # must be a matrix object! From this, we can now construct our first SingleCellExperiment object, using the defined constructor, SingleCellExperiment(). Note that we provide our data as a named list, and each entry of the list is a matrix. Here, we name the counts_matrix entry as simply counts within the list. sce &lt;- SingleCellExperiment(assays = list(counts = counts_matrix)) To inspect the object, we can simply type sce into the console to see some pertinent information, which will display an overview of the various slots available to us (which may or may not have any data). sce ## class: SingleCellExperiment ## dim: 10 3 ## metadata(0): ## assays(1): counts ## rownames(10): gene_1 gene_2 ... gene_9 gene_10 ## rowData names(0): ## colnames(3): cell_1 cell_2 cell_3 ## colData names(0): ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): To access the count data we just supplied, we can do any one of the following: assay(sce, &quot;counts&quot;) - this is the most general method, where we can supply the name of the assay as the second argument. counts(sce) - this is the same as the above, but only works for assays with the special name &quot;counts&quot;. counts(sce) ## cell_1 cell_2 cell_3 ## gene_1 11 10 43 ## gene_2 6 10 33 ## gene_3 7 12 32 ## gene_4 10 13 19 ## gene_5 16 11 26 ## gene_6 8 12 23 ## gene_7 8 10 31 ## gene_8 12 12 31 ## gene_9 8 8 27 ## gene_10 12 13 35 ## assay(sce, &quot;counts&quot;) ## same as above in this special case 4.2.2 Extending the assays Slot What makes the assay slot especially powerful is that it can hold multiple representations of the primary data. This is especially useful for storing the raw as well as a normalized version of the data. We can do just that as shown below, using the scran and scater packages to compute a normalized and log-transformed representation of the initial primary data. Note that here, we overwrite our previous sce upon reassigning the results to sce - this is because these functions return a SingleCellExperiment object. Some functions - especially those outside of single-cell oriented Bioconductor packages - do not, in which case you will need to append your results to the sce object (see below). sce &lt;- scran::computeSumFactors(sce) sce &lt;- scater::normalize(sce) Viewing the object again, we see that these functions added some new entries: sce ## class: SingleCellExperiment ## dim: 10 3 ## metadata(1): log.exprs.offset ## assays(2): counts logcounts ## rownames(10): gene_1 gene_2 ... gene_9 gene_10 ## rowData names(0): ## colnames(3): cell_1 cell_2 cell_3 ## colData names(0): ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): Specifically, we see that the assays slot has grown to be comprised of two entries: counts (our initial data) and logcounts (the normalized data). Similar to counts, the logcounts name is a special name which lets us access it simply by typing logcounts(sce), although the longhand version works just as well. logcounts(sce) ## cell_1 cell_2 cell_3 ## gene_1 4.33 4.03 4.66 ## gene_2 3.51 4.03 4.30 ## gene_3 3.71 4.27 4.26 ## gene_4 4.19 4.38 3.55 ## gene_5 4.84 4.15 3.97 ## gene_6 3.89 4.27 3.81 ## gene_7 3.89 4.03 4.21 ## gene_8 4.44 4.27 4.21 ## gene_9 3.89 3.73 4.02 ## gene_10 4.44 4.38 4.38 ## assay(sce, &quot;logcounts&quot;) ## same as above Notice that the data before had a severe discrepancy in counts between cells 1/2 versus 3, and that normalization has ameliorated this difference. To look at all the available assays within sce, we can type: assays(sce) ## List of length 2 ## names(2): counts logcounts While the functions above demonstrate automatic addition of assays to our sce object, there may be cases where we want to perform our own calculations and save the result into the assays slot. In particular, this is important for using functions that do not return a SingleCellExperiment object. Let’s append a new version of the data that has been offset by +100. counts_100 &lt;- assay(sce, &quot;counts&quot;) + 100 assay(sce, &quot;counts_100&quot;) &lt;- counts_100 # assign a new entry to assays slot Then we can use the accessor assays() (notice this is plural!) to see all our entries into the assay slot that we have made so far. Note that to see all the assays, we use the plural assays() accessor, and to retrieve a single assay entry (as a matrix) we use the singular assay() accessor, providing the name of the assay we wish to retrieve as above. assays(sce) ## List of length 3 ## names(3): counts logcounts counts_100 These entries are also seen on the default view of sce: sce ## class: SingleCellExperiment ## dim: 10 3 ## metadata(1): log.exprs.offset ## assays(3): counts logcounts counts_100 ## rownames(10): gene_1 gene_2 ... gene_9 gene_10 ## rowData names(0): ## colnames(3): cell_1 cell_2 cell_3 ## colData names(0): ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): This sort of extension of the assays slot is represented graphically in Figure 1B (dark blue box), showing the addition of the logcounts matrix into the assays slot. In a similar manner, many of the slots of sce are extendable through assignment as shown above, thus allowing for myriad custom functionality as needed for interoperability with functions outside of single-cell oriented Bioconductor packages. 4.2.3 Column (Meta)Data: colData Slot To further annotate our sce object, one of the first and most useful pieces of information is adding metadata that describes the columns of our primary data, e.g., the samples or cells of our experiment. This data is entered into the colData slot: colData slot: metadata that describes that samples (cells) provided as a data.frame (or DataFrame if appending), where rows correspond to cells, and columns correspond to the sample (cells) metadata features (e.g. id, batch, author, etc.) (Figure 1A, orange box). So, let’s come up with some metadata for the cells, starting with a batch variable, where cells 1 and 2 are in batch 1, and cell 3 is from batch 2. cell_metadata &lt;- data.frame(batch = c(1, 1, 2)) rownames(cell_metadata) &lt;- paste0(&quot;cell_&quot;, 1:3) Now, we can take two approaches - either append the cell_metadata to our existing sce, or start from scratch via the SingleCellExperiment() constructor and provide it from the get go. We’ll start from scratch for now, but will also show how to append the data: ## From scratch: sce &lt;- SingleCellExperiment(assays = list(counts = counts_matrix), colData = cell_metadata) ## Appending to existing object (requires DataFrame() coercion) ## colData(sce) &lt;- DataFrame(cell_metadata) Similar to assays, we can see our colData is now populated from the default view of sce: sce ## class: SingleCellExperiment ## dim: 10 3 ## metadata(0): ## assays(1): counts ## rownames(10): gene_1 gene_2 ... gene_9 gene_10 ## rowData names(0): ## colnames(3): cell_1 cell_2 cell_3 ## colData names(1): batch ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): And furthermore access our column (meta)data with the accessor, colData(): colData(sce) ## DataFrame with 3 rows and 1 column ## batch ## &lt;numeric&gt; ## cell_1 1 ## cell_2 1 ## cell_3 2 Finally, some packages automatically add to the colData slot, for example, the scater package features a function, calculateQCMetrics(), which appends a lot of quality control data. Here we show the first five columns of colData(sce) with the quality control metrics appended to it. sce &lt;- scater::calculateQCMetrics(sce) colData(sce)[, 1:5] ## DataFrame with 3 rows and 5 columns ## batch is_cell_control total_features_by_counts ## &lt;numeric&gt; &lt;logical&gt; &lt;integer&gt; ## cell_1 1 FALSE 10 ## cell_2 1 FALSE 10 ## cell_3 2 FALSE 10 ## log10_total_features_by_counts total_counts ## &lt;numeric&gt; &lt;integer&gt; ## cell_1 1.04139268515822 98 ## cell_2 1.04139268515822 111 ## cell_3 1.04139268515822 300 4.2.3.1 Using colData for Subsetting A common operation with colData is its use in subsetting. One simple way to access colData is through the use of the $ operator, which is a shortcut for accessing a variable within the colData slot: sce$batch ## [1] 1 1 2 ## colData(sce)$batch # same as above If we only wanted cells within batch 1, we could subset our sce object as follows (remember, we subset on the columns in this case because we are filtering by cells/samples here). sce[, sce$batch == 1] ## class: SingleCellExperiment ## dim: 10 2 ## metadata(0): ## assays(1): counts ## rownames(10): gene_1 gene_2 ... gene_9 gene_10 ## rowData names(7): is_feature_control mean_counts ... total_counts ## log10_total_counts ## colnames(2): cell_1 cell_2 ## colData names(10): batch is_cell_control ... ## pct_counts_in_top_200_features pct_counts_in_top_500_features ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): 4.2.4 Feature Metadata: rowData/rowRanges Lastly, the rows also have their own metadata slot to store information that pertains to the features of the sce object: rowData slot: contains data in a data.frame (DataFrame) format that describes aspects of the data corresponding to the rows of the primary data (Figure 1A, green box). Furthermore, there is a special slot which pertains to features with genomic coordinates: rowRanges slot: contains data in a GRangesList (where each entry is a GenomicRanges format) that describes the chromosome, start, and end coordinates of the features (genes, genomic regions). Both of these can be accessed via their respective accessors, rowRanges() and rowData(). In our case, rowRanges(sce) produces an empty list: rowRanges(sce) # empty ## GRangesList object of length 10: ## $gene_1 ## GRanges object with 0 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## ------- ## seqinfo: no sequences ## ## $gene_2 ## GRanges object with 0 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## ------- ## seqinfo: no sequences ## ## $gene_3 ## GRanges object with 0 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## ------- ## seqinfo: no sequences ## ## ... ## &lt;7 more elements&gt; However, our call to calculateQCMetrics(sce) in the prior section filled in the rowData slot of our sce object, as we can see below (only the first three columns are shown for brevity): rowData(sce)[, 1:3] ## DataFrame with 10 rows and 3 columns ## is_feature_control mean_counts log10_mean_counts ## &lt;logical&gt; &lt;numeric&gt; &lt;numeric&gt; ## gene_1 FALSE 21.3333333333333 1.34895354798116 ## gene_2 FALSE 16.3333333333333 1.23888208891514 ## gene_3 FALSE 17 1.25527250510331 ## gene_4 FALSE 14 1.17609125905568 ## gene_5 FALSE 17.6666666666667 1.27106677228654 ## gene_6 FALSE 14.3333333333333 1.18563657696191 ## gene_7 FALSE 16.3333333333333 1.23888208891514 ## gene_8 FALSE 18.3333333333333 1.28630673884327 ## gene_9 FALSE 14.3333333333333 1.18563657696191 ## gene_10 FALSE 20 1.32221929473392 In a similar fashion to the colData slot, such feature metadata could be provided at the onset when creating the SingleCellExperiment object, which we leave up to the reader as an exercise. 4.2.4.1 Subsetting by Rows To subset an sce object down at the feature/gene level, we can do a row subsetting operation similar to other R objects, by supplying either numeric indices or a vector of names: sce[c(&quot;gene_1&quot;, &quot;gene_4&quot;), ] ## class: SingleCellExperiment ## dim: 2 3 ## metadata(0): ## assays(1): counts ## rownames(2): gene_1 gene_4 ## rowData names(7): is_feature_control mean_counts ... total_counts ## log10_total_counts ## colnames(3): cell_1 cell_2 cell_3 ## colData names(10): batch is_cell_control ... ## pct_counts_in_top_200_features pct_counts_in_top_500_features ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): ## sce[c(1, 4), ] # same as above in this case 4.2.5 Size Factors Slot: sizeFactors Briefly, we already encountered this via the scran::computeSumFactors(sce) call, which adds a sizeFactors slot: sizeFactors slot: contains information in a numeric vector regarding the sample/cell normalization factors used to produce a normalized data representation (Figure 1B, brown box) sce &lt;- scran::computeSumFactors(sce) sce &lt;- scater::normalize(sce) sizeFactors(sce) ## [1] 0.578 0.654 1.768 4.3 A Brief Recap: From se to sce So far, we have covered the assays (primary data), colData (sample metadata), rowData/rowRanges (feature metadata), and sizeFactors slots of SingleCellExperiment. What is important to note is that the SingleCellExperiment class derives from the SummarizedExperiment (se) class, its predecessor, and in particular inherits the aforementioned slots. As such, much of the SummarizedExperiment functionality is retained in SingleCellExperiment. This allows existing methods that work with SummarizedExperiment to work similarly on SingleCellExperiment objects. So what’s new about the SingleCellExperiment class then? For our discussion, the most important change is the addition of a new slot called reducedDims. 4.4 The reducedDims Slot The reducedDims slot is a new addition which is specially designed to store reduced dimensionality representations of primary data, obtained by methods such as PCA, tSNE, UMAP, and others. reducedDims slot: contains a list of numeric matrix entries which describe dimensionality reduced representations of the primary data, such that rows represent the columns of the primary data (aka the samples/cells), and columns represent the dimensions Most importantly, just like the assays slot, the reducedDims slot can hold a list of many entries. So, it can hold a PCA, TSNE, and UMAP representation of a given dataset all within the reducedDims slot. In our example, we can calculate a PCA representation of our data as follows using the scater package function runPCA(). We see that the sce now shows a new reducedDim and that the accessor reducedDim() produces the results of running PCA on the normalized data from logcounts(sce). sce &lt;- scater::runPCA(sce) reducedDim(sce, &quot;PCA&quot;) ## PC1 PC2 ## cell_1 -0.7405 0.347 ## cell_2 -0.0602 -0.622 ## cell_3 0.8007 0.275 ## attr(,&quot;percentVar&quot;) ## [1] 67.2 32.8 From this, we can also calculate a tSNE representation using the scater package function runTSNE(), and see that it can be seen both in the default view of sce and via accession: sce &lt;- scater::runTSNE(sce, perplexity = 0.1) ## Perplexity should be lower than K! reducedDim(sce, &quot;TSNE&quot;) ## [,1] [,2] ## cell_1 -4746 3143 ## cell_2 5094 2540 ## cell_3 -347 -5683 We can view the names of all our entries in the reducedDims slot via the accessor, reducedDims() (notice that this is plural, and thus not the same as reducedDim(): reducedDims(sce) ## List of length 2 ## names(2): PCA TSNE Now, say we have a different dimensionality reduction approach which has not yet been implemented with SingleCellExperiment objects in mind. For example, let’s say we want to try the umap() function as implemented in the uwot package (which is a much faster version of the default umap implementation currently in scater). Similar to how we extended the assays slot with our own custom entry of counts_100, we can do similarly for the reducedDims slot: u &lt;- uwot::umap(t(logcounts(sce)), n_neighbors = 2) reducedDim(sce, &quot;UMAP_uwot&quot;) &lt;- u reducedDim(sce, &quot;UMAP_uwot&quot;) ## [,1] [,2] ## cell_1 0.548 0.427 ## cell_2 -0.373 0.170 ## cell_3 -0.175 -0.596 ## attr(,&quot;scaled:center&quot;) ## [1] -1.21 -22.09 And we can also see its entry when we look at the reducedDims() accessor output: reducedDims(sce) ## List of length 3 ## names(3): PCA TSNE UMAP_uwot 4.5 One More Thing: metadata Slot Some analyses produce results that do not fit into the aforementioned slots. Thankfully, there is a slot just for this type of messy data, and in fact, can accommodate any type of data, so long as it is in a named list: metadata slot: a named list of entries, where each entry in the list can be anything you want it to be For example, say we have some favorite genes, such as highly variable genes, we want to save inside of sce for use in our analysis at a later point. We can do this simply by appending to the metadata slot as follows: my_genes &lt;- c(&quot;gene_1&quot;, &quot;gene_5&quot;) metadata(sce) &lt;- list(favorite_genes = my_genes) metadata(sce) ## $favorite_genes ## [1] &quot;gene_1&quot; &quot;gene_5&quot; Similarly, we can append more information via the $ operator: your_genes &lt;- c(&quot;gene_4&quot;, &quot;gene_8&quot;) metadata(sce)$your_genes &lt;- your_genes metadata(sce) ## $favorite_genes ## [1] &quot;gene_1&quot; &quot;gene_5&quot; ## ## $your_genes ## [1] &quot;gene_4&quot; &quot;gene_8&quot; 4.6 About Spike-Ins You might have noticed that the sce default view produces an entry with spikeNames. The SingleCellExperiment object contains some special considerations for experiments with spike-in (ERCC) controls. We leave this to the interested reader to learn more about in the SingleCellExperiment introductory vignette. 4.7 Working with SingleCellExperiment In subsequent sections, we will show an example workflow that uses the SingleCellExperiment object as its base, and similar to our walkthrough of the SingleCellExperiment class above, continually appends new entries to save the results of the analysis. The SingleCellExperiment thus can serve as a record of analysis in this manner. This makes it especially useful for collaboration, as the object can be transferred and then visualized via graphical user interfaces such as iSEE. 4.8 The Centrality of SingleCellExperiment Graph network of package dependencies linking to the SingleCellExperiment package (class). Packages are filtered by biocView “singleCell”. To emphasize its importance, here we show the centrality of the SingleCellExperiment class to the Bioc-verse single-cell related packages. It is this connection to SingleCellExperiment that makes many of these packages easily interoperable and modular over the span of an scRNA-seq analysis. 4.9 Multimodal Data: MultiAssayExperiment Recent advances in technology and protocols allow the simultaneous collection of DNA and RNA from the same cells, enabling single-cell multi-modal analysis. These data present new challenges in the complexity of statistical analyses, which are addressed in Bioconductor through the MultiAssayExperiment container. The MultiAssayExperiment class integrates all major Bioconductor experimental data containers, and any containers derived from those, including SingleCellExperiment. It provides harmonized data management for heterogeneous assays, including subsetting by genomic identifiers, genomic coordinates, or sample/cell attributes such as cell type. The user interface mimics that of SingleCellExperiment, with comparable actions working across all assays. Multi-modal profiling is an emergent area of single-cell biology with many exciting technologies coming online, such as gene expression profiling in tandem with protein via CITE-seq/REAP-seq and adaptive repertoire sequencing. While we won’t cover multimodal data analysis further in this online book as of this writing, we anticipate infrastructure and statistical methodology advances in this area in the near future. document.addEventListener(\"click\", function (event) { if (event.target.classList.contains(\"aaron-collapse\")) { event.target.classList.toggle(\"active\"); var content = event.target.nextElementSibling; if (content.style.display === \"block\") { content.style.display = \"none\"; } else { content.style.display = \"block\"; } } }) .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } "],
["overview.html", "Chapter 5 Overview 5.1 Introduction 5.2 Experimental Design 5.3 Preprocessing 5.4 Data processing and downstream analysis 5.5 Quick start Session Info", " Chapter 5 Overview 5.1 Introduction This chapter provides an overview of the framework of a typical scRNA-seq analysis workflow (Figure 5.1). Subsequent chapters will describe each analysis step in more detail. Figure 5.1: Schematic of a typical scRNA-seq analysis workflow. Each stage (separated by dashed lines) consists of a number of specific steps, many of which operate on and modify a SingleCellExperiment instance. 5.2 Experimental Design Before starting the analysis itself, some comments on experimental design may be helpful. The most obvious question is the choice of technology, which can be roughly divided into: Droplet-based (10X Genomics, inDrop, Drop-seq) Plate-based with UMIs (CEL-seq, MARS-seq) Plate-based with reads (Smart-seq2) Other (sci-RNA-seq, seqWell) Each of these methods have their own advantages and weaknesses that are discussed extensively elsewhere (Mereu et al. 2019; Ziegenhain et al. 2017). In practical terms, droplet-based technologies are the current de facto standard due to their throughput and low cost per cell. Plate-based methods can capture other phenotypic information (e.g., morphology) and are more amenable to customization. Read-based methods provide whole-transcript coverage, which is useful in some applications (e.g., splicing, exome mutations). The choice of method is left to the reader’s circumstances - we will simply note that most aspects of our analysis pipeline are technology-agnostic. The next question is how many cells should be captured, and to what depth they should be sequenced. The short answer is “as much as you can afford to spend”. The long answer is that it depends on the aim of the analysis. If we are aiming to discover rare cell subpopulations, then we need more cells. If we are aiming to characterize subtle differences, then we need more sequencing depth. As of time of writing, an informal survey of the literature suggests that typical droplet-based experiments would capture anywhere from 10,000 to 100,000 cells, sequenced at anywhere from 1,000 to 10,000 UMIs per cell (usually in inverse proportion to the number of cells). Droplet-based methods also have a trade-off between throughput and doublet rate that affects the true efficiency of sequencing. For studies involving multiple samples or conditions, the design considerations are the same as those for bulk RNA-seq experiments. There should be multiple biological replicates for each condition and conditions should not be confounded with batch. Note that individual cells are not replicates; rather, we are referring to samples derived from replicate donors or cultures. 5.3 Preprocessing Sequencing data from scRNA-seq experiments must be converted into per-cell and per-gene expression values. The exact procedure for doing so is usually run outside of R and tends to be technology-dependent: For 10X Genomics data, the CellRanger software suite provides a custom pipeline to obtain a count matrix. This uses STAR to align reads to the reference genome, and then counts the number of unique UMIs mapped to each gene. Pseudo-alignment methods such as alevin can be used to obtain a count matrix from the same data with greater efficiency. This avoids the need for explicit alignment, which reduces the compute time and memory usage. For other highly multiplexed protocols, we can use the scPipe package, which provides a more general pipeline for processing scRNA-seq data. This uses the Rsubread aligner to align reads and then counts UMIs per gene. For CEL-seq or CEL-seq2 data, the scruff package provides a dedicated pipeline for quantification. For read-based protocols, we can use the same pipelines for processing bulk RNA-seq data. For any data involving spike-in transcripts, the spike-in sequences should be included as part of the reference genome during alignment and quantification. We import the count matrix into R and create a SingleCellExperiment object. This can be done with base methods (e.g., read.table()) followed by applying the SingleCellExperiment() constructor. Alternatively, for specific file formats, we can use dedicated methods from the DropletUtils (for 10X data) or tximport/tximeta packages (for pseudo-alignment methods). Depending on the origin of the data, this requires some vigilance: Some feature-counting tools will report mapping statistics in the count matrix (e.g., the number of unaligned or unassigned reads). While these values can be useful for quality control, they would be misleading if treated as gene expression values. Thus, they should be removed (or at least moved to the colData) prior to further analyses. Be careful of using the ^ERCC regular expression for human data where the row names of the count matrix are gene symbols. An ERCC gene family actually exists in human annotation, so this would result in incorrect identification of genes as spike-in transcripts. This problem can be avoided by publishing count matrices with standard identifiers (e.g., Ensembl, Entrez). 5.4 Data processing and downstream analysis In the simplest case, the workflow has the following form: We compute quality control metrics to remove low-quality cells that would interfere with downstream analyses. These cells may have been damaged during processing or may not have been fully captured by the sequencing protocol. Common metrics includes the total counts per cell, the proportion of spike-in or mitochondrial reads and the number of detected features. We convert the counts into normalized expression values to eliminate cell-specific biases (e.g., in capture efficiency). This allows us to perform explicit comparisons across cells in downstream steps like clustering. We also apply a transformation, typically log, to adjust for the mean-variance relationship. We perform feature selection to pick a subset of interesting features for downstream analysis. This is done by modelling the variance across cells for each gene and retaining genes that are highly variable. The aim is to reduce computational overhead and noise from uninteresting genes. We apply dimensionality reduction to compact the data and further reduce noise. Principal components analysis is typically used to obtain an initial low-rank representation for more computational work, followed by more aggressive methods like \\(t\\)-stochastic neighbor embedding for visualization purposes. We cluster cells into groups according to similarities in their (normalized) expression profiles. This aims to obtain groupings that serve as empirical proxies for distinct biological states. We typically interpret these groupings by identifying differentially expressed marker genes between clusters. Additional steps such as data integration and cell annotation will be discussed in their respective chapters. 5.5 Quick start Here, we use the a droplet-based retina dataset from Macosko et al. (2015), provided in the scRNAseq package. This starts from a count matrix and finishes with clusters (Figure 5.2) in preparation for biological interpretation. Similar workflows are available in abbreviated form in the Appendices. library(scRNAseq) sce &lt;- MacoskoRetinaData() # Quality control. library(scater) is.mito &lt;- grepl(&quot;^MT-&quot;, rownames(sce)) qcstats &lt;- perCellQCMetrics(sce, subsets=list(Mito=is.mito)) filtered &lt;- quickCellQC(qcstats, percent_subsets=&quot;subsets_Mito_percent&quot;) sce &lt;- sce[, !filtered$discard] # Normalization. sce &lt;- logNormCounts(sce) # Feature selection. library(scran) dec &lt;- modelGeneVar(sce) hvg &lt;- rownames(dec)[dec$bio &gt; 0] # Dimensionality reduction. set.seed(1234) library(BiocSingular) sce &lt;- runPCA(sce, subset_row=hvg, BSPARAM=IrlbaParam()) sce &lt;- runUMAP(sce, dimred = &#39;PCA&#39;, external_neighbors=TRUE) # Clustering. g &lt;- buildSNNGraph(sce, use.dimred = &#39;PCA&#39;) sce$clusters &lt;- factor(igraph::cluster_louvain(g)$membership) # Visualization. plotUMAP(sce, colour_by=&quot;clusters&quot;) Figure 5.2: UMAP plot of the retina dataset, where each point is a cell and is colored by the cluster identity. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] BiocSingular_1.1.7 scran_1.13.25 [3] scater_1.13.20 ggplot2_3.2.1 [5] scRNAseq_1.99.6 SingleCellExperiment_1.7.10 [7] SummarizedExperiment_1.15.9 DelayedArray_0.11.6 [9] BiocParallel_1.19.2 matrixStats_0.55.0 [11] Biobase_2.45.1 GenomicRanges_1.37.16 [13] GenomeInfoDb_1.21.1 IRanges_2.19.16 [15] S4Vectors_0.23.23 BiocGenerics_0.31.6 [17] Cairo_1.5-10 BiocStyle_2.13.2 [19] OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] bitops_1.0-6 bit64_0.9-7 [3] httr_1.4.1 tools_3.6.1 [5] backports_1.1.4 R6_2.4.0 [7] irlba_2.3.3 vipor_0.4.5 [9] uwot_0.1.4 DBI_1.0.0 [11] lazyeval_0.2.2 colorspace_1.4-1 [13] withr_2.1.2 tidyselect_0.2.5 [15] gridExtra_2.3 bit_1.1-14 [17] curl_4.2 compiler_3.6.1 [19] BiocNeighbors_1.3.5 labeling_0.3 [21] bookdown_0.13 scales_1.0.0 [23] rappdirs_0.3.1 stringr_1.4.0 [25] digest_0.6.21 rmarkdown_1.15 [27] XVector_0.25.0 pkgconfig_2.0.3 [29] htmltools_0.3.6 limma_3.41.16 [31] dbplyr_1.4.2 highr_0.8 [33] rlang_0.4.0 RSQLite_2.1.2 [35] shiny_1.3.2 DelayedMatrixStats_1.7.2 [37] dplyr_0.8.3 RCurl_1.95-4.12 [39] magrittr_1.5 GenomeInfoDbData_1.2.1 [41] Matrix_1.2-17 Rcpp_1.0.2 [43] ggbeeswarm_0.6.0 munsell_0.5.0 [45] viridis_0.5.1 edgeR_3.27.13 [47] stringi_1.4.3 yaml_2.2.0 [49] zlibbioc_1.31.0 BiocFileCache_1.9.1 [51] AnnotationHub_2.17.9 grid_3.6.1 [53] blob_1.2.0 dqrng_0.2.1 [55] promises_1.0.1 ExperimentHub_1.11.6 [57] crayon_1.3.4 lattice_0.20-38 [59] cowplot_1.0.0 locfit_1.5-9.1 [61] zeallot_0.1.0 knitr_1.25 [63] pillar_1.4.2 igraph_1.2.4.1 [65] glue_1.3.1 evaluate_0.14 [67] RcppParallel_4.4.3 BiocManager_1.30.4 [69] png_0.1-7 vctrs_0.2.0 [71] httpuv_1.5.2 gtable_0.3.0 [73] purrr_0.3.2 assertthat_0.2.1 [75] xfun_0.9 rsvd_1.0.2 [77] mime_0.7 xtable_1.8-4 [79] RSpectra_0.15-0 later_0.8.0 [81] viridisLite_0.3.0 tibble_2.1.3 [83] AnnotationDbi_1.47.1 beeswarm_0.2.3 [85] memoise_1.1.0 statmod_1.4.32 [87] interactiveDisplayBase_1.23.0 Bibliography "],
["quality-control.html", "Chapter 6 Quality Control 6.1 Motivation 6.2 Choice of QC metrics 6.3 Identifying low-quality cells 6.4 Checking diagnostic plots 6.5 Marking or removal? 6.6 Cell calling in droplet data 6.7 Checking for discarded cell types Session Info", " Chapter 6 Quality Control .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 6.1 Motivation Low-quality libraries in scRNA-seq data can arise from a variety of sources such as cell damage during dissociation or failure in library preparation (e.g., inefficient reverse transcription or PCR amplification). These usually manifest as “cells” with low total counts, few expressed genes and high mitochondrial or spike-in proportions. These low-quality libraries are problematic as they can contribute to misleading results in downstream analyses: They form their own distinct cluster(s), complicating interpretation of the results. This is most obviously driven by increased mitochondrial proportions or enrichment for nuclear RNAs after cell damage. In the worst case, low-quality libraries generated from different cell types can cluster together based on similarities in the damage-induced expression profiles, creating artificial intermediate states or trajectories between otherwise distinct subpopulations. Additionally, very small libraries can form their own clusters due to shifts in the mean upon transformation (A. Lun 2018). They distort the characterization of population heterogeneity during variance estimation or principal components analysis. The first few principal components will capture differences in quality rather than biology, reducing the effectiveness of dimensionality reduction. Similarly, genes with the largest variances will be driven by differences between low- and high-quality cells. The most obvious example involves low-quality libraries with very low counts where scaling normalization inflates the apparent variance of genes that happen to have a non-zero count in those libraries. They contain genes that appear to be strongly “upregulated” due to aggressive scaling to normalize for small library sizes. This is most problematic for contaminating transcripts (e.g., from the ambient solution) that are present in all libraries at low but constant levels. Increased scaling in low-quality libraries transforms small counts for these transcripts in large normalized expression values, resulting in apparent upregulation compared to other cells. This can be misleading as the affected genes are often biologically sensible but are actually expressed in another subpopulation. To avoid - or at least mitigate - these problems, we need to remove these cells at the start of the analysis. This step is commonly referred to as quality control (QC) on the cells. (We will use “library” and “cell” rather interchangeably here, though the distinction will become important when dealing with droplet-based data.) We will demonstrate using a small scRNA-seq dataset from A. T. L. Lun et al. (2017), which is provided with no prior QC so that we can apply our own procedures. View history ### loading ### library(scRNAseq) sce.416b &lt;- LunSpikeInData(which=&quot;416b&quot;) sce.416b$block &lt;- factor(sce.416b$block) sce.416b ## class: SingleCellExperiment ## dim: 46604 192 ## metadata(0): ## assays(1): counts ## rownames(46604): ENSMUSG00000102693 ENSMUSG00000064842 ... ## ENSMUSG00000095742 CBFB-MYH11-mcherry ## rowData names(1): Length ## colnames(192): SLX-9555.N701_S502.C89V9ANXX.s_1.r_1 ## SLX-9555.N701_S503.C89V9ANXX.s_1.r_1 ... ## SLX-11312.N712_S508.H5H5YBBXX.s_8.r_1 ## SLX-11312.N712_S517.H5H5YBBXX.s_8.r_1 ## colData names(9): Source Name cell line ... spike-in addition ## block ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(2): ERCC SIRV 6.2 Choice of QC metrics We use several common QC metrics to identify low-quality cells based on their expression profiles. These metrics are described below in terms of reads for SMART-seq2 data, but the same definitions apply to UMI data generated by other technologies like MARS-seq and droplet-based protocols. The library size is defined as the total sum of counts across all relevant features for each cell. Here, we will consider the relevant features to be the endogenous genes. Cells with small library sizes are of low quality as the RNA has been lost at some point during library preparation, either due to cell lysis or inefficient cDNA capture and amplification. The number of expressed features in each cell is defined as the number of endogenous genes with non-zero counts for that cell. Any cell with very few expressed genes is likely to be of poor quality as the diverse transcript population has not been successfully captured. The proportion of reads mapped to spike-in transcripts is calculated relative to the total count across all features (including spike-ins) for each cell. As the same amount of spike-in RNA should have been added to each cell, any enrichment in spike-in counts is symptomatic of loss of endogenous RNA. Thus, high proportions are indicative of poor-quality cells where endogenous RNA has been lost due to, e.g., partial cell lysis or RNA degradation during dissociation. In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), presumably because of loss of cytoplasmic RNA from perforated cells. The reasoning is that, in the presence of modest damage, the holes in the cell membrane permit efflux of individual transcript molecules but are too small to allow mitochondria to escape, leading to a relative enrichment of mitochondrial transcripts. For each cell, we calculate these QC metrics using the perCellQCMetrics() function from the scater package (McCarthy et al. 2017). The sum column contains the total count for each cell, the detected column contains the number of detected genes, subsets_Mito_percent contains the percentage of reads mapped to mitochondrial transcripts (based on Ensembl annotation) and altexps_ERCC_percent contains the percentage of reads mapped to ERCC transcripts. # Identifying the mitochondrial transcripts: library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] location &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) is.mito &lt;- which(location==&quot;MT&quot;) # Computing the QC metrics. library(scater) df &lt;- perCellQCMetrics(sce.416b, subsets=list(Mito=is.mito)) df ## DataFrame with 192 rows and 16 columns ## sum detected percent_top_50 percent_top_100 percent_top_200 ## &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## 1 865936 7618 26.7218362557972 32.2773276546997 39.7208338722492 ## 2 1076277 7521 29.4043262097025 35.0354044544295 42.258080401235 ## 3 1180138 8306 27.3453613052033 32.4769645583822 39.3295529844815 ## 4 1342593 8143 35.809213961342 40.2666332984009 46.2459583805368 ## 5 1668311 7154 34.1197774275899 39.0901336741171 45.6660059185607 ## ... ... ... ... ... ... ## 188 776622 8174 45.936246977294 49.7010128479492 54.6100934560185 ## 189 1299950 8956 38.0829262663949 42.8929574214393 49.0621946997961 ## 190 1800696 9530 30.6675307769885 35.5838520216627 41.8550382740896 ## 191 46731 6649 32.2997581904945 37.9148744944469 44.5999443624147 ## 192 1866692 10964 26.6632095707273 31.2583972074665 37.5607759608977 ## percent_top_500 subsets_Mito_sum subsets_Mito_detected ## &lt;numeric&gt; &lt;integer&gt; &lt;integer&gt; ## 1 52.9037942757894 78790 20 ## 2 55.7454075484285 98613 20 ## 3 51.9336721637639 100341 19 ## 4 57.1209592184675 104882 20 ## 5 58.2004194661547 129559 22 ## ... ... ... ... ## 188 64.4249068401359 48126 20 ## 189 60.6674872110466 112225 25 ## 190 53.6780778099135 135693 23 ## 191 56.5235068798014 3505 16 ## 192 48.9489428357758 150375 29 ## subsets_Mito_percent altexps_ERCC_sum altexps_ERCC_detected ## &lt;numeric&gt; &lt;integer&gt; &lt;integer&gt; ## 1 9.09882485541657 65278 39 ## 2 9.16241822504801 74748 40 ## 3 8.50248021841514 60878 42 ## 4 7.8118983191481 60073 42 ## 5 7.76587818458309 136810 44 ## ... ... ... ... ## 188 6.19683707131655 61575 39 ## 189 8.63302434709027 94982 41 ## 190 7.5355862399872 113707 40 ## 191 7.50037448374741 7580 44 ## 192 8.05569424414954 48664 39 ## altexps_ERCC_percent altexps_SIRV_sum altexps_SIRV_detected ## &lt;numeric&gt; &lt;integer&gt; &lt;integer&gt; ## 1 6.80658407035354 27828 7 ## 2 6.28029958040595 39173 7 ## 3 4.78949297995239 30058 7 ## 4 4.18566507433069 32542 7 ## 5 7.28887127185236 71850 7 ## ... ... ... ... ## 188 7.17619705260214 19848 7 ## 189 6.65764326634008 31729 7 ## 190 5.81467119470586 41116 7 ## 191 13.488984589102 1883 7 ## 192 2.51930349520745 16289 7 ## altexps_SIRV_percent total ## &lt;numeric&gt; &lt;integer&gt; ## 1 2.9016456005055 959042 ## 2 3.29130111124368 1190198 ## 3 2.36477183861837 1271074 ## 4 2.26740653619545 1435208 ## 5 3.82797603159559 1876971 ## ... ... ... ## 188 2.31316539342342 858045 ## 189 2.22400416076419 1426661 ## 190 2.10256203084705 1955519 ## 191 3.35089155425846 56194 ## 192 0.843270890872805 1931645 A key assumption here is that the QC metrics are independent of the biological state of each cell. Poor values (e.g., low library sizes, high mitochondrial proportions) are presumed to be driven by technical factors rather than biological processes, meaning that the subsequent removal of cells will not misrepresent the biology in downstream analyses. Major violations of this assumption would potentially result in the loss of cell types that have, say, systematically low RNA content or high numbers of mitochondria. We can check for such violations using some diagnostics described in Sections 6.4 and 6.7. 6.3 Identifying low-quality cells 6.3.1 With fixed thresholds The simplest approach to identifying low-quality cells is to apply thresholds on the QC metrics. For example, we might consider cells to be low quality if they have library sizes below 100,000 reads; express fewer than 5,000 genes; have spike-in proportions above 10%; or have mitochondrial proportions above 10%. qc.lib &lt;- df$sum &lt; 1e5 qc.nexprs &lt;- df$detected &lt; 5e3 qc.spike &lt;- df$altexps_ERCC_percent &gt; 10 qc.mito &lt;- df$subsets_Mito_percent &gt; 10 discard &lt;- qc.lib | qc.nexprs | qc.spike | qc.mito # Summarize the number of cells removed for each reason. DataFrame(LibSize=sum(qc.lib), NExprs=sum(qc.nexprs), SpikeProp=sum(qc.spike), MitoProp=sum(qc.mito), Total=sum(discard)) ## DataFrame with 1 row and 5 columns ## LibSize NExprs SpikeProp MitoProp Total ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 1 3 0 19 14 33 While simple, this strategy requires considerable experience to determine appropriate thresholds for each experimental protocol and biological system. Thresholds for read count-based data are simply not applicable for UMI-based data, and vice versa. Differences in mitochondrial activity or total RNA content require constant adjustment of the mitochondrial and spike-in thresholds, respectively, for different biological systems. Indeed, even with the same protocol and system, the appropriate threshold can vary from run to run due to the vagaries of cDNA capture efficiency and sequencing depth per cell. 6.3.2 With adaptive thresholds 6.3.2.1 Identifying outliers To obtain an adaptive threshold, we assume that most of the dataset consists of high-quality cells. We then identify cells that are outliers for the various QC metrics, based on the median absolute deviation (MAD) from the median value of each metric across all cells. Specifically, a value is considered an outlier if it is more than 3 MADs from the median in the “problematic” direction. This is loosely motivated by the fact that such a filter will retain 99% of non-outlier values that follow a normal distribution. For the 416B data, we identify cells with log-transformed library sizes that are more than 3 MADs below the median. A log-transformation is used to improve resolution at small values when type=&quot;lower&quot;. In particular, it guarantees that the threshold is not a negative value, which would be meaningless for quality control on these metrics. Moreover, these metrics can occasionally exhibit a heavy right tail, and the log-transformation makes the distribution seem more normal to justify the 99% rationale mentioned above. qc.lib2 &lt;- isOutlier(df$sum, log=TRUE, nmads=3, type=&quot;lower&quot;) We do the same for the log-transformed number of expressed genes. qc.nexprs2 &lt;- isOutlier(df$detected, nmads=3, log=TRUE, type=&quot;lower&quot;) isOutlier() will also return the exact filter thresholds for each metric in the attributes of the output vector. These is useful for checking whether the automatically selected thresholds are appropriate. attr(qc.lib2, &quot;thresholds&quot;) ## lower higher ## 434083 Inf attr(qc.nexprs2, &quot;thresholds&quot;) ## lower higher ## 5231 Inf We identify outliers for the proportion-based metrics in a similar manner. Here, no transformation is required as we are identifying large outliers that should already be clearly distinguishable from zero. qc.spike2 &lt;- isOutlier(df$altexps_ERCC_percent, nmads=3, type=&quot;higher&quot;) attr(qc.spike2, &quot;thresholds&quot;) ## lower higher ## -Inf 14.15 qc.mito2 &lt;- isOutlier(df$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) attr(qc.mito2, &quot;thresholds&quot;) ## lower higher ## -Inf 11.92 A cell that is an outlier for any of these metrics is considered to be of low-quality and discarded. discard2 &lt;- qc.lib2 | qc.nexprs2 | qc.spike2 | qc.mito2 # Summarize the number of cells removed for each reason. DataFrame(LibSize=sum(qc.lib2), NExprs=sum(qc.nexprs2), SpikeProp=sum(qc.spike2), MitoProp=sum(qc.mito2), Total=sum(discard2)) ## DataFrame with 1 row and 5 columns ## LibSize NExprs SpikeProp MitoProp Total ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 1 4 0 1 2 6 Alternatively, this entire process can be done in a single step using the quickCellQC() function. This is a wrapper that simply calls isOutlier() with the settings described above. reasons &lt;- quickCellQC(df, percent_subsets=c(&quot;subsets_Mito_percent&quot;, &quot;altexps_ERCC_percent&quot;), nmads=3) colSums(as.matrix(reasons)) ## low_lib_size low_n_features ## 4 0 ## high_subsets_Mito_percent high_altexps_ERCC_percent ## 2 1 ## discard ## 6 With this strategy, the thresholds adapt to both the location and spread of the distribution of values for a given metric. This allows the QC procedure to adjust to changes in sequencing depth, cDNA capture efficiency, mitochondrial content, etc. without requiring any user intervention or prior experience. However, it does require some implicit assumptions that are discussed below in more detail. 6.3.2.2 Assumptions of outlier detection Outlier detection assumes that most cells are of acceptable quality. This is usually reasonable and can be experimentally supported in some situations by visually checking that the cells are intact, e.g., on the microwell plate. If most cells are of (unacceptably) low quality, the adaptive thresholds will obviously fail as they cannot remove the majority of cells. Of course, what is acceptable or not is in the eye of the beholder - neurons, for example, are notoriously difficult to dissociate, and we would often retain cells in a neuronal scRNA-seq dataset with QC metrics that would be unacceptable in a more amenable system like embryonic stem cells. Another assumption discussed earlier is that the QC metrics are independent of the biological state of each cell. This assumption is most likely to be violated in highly heterogeneous cell populations where cell types that naturally have less RNA or more mitochondria are more likely to be considered outliers and removed, even if they are of high quality. The use of the MAD mitigates this problem to some extent by accounting for biological variability in the QC metrics. A heterogeneous population should have higher variability in the metrics among high-quality cells, increasing the MAD and reducing the chance of incorrectly removing particular cell types (at the cost of reducing power to remove low-quality cells). In general, these assumptions are either reasonable or their violations have little effect on downstream conclusions. Nonetheless, it is helpful to keep them in mind when interpreting the results. 6.3.2.3 Considering experimental factors More complex studies may involve batches of cells generated with different experimental parameters (e.g., sequencing depth). In such cases, the adaptive strategy should be applied to each batch separately. It makes little sense to compute medians and MADs from a mixture distribution containing samples from multiple batches. For example, if the sequencing coverage is lower in one batch compared to the others, it will drag down the median and inflate the MAD. This will reduce the suitability of the adaptive threshold for the other batches. If each batch is represented by its own SingleCellExperiment, the isOutlier() function can be directly applied to each batch as shown above. However, if cells from all batches have been merged into a single SingleCellExperiment, the batch= argument should be used to ensure that outliers are identified within each batch. This allows isOutlier() to accommodate systematic differences in the QC metrics across batches. We will again illustrate using the 416B dataset, which contains two experimental factors - plate of origin and oncogene induction status. We combine these factors together and use this in the batch= argument to isOutlier() via quickCellQC(). This results in the removal of more cells as the MAD is no longer inflated by (i) systematic differences in sequencing depth between batches and (ii) differences in number of genes expressed upon oncogene induction. batch &lt;- paste0(sce.416b$phenotype, &quot;-&quot;, sce.416b$Plate) batch.reasons &lt;- quickCellQC(df, percent_subsets=c(&quot;subsets_Mito_percent&quot;, &quot;altexps_ERCC_percent&quot;), nmads=3, batch=batch) colSums(as.matrix(batch.reasons)) ## low_lib_size low_n_features ## 4 2 ## high_subsets_Mito_percent high_altexps_ERCC_percent ## 2 4 ## discard ## 7 That said, the use of batch= involves the stronger assumption that most cells in each batch are of high quality. If an entire batch failed, outlier detection will not be able to act as an appropriate QC filter for that batch. For example, two batches in the Grun et al. (2016) human pancreas dataset contain a substantial proportion of putative damaged cells with higher ERCC content than the other batches (Figure 6.1). This inflates the median and MAD within those batches, resulting in a failure to remove the assumed low-quality cells. In such cases, it is better to either not use batch= or to apply a custom filter to the problematic batches (possibly based on the thresholds for the other batches in attr(discard.ercc, &quot;thresholds&quot;)). library(scRNAseq) sce.grun &lt;- GrunPancreasData() sce.grun &lt;- addQCPerCell(sce.grun) discard.ercc &lt;- isOutlier(sce.grun$altexps_ERCC_percent, nmads=3, type=&quot;higher&quot;, batch=sce.grun$donor) plotColData(sce.grun, x=&quot;donor&quot;, y=&quot;altexps_ERCC_percent&quot;, colour_by=I(discard.ercc)) Figure 6.1: Distribution of the proportion of ERCC transcripts in each donor of the Grun pancreas dataset. Each point represents a cell and is coloured according to whether it was identified as an outlier within each batch. 6.4 Checking diagnostic plots It is good practice to inspect the distributions of QC metrics (Figure 6.2) to identify possible problems. In the most ideal case, we would see normal distributions that would justify the 3 MAD threshold used in outlier detection. A large proportion of cells in another mode suggests that the QC metrics might be correlated with some biological state, potentially leading to the loss of distinct cell types during filtering. Batches with systematically poor values for any metric can also be quickly identified for further troubleshooting or outright removal. colData(sce.416b) &lt;- cbind(colData(sce.416b), df) sce.416b$block &lt;- factor(sce.416b$block) sce.416b$phenotype &lt;- ifelse(grepl(&quot;induced&quot;, sce.416b$phenotype), &quot;induced&quot;, &quot;wild type&quot;) sce.416b$discard &lt;- reasons$discard gridExtra::grid.arrange( plotColData(sce.416b, x=&quot;block&quot;, y=&quot;sum&quot;, colour_by=&quot;phenotype&quot;, shape_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(sce.416b, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;phenotype&quot;, shape_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(sce.416b, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, shape_by=&quot;discard&quot;, colour_by=&quot;phenotype&quot;) + ggtitle(&quot;Mito percent&quot;), plotColData(sce.416b, x=&quot;block&quot;, y=&quot;altexps_ERCC_percent&quot;, shape_by=&quot;discard&quot;, colour_by=&quot;phenotype&quot;) + ggtitle(&quot;ERCC percent&quot;), nrow=2, ncol=2 ) Figure 6.2: Distribution of QC metrics for each batch in the 416B dataset. Each point represents a cell with color and shape according to its oncogene induction status and whether it was discarded, respectively. Another useful diagnostic involves plotting the proportion of mitochondrial counts against some of the other QC metrics (Figure 6.3). Here, the aim is to confirm that there are no cells with both large total counts and large mitochondrial counts, to ensure that we are not inadvertently removing high-quality cells that happen to be highly metabolically active (e.g., hepatocytes). plotColData(sce.416b, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;phenotype&quot;, shape_by=&quot;discard&quot;) + scale_x_log10() Figure 6.3: Percentage of reads assigned to mitochondrial transcripts, plotted against the library size. Comparison of the ERCC and mitochondrial percentages can also be informative (Figure 6.4). Low-quality cells with small mitochondrial percentages, large spike-in percentages and small library sizes are likely to be stripped nuclei, i.e., they have been so extensively damaged that they have lost all cytoplasmic content. Conversely, cells with high mitochondrial percentages and low ERCC percentages may represent undamaged cells that are metabolically active. plotColData(sce.416b, x=&quot;altexps_ERCC_percent&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;phenotype&quot;, shape_by=&quot;discard&quot;) Figure 6.4: Percentage of reads assigned to mitochondrial transcripts, plotted against the percentage of reads assigned to ERCC transcripts. 6.5 Marking or removal? Once low-quality cells have been identified, we can choose to either remove them or mark them. Removal is the most straightforward option and is achieved by subsetting the SingleCellExperiment by column. In this case, we use the low-quality calls from Section 6.3.2.3 to generate a subsetted SingleCellExperiment that we would use for downstream analyses. # Keeping the columns we DON&#39;T want to discard. filtered &lt;- sce.416b[,!reasons$discard] The other option is to simply mark the low-quality cells as such and retain them in the downstream analysis. The aim here is to allow clusters of low-quality cells to form, and then to identify and ignore such clusters during interpretation of the results. This approach avoids discarding cell types that have poor values for the QC metrics, giving users an opportunity to decide whether a cluster of such cells represents a genuine biological state. The downside is that it shifts the burden of QC to the interpretation of the clusters, which is already the bottleneck in scRNA-seq data analysis (Chapters 10, 29.2.8 and ??). Indeed, if we do not trust the QC metrics, we would have to distinguish between genuine cell types and low-quality cells based only on marker genes, and this is not always easy due to the tendency of the latter to “express” interesting genes (Section 6.1). Retention of low-quality cells also compromises the accuracy of the variance modelling, requiring, e.g., use of more PCs to offset the fact that the early PCs are driven by differences between low-quality and other cells. marked &lt;- sce.416b marked$discard &lt;- batch.reasons$discard For routine analyses, we suggest performing removal by default to avoid complications from low-quality cells. This allows most of the population structure to be characterized with no - or, at least, fewer - concerns about its validity. Once the initial analysis is done, and if there are any concerns about discarded cell types (Section 6.7), a more thorough re-analysis can be performed where the low-quality cells are only marked. This recovers cell types with low RNA content, high mitochondrial proportions, etc. that only need to be interpreted insofar as they “fill the gaps” in the initial analysis. 6.6 Cell calling in droplet data 6.6.1 Background An unique aspect of droplet-based data is that we have no prior knowledge about whether a particular library (i.e., cell barcode) corresponds to cell-containing or empty droplets. Thus, we need to call cells from empty droplets based on the observed expression profiles. This is not entirely straightforward as empty droplets can contain ambient (i.e., extracellular) RNA that can be captured and sequenced, resulting in non-zero counts for libraries that do not contain any cell. To demonstrate, we obtain the unfiltered count matrix for the PBMC dataset from 10X Genomics. library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) library(Matrix) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) sce.pbmc ## class: SingleCellExperiment ## dim: 33694 737280 ## metadata(1): Samples ## assays(1): counts ## rownames(33694): ENSG00000243485 ENSG00000237613 ... ## ENSG00000277475 ENSG00000268674 ## rowData names(2): ID Symbol ## colnames(737280): AAACCTGAGAAACCAT-1 AAACCTGAGAAACCGC-1 ... ## TTTGTCATCTTTAGTC-1 TTTGTCATCTTTCCTC-1 ## colData names(2): Sample Barcode ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): The distribution of total counts exhibits a sharp transition between barcodes with large and small total counts (Figure 6.5), probably corresponding to cell-containing and empty droplets respectively. A simple approach would be to apply a threshold on the total count to only retain those barcodes with large totals. However, this unnecessarily discards libraries derived from cell types with low RNA content. bcrank &lt;- barcodeRanks(counts(sce.pbmc)) # Only showing unique points for plotting speed. uniq &lt;- !duplicated(bcrank$rank) plot(bcrank$rank[uniq], bcrank$total[uniq], log=&quot;xy&quot;, xlab=&quot;Rank&quot;, ylab=&quot;Total UMI count&quot;, cex.lab=1.2) abline(h=metadata(bcrank)$inflection, col=&quot;darkgreen&quot;, lty=2) abline(h=metadata(bcrank)$knee, col=&quot;dodgerblue&quot;, lty=2) legend(&quot;bottomleft&quot;, legend=c(&quot;Inflection&quot;, &quot;Knee&quot;), col=c(&quot;darkgreen&quot;, &quot;dodgerblue&quot;), lty=2, cex=1.2) Figure 6.5: Total UMI count for each barcode in the PBMC dataset, plotted against its rank (in decreasing order of total counts). The inferred locations of the inflection and knee points are also shown. 6.6.2 Testing for empty droplets We use the emptyDrops() function to test whether the expression profile for each cell barcode is significantly different from the ambient RNA pool (Lun et al. 2019). Any significant deviation indicates that the barcode corresponds to a cell-containing droplet. This allows us to discriminate between well-sequenced empty droplets and droplets derived from cells with little RNA, both of which would have similar total counts in Figure 6.5. We call cells at a false discovery rate (FDR) of 0.1%, meaning that no more than 0.1% of our called barcodes should be empty droplets on average. set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sum(e.out$FDR &lt;= 0.001, na.rm=TRUE) ## [1] 4233 emptyDrops() computes Monte Carlo \\(p\\)-values based on a Dirichlet-multinomial model of sampling molecules into droplets. These \\(p\\)-values are stochastic so it is important to set the random seed to obtain reproducible results. The stability of the Monte Carlo \\(p\\)-values depends on the number of iterations used to compute them. This is controlled using the niters= argument in emptyDrops(), set to a default of 10000 for speed. Larger values improve stability with the only cost being that of time, so users should set niters= to the largest value they are willing to wait for. emptyDrops() assumes that libraries with total UMI counts below a certain threshold (lower=100 by default) correspond to empty droplets. These are used to estimate the ambient expression profile against which the remaining libraries are tested. Under this definition, these low-count libraries cannot be cell-containing droplets and are excluded from the hypothesis testing - hence the NAs in the output of the function. To retain only the detected cells, we subset our SingleCellExperiment object. Discerning readers will notice the use of which(), which conveniently removes the NAs prior to the subsetting. sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] 6.6.3 Examining cell-calling diagnostics The number of Monte Carlo iterations determines the lower bound for the \\(p\\)-values (Phipson and Smyth 2010). The Limited field in the output indicates whether or not the computed \\(p\\)-value for a particular barcode is bounded by the number of iterations. If any non-significant barcodes are TRUE for Limited, we may need to increase the number of iterations. A larger number of iterations will result in a lower \\(p\\)-value for these barcodes, which may allow them to be detected after correcting for multiple testing. table(Sig=e.out$FDR &lt;= 0.001, Limited=e.out$Limited) ## Limited ## Sig FALSE TRUE ## FALSE 1056 0 ## TRUE 1661 2572 As mentioned above, emptyDrops() assumes that barcodes with low total UMI counts are empty droplets. Thus, the null hypothesis should be true for all of these barcodes. We can check whether the hypothesis testing procedure holds its size by examining the distribution of \\(p\\)-values for low-total barcodes with test.ambient=TRUE. Ideally, the distribution should be close to uniform. full.data &lt;- read10xCounts(fname, col.names=TRUE) set.seed(100) limit &lt;- 100 all.out &lt;- emptyDrops(counts(full.data), lower=limit, test.ambient=TRUE) hist(all.out$PValue[all.out$Total &lt;= limit &amp; all.out$Total &gt; 0], xlab=&quot;P-value&quot;, main=&quot;&quot;, col=&quot;grey80&quot;) Figure 6.6: Distribution of \\(p\\)-values for the assumed empty droplets. Large peaks near zero indicate that barcodes with total counts below lower are not all ambient in origin. This can be resolved by decreasing lower further to ensure that barcodes corresponding to droplets with very small cells are not used to estimate the ambient profile. 6.6.4 Relationship with other QC metrics While emptyDrops() will distinguish cells from empty droplets, it makes no statement about the quality of the cells. It is entirely possible for droplets to contain damaged or dying cells, which need to be removed prior to downstream analysis. This can be done using the same outlier-based strategy described in Section 6.3.2. Filtering on the mitochondrial proportion provides the most additional benefit in this situation, provided that we check that we are not removing a subpopulation of metabolically active cells (Figure 6.7). is.mito &lt;- grep(&quot;^MT-&quot;, rowData(sce.pbmc)$Symbol) pbmc.qc &lt;- perCellQCMetrics(sce.pbmc, subsets=list(MT=is.mito)) discard.mito &lt;- isOutlier(pbmc.qc$subsets_MT_percent, type=&quot;higher&quot;, nmads=3) summary(discard.mito) ## Mode FALSE TRUE ## logical 3922 311 plot(pbmc.qc$sum, pbmc.qc$subsets_MT_percent, log=&quot;x&quot;, xlab=&quot;Total count&quot;, ylab=&#39;Mitochondrial %&#39;) Figure 6.7: Percentage of reads assigned to mitochondrial transcripts, plotted against the library size. emptyDrops() already removes cells with very low library sizes or (by association) low numbers of expressed genes. Thus, further filtering on these metrics is not strictly necessary. It may still be desirable to filter on both of these metrics to remove non-empty droplets containing cell fragments or stripped nuclei that were not caught by the mitochondrial filter. However, this should be weighed against the risk of losing genuine cell types as discussed in Section 6.3.2.2. Note that CellRanger version 3 automatically performs cell calling using an algorithm similar to emptyDrops(). If we had started our analysis with the filtered count matrix, we could go straight to computing other QC metrics. We would not need to run emptyDrops() manually as shown here, and indeed, attempting to do so would lead to nonsensical results if not outright software errors. Nonetheless, it may still be desirable to load the unfiltered matrix and apply emptyDrops() ourselves, on occasions where more detailed inspection or control of the cell-calling statistics is desired. 6.7 Checking for discarded cell types The biggest practical concern during QC is whether an entire cell type is inadvertently discarded. There is always some risk of this occurring as the QC metrics are never fully independent of biological state. We can diagnose cell type loss by looking for systematic differences in gene expression between the discarded and retained cells. To demonstrate, we compute the average count across the discarded and retained pools in the 416B data set, and we compute the log-fold change between the pool averages. lost &lt;- calculateAverage(counts(sce.416b)[,!discard]) kept &lt;- calculateAverage(counts(sce.416b)[,discard]) library(edgeR) logged &lt;- cpm(cbind(lost, kept), log=TRUE, prior.count=2) logFC &lt;- logged[,1] - logged[,2] abundance &lt;- rowMeans(logged) If the discarded pool is enriched for a certain cell type, we should observe increased expression of the corresponding marker genes. No systematic upregulation of genes is apparent in the discarded pool in Figure 6.8, suggesting that the QC step did not inadvertently filter out a cell type in the 416B dataset. plot(abundance, logFC, xlab=&quot;Average count&quot;, ylab=&quot;Log-FC (lost/kept)&quot;, pch=16) points(abundance[is.mito], logFC[is.mito], col=&quot;dodgerblue&quot;, pch=16) Figure 6.8: Log-fold change in expression in the discarded cells compared to the retained cells in the 416B dataset. Each point represents a gene with mitochondrial transcripts in blue. For comparison, let’s pretend that we applied a fixed threshold on the library size to filter cells in the PBMC data set. Specifically, we remove all libraries with a library size below 500. alt.discard &lt;- colSums(counts(sce.pbmc)) &lt; 500 lost &lt;- calculateAverage(counts(sce.pbmc)[,alt.discard]) kept &lt;- calculateAverage(counts(sce.pbmc)[,!alt.discard]) logged &lt;- edgeR::cpm(cbind(lost, kept), log=TRUE, prior.count=2) logFC &lt;- logged[,1] - logged[,2] abundance &lt;- rowMeans(logged) The presence of a distinct population in the discarded pool manifests in Figure 6.9 as a set of genes that are strongly upregulated in lost. This includes PF4, PPBP and CAVIN2, which (spoiler alert!) indicates that there is a platelet population that has been discarded by alt.discard. plot(abundance, logFC, xlab=&quot;Average count&quot;, ylab=&quot;Log-FC (lost/kept)&quot;, pch=16) platelet &lt;- c(&quot;PF4&quot;, &quot;PPBP&quot;, &quot;CAVIN2&quot;) library(org.Hs.eg.db) ids &lt;- mapIds(org.Hs.eg.db, keys=platelet, column=&quot;ENSEMBL&quot;, keytype=&quot;SYMBOL&quot;) points(abundance[ids], logFC[ids], col=&quot;orange&quot;, pch=16) Figure 6.9: Average counts across all discarded and retained cells in the PBMC dataset, after using a more stringent filter on the total UMI count. Each point represents a gene, with platelet-related genes highlighted in orange. If we suspect that cell types have been incorrectly discarded by our QC procedure, the most direct solution is to relax the QC filters. For example, outlier detection can be relaxed by increasing nmads= in the isOutlier() calls. We can also avoid filtering altogether on metrics that are associated with genuine biological differences between cell types. Of course, this increases the risk of retaining more low-quality cells and encountering the problems discussed in Section 6.1. As an aside, it is worth mentioning that the true technical quality of a cell may also be correlated with its type. (This differs from a correlation between the cell type and the QC metrics, as the latter are our imperfect proxies for quality.) This can arise if some cell types are not amenable to dissociation or microfluidics handling during the scRNA-seq protocol. In such cases, it is possible to “correctly” discard an entire cell type during QC if all of its cells are damaged. Indeed, concerns over the computational removal of cell types during QC are probably minor compared to losses in the experimental protocol. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] org.Hs.eg.db_3.8.2 edgeR_3.27.13 [3] limma_3.41.16 Matrix_1.2-17 [5] DropletUtils_1.5.8 scRNAseq_1.99.6 [7] scater_1.13.20 ggplot2_3.2.1 [9] ensembldb_2.9.6 AnnotationFilter_1.9.0 [11] GenomicFeatures_1.37.4 AnnotationDbi_1.47.1 [13] AnnotationHub_2.17.9 BiocFileCache_1.9.1 [15] dbplyr_1.4.2 SingleCellExperiment_1.7.10 [17] SummarizedExperiment_1.15.9 DelayedArray_0.11.6 [19] BiocParallel_1.19.2 matrixStats_0.55.0 [21] Biobase_2.45.1 GenomicRanges_1.37.16 [23] GenomeInfoDb_1.21.1 IRanges_2.19.16 [25] S4Vectors_0.23.23 BiocGenerics_0.31.6 [27] Cairo_1.5-10 BiocStyle_2.13.2 [29] OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] ggbeeswarm_0.6.0 colorspace_1.4-1 [3] XVector_0.25.0 BiocNeighbors_1.3.5 [5] bit64_0.9-7 interactiveDisplayBase_1.23.0 [7] R.methodsS3_1.7.1 knitr_1.25 [9] zeallot_0.1.0 Rsamtools_2.1.5 [11] R.oo_1.22.0 shiny_1.3.2 [13] HDF5Array_1.13.8 BiocManager_1.30.4 [15] compiler_3.6.1 httr_1.4.1 [17] dqrng_0.2.1 backports_1.1.4 [19] assertthat_0.2.1 lazyeval_0.2.2 [21] later_0.8.0 BiocSingular_1.1.7 [23] htmltools_0.3.6 prettyunits_1.0.2 [25] tools_3.6.1 rsvd_1.0.2 [27] gtable_0.3.0 glue_1.3.1 [29] GenomeInfoDbData_1.2.1 dplyr_0.8.3 [31] rappdirs_0.3.1 Rcpp_1.0.2 [33] vctrs_0.2.0 Biostrings_2.53.2 [35] ExperimentHub_1.11.6 rtracklayer_1.45.6 [37] DelayedMatrixStats_1.7.2 xfun_0.9 [39] stringr_1.4.0 mime_0.7 [41] irlba_2.3.3 XML_3.98-1.20 [43] zlibbioc_1.31.0 scales_1.0.0 [45] hms_0.5.1 promises_1.0.1 [47] ProtGenerics_1.17.4 rhdf5_2.29.3 [49] yaml_2.2.0 curl_4.2 [51] memoise_1.1.0 gridExtra_2.3 [53] biomaRt_2.41.8 stringi_1.4.3 [55] RSQLite_2.1.2 highr_0.8 [57] rlang_0.4.0 pkgconfig_2.0.3 [59] bitops_1.0-6 evaluate_0.14 [61] lattice_0.20-38 purrr_0.3.2 [63] Rhdf5lib_1.7.5 GenomicAlignments_1.21.7 [65] labeling_0.3 cowplot_1.0.0 [67] bit_1.1-14 tidyselect_0.2.5 [69] magrittr_1.5 bookdown_0.13 [71] R6_2.4.0 DBI_1.0.0 [73] pillar_1.4.2 withr_2.1.2 [75] RCurl_1.95-4.12 tibble_2.1.3 [77] crayon_1.3.4 rmarkdown_1.15 [79] viridis_0.5.1 progress_1.2.2 [81] locfit_1.5-9.1 grid_3.6.1 [83] blob_1.2.0 digest_0.6.21 [85] xtable_1.8-4 httpuv_1.5.2 [87] R.utils_2.9.0 openssl_1.4.1 [89] munsell_0.5.0 beeswarm_0.2.3 [91] viridisLite_0.3.0 vipor_0.4.5 [93] askpass_1.1 Bibliography "],
["normalization.html", "Chapter 7 Normalization 7.1 Motivation 7.2 Library size normalization 7.3 Normalization by deconvolution 7.4 Normalization by spike-ins 7.5 Normalizing and (log-)transforming Session Info", " Chapter 7 Normalization .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 7.1 Motivation Systematic differences in sequencing coverage between libraries are often observed in single-cell RNA sequencing data (Stegle, Teichmann, and Marioni 2015). They typically arise from technical differences in cDNA capture or PCR amplification efficiency across cells, attributable to the difficulty of achieving consistent library preparation with minimal starting material. Normalization aims to remove these differences such that they do not interfere with comparisons of the expression profiles between cells. This ensures that any observed heterogeneity or differential expression within the cell population are driven by biology and not technical biases. At this point, it is worth noting the difference between normalization and batch correction (Chapter 19.2.6). Normalization occurs regardless of the batch structure and only considers technical biases, while batch correction - as the name suggests - only occurs across batches and must consider both technical biases and biological differences. Technical biases tend to affect genes in a similar manner, or at least in a manner related to their biophysical properties (e.g., length, GC content), while biological differences between batches can be highly unpredictable. As such, these two tasks involve different assumptions and generally involve different computational methods (though some packages aim to perform both steps at once, e.g., zinbwave). Thus, it is important to avoid conflating “normalized” and “batch-corrected” data, as these usually refer to different things. We will mostly focus our attention on scaling normalization, which is the simplest and most commonly used class of normalization strategies. This involves dividing all counts for each cell by a cell-specific scaling factor, often called a “size factor” (Anders and Huber 2010). The assumption here is that any cell-specific bias (e.g., in capture or amplification efficiency) affects all genes equally via scaling of the expected mean count for that cell. The size factor for each cell represents the estimate of the relative bias in that cell, so division of its counts by its size factor should remove that bias. The resulting “normalized expression values” can then be used for downstream analyses such as clustering and dimensionality reduction. To demonstrate, we will use the Zeisel et al. (2015) dataset from the scRNAseq package. View history ### loading ### library(scRNAseq) sce.zeisel &lt;- ZeiselBrainData() sce.zeisel &lt;- sce.zeisel[rowData(sce.zeisel)$featureType!=&quot;repeat&quot;,] library(scater) sce.zeisel &lt;- aggregateAcrossFeatures(sce.zeisel, id=sub(&quot;_loc[0-9]+$&quot;, &quot;&quot;, rownames(sce.zeisel))) ### gene-annotation ### library(org.Mm.eg.db) ensembl &lt;- mapIds(org.Mm.eg.db, keys=rownames(sce.zeisel), keytype=&quot;SYMBOL&quot;, column=&quot;ENSEMBL&quot;) rowData(sce.zeisel)$ENSEMBL &lt;- ensembl ### quality-control ### stats &lt;- perCellQCMetrics(sce.zeisel, subsets=list( Mt=rowData(sce.zeisel)$featureType==&quot;mito&quot;)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;altexps_ERCC_percent&quot;, &quot;subsets_Mt_percent&quot;), nmads=3) sce.zeisel &lt;- sce.zeisel[,!qc$discard] sce.zeisel ## class: SingleCellExperiment ## dim: 19839 2816 ## metadata(0): ## assays(1): counts ## rownames(19839): 0610005C13Rik 0610007N19Rik ... mt-Tw mt-Ty ## rowData names(2): featureType ENSEMBL ## colnames(2816): 1772071015_C02 1772071017_G12 ... 1772063068_D01 ## 1772066098_A12 ## colData names(10): tissue group # ... level1class level2class ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(2): ERCC repeat 7.2 Library size normalization Library size normalization is the simplest strategy for performing scaling normalization. We define the library size as the total sum of counts across all genes for each cell. The “library size factor” for each cell is then directly proportional to its library size, where the proportionality constant is defined such that the mean size factor across all cells is equal to 1. This ensures that the normalized expression values are on the same scale as the original counts, which is useful for interpretation - especially when dealing with transformed data (see Section 7.5). library(scater) lib.sf.zeisel &lt;- librarySizeFactors(sce.zeisel) summary(lib.sf.zeisel) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.176 0.568 0.868 1.000 1.278 4.084 In the Zeisel brain data, the library size factors differ by up to 10-fold across cells (Figure 7.1). This is typical of the variability in coverage in scRNA-seq data. hist(log10(lib.sf.zeisel), xlab=&quot;Log10[Size factor]&quot;, col=&#39;grey80&#39;) Figure 7.1: Distribution of size factors derived from the library size in the Zeisel brain dataset. Strictly speaking, the use of library size factors assumes that there is no “imbalance” in the differentially expressed (DE) genes between any pair of cells. That is, any upregulation for a subset of genes is cancelled out by the same magnitude of downregulation in a different subset of genes. This ensures that the library size is an unbiased estimate of the relative cell-specific bias. (Otherwise, the estimate would be compromised by composition biases, as discussed in Robinson and Oshlack (2010).) This may not be true in scRNA-seq applications, which means that library size normalization may not yield accurate normalized expression values for downstream analyses. In practice, normalization accuracy is not a major consideration for exploratory scRNA-seq data analyses. Composition biases do not usually affect the separation of clusters, only the magnitude - and to a lesser extent, direction - of the log-fold changes between clusters or cell types. As such, library size normalization is usually sufficient in many applications where the aim is to identify clusters and the top markers that define each cluster. 7.3 Normalization by deconvolution As previously mentioned, composition biases will be present when any unbalanced differential expression exists between samples. Consider the simple example of two cells where a single gene \\(X\\) is upregulated in one cell \\(A\\) compared to the other cell \\(B\\). This upregulation means that either (i) more sequencing resources are devoted to \\(X\\) in \\(A\\), thus decreasing coverage of all other non-DE genes when the total library size of each cell is experimentally fixed (e.g., due to library quantification); or (ii) the library size of \\(A\\) increases when \\(X\\) is assigned more reads or UMIs, increasing the library size factor and yielding smaller normalized expression values for all non-DE genes. In both cases, the net effect is that non-DE genes in \\(A\\) will incorrectly appear to be downregulated compared to \\(B\\). The removal of composition biases is a well-studied problem for bulk RNA sequencing data analysis. Normalization can be performed with the estimateSizeFactorsFromMatrix() function in the DESeq2 package (Anders and Huber 2010; Love, Huber, and Anders 2014) or with the calcNormFactors() function (Robinson and Oshlack 2010) in the edgeR package. These assume that most genes are not DE between cells. Any systematic difference in count size across the non-DE majority of genes between two cells is assumed to represent bias that is used to compute an appropriate size factor for its removal. However, single-cell data can be problematic for these bulk normalization methods due to the dominance of low and zero counts. To overcome this, we pool counts from many cells to increase the size of the counts for accurate size factor estimation (Lun, Bach, and Marioni 2016). Pool-based size factors are then “deconvolved” into cell-based factors for normalization of each cell’s expression profile. This is performed using the calculateSumFactors() function from scran, as shown below. library(scran) set.seed(100) clust.zeisel &lt;- quickCluster(sce.zeisel) table(clust.zeisel) ## clust.zeisel ## 1 2 3 4 5 6 7 8 9 10 11 ## 161 194 489 451 269 153 256 226 126 270 221 deconv.sf.zeisel &lt;- calculateSumFactors(sce.zeisel, cluster=clust.zeisel) summary(deconv.sf.zeisel) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.129 0.478 0.821 1.000 1.318 4.812 We use a pre-clustering step with quickCluster() where cells in each cluster are normalized separately and the size factors are rescaled to be comparable across clusters. This avoids the assumption that most genes are non-DE across the entire population - only a non-DE majority is required between pairs of clusters, which is a weaker assumption for highly heterogeneous populations. By default, quickCluster() will use an approximate algorithm for PCA based on methods from the irlba package. The approximation relies on stochastic initialization so we need to set the random seed (via set.seed()) for reproducibility. We see that the deconvolution size factors exhibit cell type-specific deviations from the library size factors in Figure 7.2. This is consistent with the presence of composition biases that are introduced by strong differential expression between cell types. Use of the deconvolution size factors adjusts for these biases to improve normalization accuracy for downstream applications. plot(lib.sf.zeisel, deconv.sf.zeisel, xlab=&quot;Library size factor&quot;, ylab=&quot;Deconvolution size factor&quot;, log=&#39;xy&#39;, pch=16, col=as.integer(factor(sce.zeisel$level1class))) abline(a=0, b=1, col=&quot;red&quot;) Figure 7.2: Deconvolution size factor for each cell in the Zeisel brain dataset, compared to the equivalent size factor derived from the library size. The red line corresponds to identity between the two size factors. Accurate normalization is most important for procedures that involve estimation and interpretation of per-gene statistics. For example, composition biases can compromise DE analyses by systematically shifting the log-fold changes in one direction or another. However, it tends to provide less benefit over simple library size normalization for cell-based analyses such as clustering. The presence of composition biases already implies strong differences in expression profiles, so changing the normalization strategy is unlikely to affect the outcome of a clustering procedure. 7.4 Normalization by spike-ins Spike-in normalization is based on the assumption that the same amount of spike-in RNA was added to each cell (A. T. L. Lun et al. 2017). Systematic differences in the coverage of the spike-in transcripts can only be due to cell-specific biases, e.g., in capture efficiency or sequencing depth. To remove these biases, we equalize spike-in coverage across cells by scaling with “spike-in size factors”. Compared to the previous methods, spike-in normalization requires no assumption about the biology of the system (i.e., the absence of many DE genes). Instead, it assumes that the spike-in transcripts were (i) added at a constant level to each cell, and (ii) respond to biases in the same relative manner as endogenous genes. Practically, spike-in normalization should be used if differences in the total RNA content of individual cells are of interest and must be preserved in downstream analyses. For a given cell, an increase in its overall amount of endogenous RNA will not increase its spike-in size factor. This ensures that the effects of total RNA content on expression across the population will not be removed upon scaling. By comparison, the other normalization methods described above will simply interpret any change in total RNA content as part of the bias and remove it. We demonstrate the use of spike-in normalization on a different dataset involving T cell activation after stimulation with T cell recepter ligands of varying affinity (Richard et al. 2018). library(scRNAseq) sce.richard &lt;- RichardTCellData() sce.richard &lt;- sce.richard[,sce.richard$`single cell quality`==&quot;OK&quot;] sce.richard ## class: SingleCellExperiment ## dim: 46603 528 ## metadata(0): ## assays(1): counts ## rownames(46603): ENSMUSG00000102693 ENSMUSG00000064842 ... ## ENSMUSG00000096730 ENSMUSG00000095742 ## rowData names(0): ## colnames(528): SLX-12611.N701_S502. SLX-12611.N702_S502. ... ## SLX-12612.i712_i522. SLX-12612.i714_i522. ## colData names(13): age individual ... stimulus time ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(1): ERCC We apply the computeSpikeFactors() method to estimate spike-in size factors for all cells. This is defined by converting the total spike-in count per cell into a size factor, using the same reasoning as in librarySizeFactors(). Scaling will subsequently remove any differences in spike-in coverage across cells. sce.richard &lt;- computeSpikeFactors(sce.richard, &quot;ERCC&quot;) summary(sizeFactors(sce.richard)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.125 0.428 0.627 1.000 1.070 23.316 We observe a positive correlation between the spike-in size factors and deconvolution size factors within each treatment condition (Figure 7.3), indicating that they are capturing similar technical biases in sequencing depth and capture efficiency. However, we also observe that increasing stimulation of the T cell receptor - in terms of increasing affinity or time - results in a decrease in the spike-in factors relative to the library size factors. This is consistent with an increase in biosynthetic activity and total RNA content during stimulation, which reduces the relative spike-in coverage in each library (thereby decreasing the spike-in size factors) but increases the coverage of endogenous genes (thus increasing the library size factors). to.plot &lt;- data.frame( DeconvFactor=calculateSumFactors(sce.richard), SpikeFactor=sizeFactors(sce.richard), Stimulus=sce.richard$stimulus, Time=sce.richard$time ) ggplot(to.plot, aes(x=DeconvFactor, y=SpikeFactor, color=Time)) + geom_point() + facet_wrap(~Stimulus) + scale_x_log10() + scale_y_log10() + geom_abline(intercept=0, slope=1, color=&quot;red&quot;) Figure 7.3: Size factors from spike-in normalization, plotted against the library size factors for all cells in the T cell dataset. Each plot represents a different ligand treatment and each point is a cell coloured according by time from stimulation. The differences between these two sets of size factors have real consequences for downstream interpretation. If the spike-in size factors were applied to the counts, the expression values in unstimulated cells would be scaled up while expression in stimulated cells would be scaled down. However, the opposite would occur if the deconvolution size factors were used. This can manifest as shifts in the magnitude and direction of DE between conditions when we switch between normalization strategies, as shown below for Malat1 (Figure 7.4). # See below for explanation of logNormCounts(). sce.richard.deconv &lt;- logNormCounts(sce.richard, size_factors=to.plot$DeconvFactor) sce.richard.spike &lt;- logNormCounts(sce.richard, size_factors=to.plot$SpikeFactor) gridExtra::grid.arrange( plotExpression(sce.richard.deconv, x=&quot;stimulus&quot;, colour_by=&quot;time&quot;, features=&quot;ENSMUSG00000092341&quot;) + theme(axis.text.x = element_text(angle = 90)) + ggtitle(&quot;After deconvolution&quot;), plotExpression(sce.richard.spike, x=&quot;stimulus&quot;, colour_by=&quot;time&quot;, features=&quot;ENSMUSG00000092341&quot;) + theme(axis.text.x = element_text(angle = 90)) + ggtitle(&quot;After spike-in normalization&quot;), ncol=2 ) Figure 7.4: Distribution of log-normalized expression values for Malat1 after normalization with the deconvolution size factors (left) or spike-in size factors (right). Cells are stratified by the ligand affinity and colored by the time after stimulation. Whether or not total RNA content is relevant – and thus, the choice of normalization strategy – depends on the biological hypothesis. In most cases, changes in total RNA content are not interesting and can be normalized out by applying the library size or deconvolution factors. However, this may not always be appropriate if differences in total RNA are associated with a biological process of interest, e.g., cell cycle activity or T cell activation. Spike-in normalization will preserve these differences such that any changes in expression between biological groups have the correct sign. However! Regardless of whether we care about total RNA content, it is critical that the spike-in transcripts are normalized using the spike-in size factors. Size factors computed from the counts for endogenous genes should not be applied to the spike-in transcripts, precisely because the former captures differences in total RNA content that are not experienced by the latter. Attempting to normalize the spike-in counts with the gene-based size factors will lead to over-normalization and incorrect quantification. Thus, whenever spike-in data is present, we must compute a separate set of size factors for the spike-in set. This is discussed below for the Zeisel dataset. 7.5 Normalizing and (log-)transforming Once we have computed the size factors, we use the logNormCounts() function from scater to compute normalized expression values for each cell. This is done by dividing the count for each gene/spike-in transcript with the appropriate size factor for that cell. The function also log-transforms the normalized values, creating a new assay called `“logcounts”. (Technically, these are “log-transformed normalized expression values”, but that’s too much of a mouthful to fit into the assay name.) These log-values will be the basis of our downstream analyses in the following chapters. set.seed(100) clust.zeisel &lt;- quickCluster(sce.zeisel) sce.zeisel &lt;- computeSumFactors(sce.zeisel, cluster=clust.zeisel, min.mean=0.1) sce.zeisel &lt;- logNormCounts(sce.zeisel) assayNames(sce.zeisel) ## [1] &quot;counts&quot; &quot;logcounts&quot; The log-transformation is useful as differences in the log-values represent log-fold changes in expression. This is important in downstream procedures based on Euclidean distances, which includes many forms of clustering and dimensionality reduction. By operating on log-transformed data, we ensure that these procedures are measuring distances between cells based on log-fold changes in expression. Or in other words, which is more interesting - a gene that is expressed at an average count of 50 in cell type \\(A\\) and 10 in cell type \\(B\\), or a gene that is expressed at an average count of 1100 in \\(A\\) and 1000 in \\(B\\)? Log-transformation focuses on the former by promoting contributions from genes with strong relative differences. When log-transforming, we need to consider the pseudo-count that is added to avoid undefined values at zero. Larger pseudo-counts will effectively shrink the log-fold changes between cells towards zero for low-abundance genes, meaning that downstream analyses will be driven more by differences in expression for high-abundance genes. Conversely, smaller pseudo-counts will increase the contribution of low-abundance genes. Common practice is to use a pseudo-count of 1, for the simple pragmatic reason that it preserves sparsity in the original matrix (i.e., zeroes in the input remain zeroes after transformation). This works well in all but the most pathological scenarios (A. Lun 2018). (Incidentally, the addition of the pseudo-count is the motivation for the centering of the size factors at unity. This ensures that both the pseudo-count and the normalized expression values are on the same scale. A pseudo-count of 1 can then be interpreted as an extra read or UMI for each gene. In practical terms, this means that the shrinkage effect of the pseudo-count diminishes as sequencing depth improves. This is the correct behavior as it allows log-fold change estimates to become increasingly accurate with deeper coverage. In contrast, if we had simply divided each cell’s counts by its library size before log-transformation, accuracy of the log-fold changes would never improve regardless of how much additional sequencing we performed.) Of course, log-transformation is not the only possible transformation. More sophisticated approaches can be used such as dedicated variance stabilizing transformations (e.g., from the DESeq2 or sctransform packages), which out-perform the log-transformation for removal of the mean-variance trend. In practice, though, the log-transformation is a good default choice due its simplicity (a.k.a., reliability, predictability and computational efficiency) and interpretability. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] scRNAseq_1.99.6 scran_1.13.25 [3] scater_1.13.20 ggplot2_3.2.1 [5] SingleCellExperiment_1.7.10 SummarizedExperiment_1.15.9 [7] DelayedArray_0.11.6 BiocParallel_1.19.2 [9] matrixStats_0.55.0 Biobase_2.45.1 [11] GenomicRanges_1.37.16 GenomeInfoDb_1.21.1 [13] IRanges_2.19.16 S4Vectors_0.23.23 [15] BiocGenerics_0.31.6 Cairo_1.5-10 [17] BiocStyle_2.13.2 OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] bitops_1.0-6 bit64_0.9-7 [3] httr_1.4.1 tools_3.6.1 [5] backports_1.1.4 R6_2.4.0 [7] irlba_2.3.3 vipor_0.4.5 [9] DBI_1.0.0 lazyeval_0.2.2 [11] colorspace_1.4-1 withr_2.1.2 [13] tidyselect_0.2.5 gridExtra_2.3 [15] curl_4.2 bit_1.1-14 [17] compiler_3.6.1 BiocNeighbors_1.3.5 [19] labeling_0.3 bookdown_0.13 [21] scales_1.0.0 rappdirs_0.3.1 [23] stringr_1.4.0 digest_0.6.21 [25] rmarkdown_1.15 XVector_0.25.0 [27] pkgconfig_2.0.3 htmltools_0.3.6 [29] dbplyr_1.4.2 limma_3.41.16 [31] highr_0.8 rlang_0.4.0 [33] RSQLite_2.1.2 shiny_1.3.2 [35] DelayedMatrixStats_1.7.2 dplyr_0.8.3 [37] RCurl_1.95-4.12 magrittr_1.5 [39] BiocSingular_1.1.7 GenomeInfoDbData_1.2.1 [41] Matrix_1.2-17 Rcpp_1.0.2 [43] ggbeeswarm_0.6.0 munsell_0.5.0 [45] viridis_0.5.1 stringi_1.4.3 [47] yaml_2.2.0 edgeR_3.27.13 [49] zlibbioc_1.31.0 BiocFileCache_1.9.1 [51] AnnotationHub_2.17.9 grid_3.6.1 [53] blob_1.2.0 promises_1.0.1 [55] dqrng_0.2.1 ExperimentHub_1.11.6 [57] crayon_1.3.4 lattice_0.20-38 [59] cowplot_1.0.0 locfit_1.5-9.1 [61] zeallot_0.1.0 knitr_1.25 [63] pillar_1.4.2 igraph_1.2.4.1 [65] glue_1.3.1 evaluate_0.14 [67] BiocManager_1.30.4 httpuv_1.5.2 [69] vctrs_0.2.0 gtable_0.3.0 [71] purrr_0.3.2 assertthat_0.2.1 [73] xfun_0.9 mime_0.7 [75] rsvd_1.0.2 xtable_1.8-4 [77] later_0.8.0 viridisLite_0.3.0 [79] tibble_2.1.3 AnnotationDbi_1.47.1 [81] beeswarm_0.2.3 memoise_1.1.0 [83] statmod_1.4.32 interactiveDisplayBase_1.23.0 Bibliography "],
["feature-selection.html", "Chapter 8 Feature selection 8.1 Motivation 8.2 Quantifying per-gene variation 8.3 Selecting highly variable genes 8.4 Putting it all together Session Info", " Chapter 8 Feature selection .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 8.1 Motivation We often use scRNA-seq data in exploratory analyses to characterize heterogeneity across cells. Procedures like clustering and dimensionality reduction compare cells based on their gene expression profiles, which involves aggregating per-gene differences into a single (dis)similarity metric between a pair of cells. The choice of genes to use in this calculation has a major impact on the behavior of the metric and the performance of downstream methods. We want to select genes that contain useful information about the biology of the system while removing genes that contain random noise. This aims to preserve interesting biological structure without the variance that obscures that structure. It also reduces the size of the dataset to improve computational efficiency of later steps. The simplest approach to feature selection is to select the most variable genes based on their expression across the population. This assumes that genuine biological differences will manifest as increased variation in the affected genes, compared to other genes that are only affected by technical noise or a baseline level of “uninteresting” biological variation (e.g., from transcriptional bursting). Several methods are available to quantify the variation per gene and to select the highly variable genes (HVGs), which we will discuss below. For demonstration, we will use the 10X PBMC dataset: View history ### loading ### library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) ### gene-annotation ### library(scater) rownames(sce.pbmc) &lt;- uniquifyFeatureNames( rowData(sce.pbmc)$ID, rowData(sce.pbmc)$Symbol) library(EnsDb.Hsapiens.v86) location &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce.pbmc)$ID, column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) ### cell-detection ### set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] ### quality-control ### stats &lt;- perCellQCMetrics(sce.pbmc, subsets=list(Mito=which(location==&quot;MT&quot;))) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) sce.pbmc &lt;- sce.pbmc[,!high.mito] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.pbmc) sce.pbmc &lt;- computeSumFactors(sce.pbmc, cluster=clusters) sce.pbmc &lt;- logNormCounts(sce.pbmc) sce.pbmc ## class: SingleCellExperiment ## dim: 33694 3922 ## metadata(1): Samples ## assays(2): counts logcounts ## rownames(33694): RP11-34P13.3 FAM138A ... AC213203.1 FAM231B ## rowData names(2): ID Symbol ## colnames(3922): AAACCTGAGAAGGCCT-1 AAACCTGAGACAGACC-1 ... ## TTTGTCACAGGTCCAC-1 TTTGTCATCCCAAGAT-1 ## colData names(2): Sample Barcode ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): As well as the 416B dataset: View history ### loading ### library(scRNAseq) sce.416b &lt;- LunSpikeInData(which=&quot;416b&quot;) sce.416b$block &lt;- factor(sce.416b$block) ### gene-annotation ### library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] rowData(sce.416b)$ENSEMBL &lt;- rownames(sce.416b) rowData(sce.416b)$SYMBOL &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SYMBOL&quot;) rowData(sce.416b)$SEQNAME &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) library(scater) rownames(sce.416b) &lt;- uniquifyFeatureNames(rowData(sce.416b)$ENSEMBL, rowData(sce.416b)$SYMBOL) ### quality-control ### mito &lt;- which(rowData(sce.416b)$SEQNAME==&quot;MT&quot;) stats &lt;- perCellQCMetrics(sce.416b, subsets=list(Mt=mito)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;subsets_Mt_percent&quot;, &quot;altexps_ERCC_percent&quot;), nmads=3, batch=sce.416b$block) sce.416b &lt;- sce.416b[,!qc$discard] ### normalization ### library(scran) sce.416b &lt;- computeSumFactors(sce.416b) sce.416b &lt;- logNormCounts(sce.416b) sce.416b ## class: SingleCellExperiment ## dim: 46604 185 ## metadata(0): ## assays(2): counts logcounts ## rownames(46604): 4933401J01Rik Gm26206 ... CAAA01147332.1 ## CBFB-MYH11-mcherry ## rowData names(4): Length ENSEMBL SYMBOL SEQNAME ## colnames(185): SLX-9555.N701_S502.C89V9ANXX.s_1.r_1 ## SLX-9555.N701_S503.C89V9ANXX.s_1.r_1 ... ## SLX-11312.N712_S507.H5H5YBBXX.s_8.r_1 ## SLX-11312.N712_S517.H5H5YBBXX.s_8.r_1 ## colData names(9): Source Name cell line ... spike-in addition ## block ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(2): ERCC SIRV 8.2 Quantifying per-gene variation 8.2.1 Variance of the log-counts The simplest approach to quantifying per-gene variation is to simply compute the variance of the log-normalized expression values (referred to as “log-counts” for simplicity) for each gene across all cells in the population (A. T. L. Lun, McCarthy, and Marioni 2016). This has an advantage in that the feature selection is based on the same log-values that are used for later downstream steps. Genes with the largest variances in log-values will contribute the most to the Euclidean distances between cells. By using log-values here, we ensure that our quantitative definition of heterogeneity is consistent throughout the entire analysis. Calculation of the per-gene variance is simple but feature selection requires modelling of the mean-variance relationship. As discussed briefly in the last chapter, the log-transformation does not achieve perfect variance stabilization. This means that the variance of a gene is more affected by its abundance than the underlying biological heterogeneity. To account for this effect, we use the modelGeneVar() function to fit a trend to the variance with respect to abundance across all genes (Figure 8.1). library(scran) dec.pbmc &lt;- modelGeneVar(sce.pbmc) # Visualizing the fit: fit.pbmc &lt;- metadata(dec.pbmc) plot(fit.pbmc$mean, fit.pbmc$var, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curve(fit.pbmc$trend(x), col=&quot;dodgerblue&quot;, add=TRUE, lwd=2) Figure 8.1: Variance in the PBMC data set as a function of the mean. Each point represents a gene while the blue line represents the trend fitted to all genes. At any given abundance, we assume that the expression profiles of most genes are dominated by random technical noise (see 8.2.3 for details). Under this assumption, our trend represents an estimate of the technical noise as a function of abundance. We then break down the total variance of each gene into the technical component, i.e., the fitted value of the trend at that gene’s abundance; and the biological component, defined as the difference between the total variance and the technical component. This biological component represents the “interesting” variation for each gene and can be used as the metric for HVG selection. # Ordering by most interesting genes for inspection. dec.pbmc[order(dec.pbmc$bio, decreasing=TRUE),] ## DataFrame with 33694 rows and 6 columns ## mean total tech ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## LYZ 1.97720774557909 5.1093189779025 0.829103127339641 ## S100A9 1.94951728004377 4.58067979752237 0.829355453833642 ## S100A8 1.71813080049067 4.45055534363201 0.821139887638155 ## HLA-DRA 2.09809035649378 3.73632552542341 0.825379685977392 ## CD74 2.89964299605066 3.32217806233448 0.794847540253829 ## ... ... ... ... ## PTMA 3.83104778025389 0.473973817102769 0.742787426970617 ## HLA-B 4.50257580785005 0.477758219250799 0.758429131374342 ## EIF1 3.24339798459787 0.47749233228004 0.773251495255292 ## TMSB4X 6.08574497419255 0.405491648922873 0.748371851921361 ## B2M 5.95574224289044 0.3039647664231 0.720380624981018 ## bio p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## LYZ 4.28021585056286 1.21236560942303e-263 1.19114921125812e-259 ## S100A9 3.75132434368872 5.94533311061492e-203 3.89419318745278e-199 ## S100A8 3.62941545599385 6.64673132537092e-194 3.26520676358846e-190 ## HLA-DRA 2.91094583944602 2.66256736867182e-124 4.02457298418472e-121 ## CD74 2.52733052208066 1.85532049884549e-101 1.73604989534828e-98 ## ... ... ... ... ## PTMA -0.268813609867848 0.992456096325914 0.999999999334435 ## HLA-B -0.280670912123543 0.993524806169525 0.999999999334435 ## EIF1 -0.295759162975252 0.994893424392943 0.999999999334435 ## TMSB4X -0.342880202998488 0.998953636189745 0.999999999334435 ## B2M -0.416415858557918 0.999948154865494 0.999999999334435 (Careful readers will notice that some genes have negative biological components. Negative components of variation have no obvious interpretation and can be ignored for most applications. They are inevitable when fitting a trend to the per-gene variances, as approximately half of the genes will lie below the trend.) 8.2.2 Coefficient of variation An alternative approach to quantification uses the squared coefficient of variation (CV2) of the normalized expression values prior to log-transformation. The CV2 is a widely used metric for describing variation in non-negative data and is closely related to the dispersion parameter of the negative binomial distribution in packages like edgeR and DESeq2. We compute the CV2 for each gene in the PBMC dataset using the modelGeneCV2() function, which provides a robust implementation of the approach described by Brennecke et al. (2013). dec.cv2.pbmc &lt;- modelGeneCV2(sce.pbmc) This allows us to model the mean-variance relationship when considering the relevance of each gene (Figure 8.2). Again, our assumption is that most genes contain random noise and that the trend captures mostly technical variation. Large CV\\(^2\\) values that deviate strongly from the trend are likely to represent genes affected by biological structure. fit.cv2.pbmc &lt;- metadata(dec.cv2.pbmc) plot(fit.cv2.pbmc$mean, fit.cv2.pbmc$cv2, log=&quot;xy&quot;) curve(fit.cv2.pbmc$trend(x), col=&quot;dodgerblue&quot;, add=TRUE, lwd=2) Figure 8.2: CV2 in the PBMC data set as a function of the mean. Each point represents a gene while the blue line represents the fitted trend. For each gene, we quantify the deviation from the trend in terms of the ratio of its CV2 to the fitted value of trend at its abundance. This is more appropriate than the directly subtracting the trend from the CV2, as the magnitude of the ratio is not affected by the mean. dec.cv2.pbmc[order(dec.cv2.pbmc$ratio, decreasing=TRUE),] ## DataFrame with 33694 rows and 5 columns ## mean total trend ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## HIST1H2AC 0.903832087554492 267.529464650432 1.5624934717354 ## GNG11 0.689915788093486 219.246474356749 1.98426985647823 ## PRTFDC1 0.0411712190890846 3039.89950832652 30.0648545663972 ## TNNC2 0.102005431273827 1211.4778002681 12.255298794817 ## PF4 1.1070844889201 128.819231749223 1.31275273667162 ## ... ... ... ... ## AC023491.2 0 NaN Inf ## AC233755.2 0 NaN Inf ## AC233755.1 0 NaN Inf ## AC213203.1 0 NaN Inf ## FAM231B 0 NaN Inf ## ratio p.value ## &lt;numeric&gt; &lt;numeric&gt; ## HIST1H2AC 171.219572746948 0 ## GNG11 110.492266785667 0 ## PRTFDC1 101.11139907938 0 ## TNNC2 98.8533874653847 0 ## PF4 98.1290902320522 0 ## ... ... ... ## AC023491.2 NaN NaN ## AC233755.2 NaN NaN ## AC233755.1 NaN NaN ## AC213203.1 NaN NaN ## FAM231B NaN NaN Both the CV2 and the variance of log-counts are effective metrics for quantifying variation in gene expression. The CV2 tends to give higher rank to low-abundance HVGs driven by upregulation in rare subpopulations, for which the increase in variance on the raw scale is stronger than that on the log-scale. However, the variation described by the CV2 is less directly relevant to downstream procedures operating on the log-counts, and the reliance on the ratio can assign high rank to uninteresting genes with low absolute variance. We generally prefer the use of the variance of log-counts and will use it in the following sections, though the many of the same principles apply to procedures based on the CV2. 8.2.3 Quantifying technical noise Strictly speaking, the use of a trend fitted to endogenous genes assumes that the expression profiles of most genes are dominated by random technical noise. In practice, all expressed genes will exhibit some non-zero level of biological variability due to events like transcriptional bursting. This suggests that our estimates of the technical component are likely to be inflated. It would be more appropriate to consider these estimates as technical noise plus “uninteresting” biological variation, under the assumption that most genes are unaffected by the relevant heterogeneity in the population. This revised assumption is generally reasonable but may be problematic in some scenarios where many genes at a particular abundance are affected by a biological process. For example, strong upregulation of cell type-specific genes may result in an enrichment of HVGs at high abundances. This would inflate the fitted trend in that abundance interval and compromise the detection of the relevant genes. We can avoid this problem by fitting a mean-dependent trend to the variance of the spike-in transcripts, if they are available (Figure 8.3). The premise here is that spike-ins should not be affected by biological variation, so the fitted value of the spike-in trend should represent a better estimate of the technical component for each gene. dec.spike.416b &lt;- modelGeneVarWithSpikes(sce.416b, &quot;ERCC&quot;) dec.spike.416b[order(dec.spike.416b$bio, decreasing=TRUE),] ## DataFrame with 46604 rows and 6 columns ## mean total tech ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Lyz2 6.61096803891878 13.8497201762179 1.57130530159628 ## Ccl9 6.67845998360554 13.1869005745724 1.50034784951575 ## Top2a 5.81023942468506 14.1787245984925 2.54775542207223 ## Cd200r3 4.83179821635761 15.5612599938701 4.22984247867865 ## Ccnb2 5.97776034107469 13.1392817339087 2.30176764474006 ## ... ... ... ... ## Rpl5-ps2 3.60625401733281 0.612623344818866 6.32852660729456 ## Gm11942 3.38767658515201 0.798570319939665 6.51473011137326 ## Gm12816 2.91276213414496 0.83866968433397 6.57363560699119 ## Gm13623 2.72843841213055 0.708071335002565 6.45448378131385 ## Rps12l1 3.15419890541469 0.746615468755298 6.593316320265 ## bio p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Lyz2 12.2784148746216 1.48992982137285e-186 1.54155912866129e-183 ## Ccl9 11.6865527250566 2.21855297819158e-185 2.19978771758437e-182 ## Top2a 11.6309691764202 3.80015396614872e-65 1.13040329915551e-62 ## Cd200r3 11.3314175151915 9.4622094003004e-24 6.08573505672834e-22 ## Ccnb2 10.8375140891687 3.68706024719105e-69 1.20193113290966e-66 ## ... ... ... ... ## Rpl5-ps2 -5.71590326247569 0.999616247009411 0.999726145748132 ## Gm11942 -5.7161597914336 0.999458916367196 0.999726145748132 ## Gm12816 -5.73496592265722 0.999422192516362 0.999726145748132 ## Gm13623 -5.74641244631128 0.99954376258778 0.999726145748132 ## Rps12l1 -5.8467008515097 0.999521783342308 0.999726145748132 plot(dec.spike.416b$mean, dec.spike.416b$total, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) fit.spike.416b &lt;- metadata(dec.spike.416b) points(fit.spike.416b$mean, fit.spike.416b$var, col=&quot;red&quot;, pch=16) curve(fit.spike.416b$trend(x), col=&quot;dodgerblue&quot;, add=TRUE, lwd=2) Figure 8.3: Variance in the 416B data set as a function of the mean. Each point represents a gene (black) or spike-in transcript (red) and the blue line represents the trend fitted to all spike-ins. In the absence of spike-in data, one can attempt to create a trend by making some distributional assumptions about the noise. For example, UMI counts typically exhibit near-Poisson variation if we only consider technical noise from library preparation and sequencing. This can be used to construct a mean-variance trend in the log-counts (Figure 8.4) with the modelGeneVarByPoisson() function. Note the increased residuals of the high-abundance genes, which can be interpreted as the amount of biological variation that was assumed to be “uninteresting” when fitting the gene-based trend in Figure 8.1. set.seed(0010101) dec.pois.pbmc &lt;- modelGeneVarByPoisson(sce.pbmc) dec.pois.pbmc &lt;- dec.pois.pbmc[order(dec.pois.pbmc$bio, decreasing=TRUE),] head(dec.pois.pbmc) ## DataFrame with 6 rows and 6 columns ## mean total tech ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## LYZ 1.97720774557909 5.1093189779025 0.625920315506784 ## S100A9 1.94951728004377 4.58067979752237 0.631472547598291 ## S100A8 1.71813080049067 4.45055534363201 0.672535358554566 ## HLA-DRA 2.09809035649378 3.73632552542341 0.600680256888961 ## CD74 2.89964299605066 3.32217806233448 0.425592152366567 ## CST3 1.4921009978511 2.9688331724004 0.697923385536007 ## bio p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## LYZ 4.48339866239571 0 0 ## S100A9 3.94920724992408 0 0 ## S100A8 3.77801998507744 0 0 ## HLA-DRA 3.13564526853445 0 0 ## CD74 2.89658590996792 0 0 ## CST3 2.27090978686439 0 0 plot(dec.pois.pbmc$mean, dec.pois.pbmc$total, pch=16, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curve(metadata(dec.pois.pbmc)$trend(x), col=&quot;dodgerblue&quot;, add=TRUE) Figure 8.4: Variance of normalized log-expression values for each gene in the PBMC dataset, plotted against the mean log-expression. The blue line represents represents the mean-variance relationship corresponding to Poisson noise. Interestingly, trends based purely on technical noise tend to yield large biological components for highly-expressed genes. This often includes so-called “house-keeping” genes coding for essential cellular components such as ribosomal proteins, which are considered uninteresting for characterizing cellular heterogeneity. These observations suggest that a more accurate noise model does not necessarily yield a better ranking of HVGs, though one should keep an open mind - house-keeping genes are regularly DE in a variety of conditions (Glare et al. 2002; Nazari, Parham, and Maleki 2015; Guimaraes and Zavolan 2016), and the fact that they have large biological components indicates that there is strong variation across cells that may not be completely irrelevant. 8.2.4 Accounting for blocking factors 8.2.4.1 Fitting block-specific trends Data containing multiple batches will often exhibit batch effects (see Chapter 19.2.6 for more details). We are (usually) not interested in HVGs that are driven by batch effects. Rather, we want to focus on genes that are highly variable within each batch. This is naturally achieved by performing trend fitting and variance decomposition separately for each batch. We demonstrate this approach by treating each plate (block) in the 416B dataset as a different batch, using the modelGeneVarWithSpikes() function. (The same argument is available in all other variance-modelling functions.) dec.block.416b &lt;- modelGeneVarWithSpikes(sce.416b, &quot;ERCC&quot;, block=sce.416b$block) head(dec.block.416b[order(dec.block.416b$bio, decreasing=TRUE),1:6]) ## DataFrame with 6 rows and 6 columns ## mean total tech ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Lyz2 6.61235092956153 13.8618988024144 1.58416440878876 ## Ccl9 6.67841214065115 13.2598761518269 1.44553397965825 ## Top2a 5.81274666129111 14.0191605357462 2.74571164328693 ## Cd200r3 4.83305175110888 15.5908569933105 4.31892122926251 ## Ccnb2 5.97999269432625 13.0256084334992 2.46646680409343 ## Hbb-bt 4.91682531222784 14.6538670496416 4.12156477107562 ## bio p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Lyz2 12.2777343936257 0 0 ## Ccl9 11.8143421721686 0 0 ## Top2a 11.2734488924592 3.89854825869685e-137 8.43397753747354e-135 ## Cd200r3 11.271935764048 1.17783174428153e-54 7.00721550466689e-53 ## Ccnb2 10.5591416294057 1.20380000061177e-151 2.98404464734982e-149 ## Hbb-bt 10.532302278566 2.5263862540857e-49 1.34197351983209e-47 The use of a batch-specific trend fit is useful as it accommodates differences in the mean-variance trends between batches. This is especially important if batches exhibit systematic technical differences, e.g., differences in coverage or in the amount of spike-in RNA added. In this case, there are only minor differences between the trends in Figure 8.5, which indicates that the experiment was tightly replicated across plates. The analysis of each plate yields estimates of the biological and technical components for each gene, which are averaged across plates to take advantage of information from multiple batches. par(mfrow=c(1,2)) blocked.stats &lt;- dec.block.416b$per.block for (i in colnames(blocked.stats)) { current &lt;- blocked.stats[[i]] plot(current$mean, current$total, main=i, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(current) points(curfit$mean, curfit$var, col=&quot;red&quot;, pch=16) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) } Figure 8.5: Variance in the 416B data set as a function of the mean after blocking on the plate of origin. Each plot represents the results for a single plate, each point represents a gene (black) or spike-in transcript (red) and the blue line represents the trend fitted to all spike-ins. As an aside, the wave-like shape observed above is typical of the mean-variance trend for log-expression values. (The same wave is present but much less pronounced for UMI data.) A linear increase in the variance is observed as the mean increases from zero, as larger variances are obviously possible when the counts are not all zero. The peak in the variance usually occurs close to the mean at which 50% of observations are zero, attributable to the fact that any fold change between cells corresponds to the largest difference in log-space when one of the observations is zero. At very high abundances, the effect of sampling noise decreases due to the law of large numbers, resulting in a decrease in the variance. 8.2.4.2 Using a design matrix The use of block-specific trends is the recommended approach for experiments with a single blocking factor. However, this is not practical for studies involving a large number of blocking factors and/or covariates. In such cases, we can use the design= argument to specify a design matrix with uninteresting factors of variation. We illustrate again with the 416B data set, blocking on the plate of origin and oncogene induction. (The same argument is available in modelGeneVar() when spike-ins are not available.) design &lt;- model.matrix(~factor(block) + phenotype, colData(sce.416b)) dec.design.416b &lt;- modelGeneVarWithSpikes(sce.416b, &quot;ERCC&quot;, design=design) dec.design.416b[order(dec.design.416b$bio, decreasing=TRUE),] ## DataFrame with 46604 rows and 6 columns ## mean total tech ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Lyz2 6.61096803891878 8.90512635193215 1.50405193582095 ## Ccnb2 5.97776034107469 9.54372612545439 2.24180423717101 ## Gem 5.90224546535998 9.54358133115793 2.35175324142717 ## Cenpa 5.81348980307671 8.65621880001792 2.48791803297 ## Idh1 5.99343230026856 8.32112833403297 2.21964586481642 ## ... ... ... ... ## Gm5054 2.90433859612123 0.463698403028673 6.76999876266688 ## Gm12191 3.55920216241565 0.170709357430238 6.53284597878746 ## Gm7429 3.45394451046348 0.248350912621566 6.63457982170964 ## Gm16378 2.83987048016898 0.208215208521281 6.74662681328272 ## Rps2-ps2 3.11324156219337 0.202307294410046 6.78483536857142 ## bio p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Lyz2 7.40107441611121 1.78185058463941e-172 1.28493025341406e-169 ## Ccnb2 7.30192188828338 7.77223320238053e-77 1.44496744935195e-74 ## Gem 7.19182808973075 5.49586828733217e-68 8.12330295861141e-66 ## Cenpa 6.16830076704792 2.08034584949453e-45 1.52796265988954e-43 ## Idh1 6.10148246921656 2.42818909044647e-55 2.41772450984748e-53 ## ... ... ... ... ## Gm5054 -6.30630035963821 0.999999940536335 0.999999984861416 ## Gm12191 -6.36213662135722 0.999999984522185 0.999999984861416 ## Gm7429 -6.38622890908807 0.999999977712902 0.999999984861416 ## Gm16378 -6.53841160476144 0.999999981961201 0.999999984861416 ## Rps2-ps2 -6.58252807416138 0.99999998255976 0.999999984861416 This strategy is simple but somewhat inaccurate as it does not consider the mean expression in each blocking level. Recall that the technical component is estimated as the fitted value of the trend at the average abundance for each gene. However, the true technical component is the average of the fitted values at the per-block means, which may be quite different for strong batch effects and non-linear mean-variance relationships. The block= approach is safer and should be preferred in all situations where it is applicable. 8.3 Selecting highly variable genes 8.3.1 Overview Once we have quantified the per-gene variation, the next step is to select the subset of HVGs to use in downstream analyses. A larger subset will reduce the risk of discarding interesting biological signal by retaining more potentially relevant genes, at the cost of increasing noise from irrelevant genes that might obscure said signal. It is difficult to determine the optimal trade-off for any given application as noise in one context may be useful signal in another. For example, heterogeneity in T cell activation responses is an interesting phenomena (Richard et al. 2018) but may be irrelevant noise in studies that only care about distinguishing the major immunophenotypes. That said, there are several common strategies that are routinely used to guide HVG selection, which we shall discuss here. 8.3.2 Based on the largest metrics The simplest HVG selection strategy is to take the top \\(X\\) genes with the largest values for the relevant variance metric. The main advantage of this approach is that the user can directly control the number of genes retained, which ensures that the computational complexity of downstream calculations is easily predicted. For modelGeneVar() and modelGeneVarWithSpikes(), we would select the genes with the largest biological components: # Setting X = 1000 here. hvg.pbmc.var &lt;- head(order(dec.pbmc$bio, decreasing=TRUE), 1000) hvg.pbmc.var &lt;- rownames(dec.pbmc)[hvg.pbmc.var] For modelGeneCV2() (and its relative, modelGeneCV2WithSpikes()), this would instead be the genes with the largest ratios: hvg.pbmc.cv2 &lt;- head(order(dec.cv2.pbmc$ratio, decreasing=TRUE), 1000) hvg.pbmc.cv2 &lt;- rownames(dec.pbmc)[hvg.pbmc.cv2] The choice of \\(X\\) also has a fairly straightforward biological interpretation. Recall our trend-fitting assumption that most genes are not differentially expressed between cell types or states in our population. If we quantify this assumption into a statement that, e.g., no more than 5% of genes are differentially expressed, we can naturally set \\(X\\) to 5% of the number of genes. In practice, we usually do not know the proportion of DE genes beforehand so this interpretation just exchanges one unknown for another. Nonetheless, it is still useful as it implies that we should lower \\(X\\) for less heterogeneous datasets, retaining most of the biological signal without unnecessary noise from irrelevant genes. Conversely, more heterogeneous datasets should use larger values of \\(X\\) to preserve secondary factors of variation beyond those driving the most obvious HVGs. The main disadvantage of this approach that it turns HVG selection into a competition between genes, whereby a subset of very highly variable genes can push other informative genes out of the top set. This can be problematic for analyses of highly heterogeneous populations, especially when a single subpopulation is very different from the others. In such cases, the top set will be dominated by differentially expressed genes involving the outlier subpopulation, compromising resolution of heterogeneity between the other populations. (This can salvaged with a nested analysis, as discussed in Section 10.6, but we would prefer to avoid the problem in the first place.) Similarly, abundance-dependent changes in the magnitude of the chosen variance metric can introduce unexpected biases in competitive gene selection. For example, the wave shape in Figure 8.5 means that the largest biological components usually occur around the peak and will be preferentially selected, while an upper bound on the CV2 discriminates against selection of low-abundance genes. Another possible concern with this approach is the fact that the choice of \\(X\\) is fairly arbitrary, with any value from 500 to 5000 considered “reasonable”. We have chosen \\(X=1000\\) in the code above though there is no particular a priori reason for doing so. Our recommendation is to simply pick an arbitrary \\(X\\) and proceed with the rest of the analysis, with the intention of testing other choices later, rather than spending much time worrying about obtaining the “optimal” value. 8.3.3 Based on a fixed threshold Another approach to feature selection is to set a fixed threshold of one of the metrics. This is most commonly done with the (adjusted) \\(p\\)-value reported by each of the above methods. The \\(p\\)-value for each gene is generated by testing against the null hypothesis that the variance is equal to the trend. For example, we might define our HVGs as all genes that have adjusted \\(p\\)-values below 0.05. # &#39;which()&#39; automatically removes &#39;NA&#39; FDR values. hvg.pbmc.var.2 &lt;- rownames(dec.pbmc)[which(dec.pbmc$FDR &lt;= 0.05)] length(hvg.pbmc.var.2) ## [1] 642 This approach is simple to implement and - if the test holds its size - it controls the false discovery rate (FDR). That is, it returns a subset of genes where the proportion of false positives is expected to be below the specified threshold. This can occasionally be useful in applications where the HVGs themselves are of interest. For example, if we were to use the list of HVGs in further experiments to verify the existence of heterogeneous expression for some of the genes, we would want to control the FDR in that list. The downside of this approach is that it is less predictable than the top \\(X\\) strategy. The number of genes returned depends on the type II error rate of the test and the severity of the multiple testing correction. One might obtain no genes or every gene at a given FDR threshold, depending on the circumstances. Moreover, control of the FDR is usually not helpful at this stage of the analysis. We are not interpreting the individual HVGs themselves but are only using them for feature selection prior to downstream steps. There is no reason to think that a 5% threshold on the FDR yields a more suitable compromise between bias and noise. Alternatively, we might consider ranking genes by the \\(p\\)-value instead of the biological component for use in a top \\(X\\) approach. This results in some counterintuitive behavior due to the nature of the underlying hypothesis test, which is based on the ratio of the total variance to the expected technical variance. Ranking based on \\(p\\)-value tends to prioritize HVGs that are more likely to be true positives but, at the same time, less likely to be biologically interesting. Many of the largest ratios are observed in high-abundance genes and are driven by very low technical variance; the total variance is typically modest for such genes, and they do not contribute much to population heterogeneity in absolute terms. (Note that the same can be said of the ratio of CV2 values, as briefly discussed above.) 8.3.4 Keeping all genes above the trend As the title suggests, this involves keeping all genes above the trend. The rationale is to only remove the obviously uninteresting genes with variances below the trend. By doing so, we avoid the need to make any judgement calls regarding what level of variation is interesting enough to retain. This approach represents one extreme of the bias-variance trade-off where bias is minimized at the cost of maximizing noise. For modelGeneVar(), it equates to keeping all positive biological components: hvg.pbmc.var.3 &lt;- rownames(dec.pbmc)[dec.pbmc$bio &gt; 0] length(hvg.pbmc.var.3) ## [1] 12775 For modelGeneCV2(), this involves keeping all ratios above 1: # &#39;which()&#39; automatically removes &#39;NA&#39; ratios. hvg.pbmc.cv2.3 &lt;- rownames(dec.cv2.pbmc)[which(dec.cv2.pbmc$ratio &gt; 1)] length(hvg.pbmc.cv2.3) ## [1] 9390 This strategy is the most conservative as it does not discard any potential biological signal. Weak or secondary population structure is given the chance to manifest as the affected genes are retained. This makes it useful for reliable automated processing of diverse data sets where the primary factor of variation in one data set might be a secondary factor in another data set (and thus overlooked by the top \\(X\\) approach with a fixed value for \\(X\\)). The obvious cost is that more noise is also captured, which can reduce the resolution of otherwise well-separated populations. From a practical perspective, the use of more genes involves more computational work in each downstream step. 8.3.5 Based on a priori genes of interest A blunt yet effective feature selection strategy is to use pre-defined sets of interesting genes. The aim is to focus on specific aspects of biological heterogeneity that may be masked by other factors when using unsupervised methods for HVG selection. One example application lies in the dissection of transcriptional changes during the earliest stages of cell fate commitment (Messmer et al. 2019), which may be modest relative to activity in other pathways (e.g., cell cycle, metabolism). Indeed, if our aim is to show that there is no meaningful heterogeneity in a given pathway, we would - at the very least - be obliged to repeat our analysis using only the genes in that pathway to maximize power for detecting such heterogeneity. This approach is conceptually equivalent to that of a fluorescence activated cell sorting (FACS) experiment, with the convenience of being able to (re)define the features of interest at any time. For example, in the PBMC dataset, we might use some of the C7 immunologic signatures from MSigDB (Godec et al. 2016) to improve resolution of the various T cell subtypes. We stress that there is no shame in leveraging prior biological knowledge to address specific hypotheses in this manner. We say this because a common refrain in genomics is that the data analysis should be “unbiased”, i.e., free from any biological preconceptions. Attempting to derive biological insight ab initio is admirable but such “biases” are already present at every stage, starting from experimental design (why are we interested in this cell population in the first place?) and continuing through to interpretation of marker genes (Section 29.2.8). The downside of focusing on pre-defined genes is that it will limit our capacity to detect novel or unexpected aspects of variation. Thus, this kind of focused analysis should be complementary to (rather than a replacement for) the unsupervised feature selection strategies discussed previously. 8.4 Putting it all together The few lines of code below will select the top 10% of genes with the highest biological components. dec.pbmc &lt;- modelGeneVar(sce.pbmc) chosen &lt;- rownames(dec.pbmc)[order(dec.pbmc$bio, decreasing=TRUE)] chosen &lt;- head(chosen, nrow(dec.pbmc) * 0.1) length(chosen) ## [1] 3369 We can then subset the SingleCellExperiment to only retain our selection of HVGs. This ensures that downstream methods will only use these genes for their calculations. sce.pbmc &lt;- sce.pbmc[chosen,] dim(sce.pbmc) ## [1] 3369 3922 Alternatively, some methods may allow users to pass in the full SingleCellExperiment object and specify the genes to use via an extra argument like subset.row=. This may be more convenient in the context of the overall analysis, where genes outside of this subset may still be of interest during DE analyses or for visualization. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] scran_1.13.25 SingleCellExperiment_1.7.10 [3] SummarizedExperiment_1.15.9 DelayedArray_0.11.6 [5] BiocParallel_1.19.2 matrixStats_0.55.0 [7] Biobase_2.45.1 GenomicRanges_1.37.16 [9] GenomeInfoDb_1.21.1 IRanges_2.19.16 [11] S4Vectors_0.23.23 BiocGenerics_0.31.6 [13] Cairo_1.5-10 BiocStyle_2.13.2 [15] OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] Rcpp_1.0.2 rsvd_1.0.2 [3] locfit_1.5-9.1 lattice_0.20-38 [5] assertthat_0.2.1 digest_0.6.21 [7] R6_2.4.0 evaluate_0.14 [9] highr_0.8 ggplot2_3.2.1 [11] pillar_1.4.2 zlibbioc_1.31.0 [13] rlang_0.4.0 lazyeval_0.2.2 [15] irlba_2.3.3 Matrix_1.2-17 [17] rmarkdown_1.15 BiocNeighbors_1.3.5 [19] statmod_1.4.32 stringr_1.4.0 [21] igraph_1.2.4.1 RCurl_1.95-4.12 [23] munsell_0.5.0 vipor_0.4.5 [25] compiler_3.6.1 BiocSingular_1.1.7 [27] xfun_0.9 pkgconfig_2.0.3 [29] ggbeeswarm_0.6.0 htmltools_0.3.6 [31] tidyselect_0.2.5 gridExtra_2.3 [33] tibble_2.1.3 GenomeInfoDbData_1.2.1 [35] bookdown_0.13 edgeR_3.27.13 [37] viridisLite_0.3.0 crayon_1.3.4 [39] dplyr_0.8.3 bitops_1.0-6 [41] grid_3.6.1 gtable_0.3.0 [43] magrittr_1.5 scales_1.0.0 [45] dqrng_0.2.1 stringi_1.4.3 [47] XVector_0.25.0 viridis_0.5.1 [49] limma_3.41.16 scater_1.13.20 [51] DelayedMatrixStats_1.7.2 tools_3.6.1 [53] beeswarm_0.2.3 glue_1.3.1 [55] purrr_0.3.2 yaml_2.2.0 [57] colorspace_1.4-1 BiocManager_1.30.4 [59] knitr_1.25 Bibliography "],
["dimensionality-reduction.html", "Chapter 9 Dimensionality reduction 9.1 Overview 9.2 Principal components analysis 9.3 Dimensionality reduction for visualization Session Info", " Chapter 9 Dimensionality reduction .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 9.1 Overview Many scRNA-seq analysis procedures involve comparing cells based on their expression values across multiple genes. For example, clustering aims to identify cells with similar transcriptomic profiles by computing Euclidean distances across genes. In these applications, each individual gene represents a dimension of the data. More intuitively, if we had a scRNA-seq data set with two genes, we could make a two-dimensional plot where each axis represents the expression of one gene and each point in the plot represents a cell. This concept can be extended to data sets with thousands of genes where each cell’s expression profile defines its location in the high-dimensional expression space. As the name suggests, dimensionality reduction aims to reduce the number of separate dimensions in the data. This is possible because different genes are correlated if they are affected by the same biological process. Thus, we do not need to store separate information for individual genes, but can instead compress multiple features into a single dimension, e.g., an “eigengene” (Langfelder and Horvath 2007). This reduces computational work in downstream analyses, as calculations only need to be performed for a few dimensions rather than thousands of genes; reduces noise by averaging across multiple genes to obtain a more precise representation of the patterns in the data; and enables effective plotting of the data, for those of us who are not capable of visualizing more than 3 dimensions. We will use the Zeisel et al. (2015) dataset to demonstrate the applications of various dimensionality reduction methods in this chapter. View history ### loading ### library(scRNAseq) sce.zeisel &lt;- ZeiselBrainData() sce.zeisel &lt;- sce.zeisel[rowData(sce.zeisel)$featureType!=&quot;repeat&quot;,] library(scater) sce.zeisel &lt;- aggregateAcrossFeatures(sce.zeisel, id=sub(&quot;_loc[0-9]+$&quot;, &quot;&quot;, rownames(sce.zeisel))) ### gene-annotation ### library(org.Mm.eg.db) ensembl &lt;- mapIds(org.Mm.eg.db, keys=rownames(sce.zeisel), keytype=&quot;SYMBOL&quot;, column=&quot;ENSEMBL&quot;) rowData(sce.zeisel)$ENSEMBL &lt;- ensembl ### quality-control ### stats &lt;- perCellQCMetrics(sce.zeisel, subsets=list( Mt=rowData(sce.zeisel)$featureType==&quot;mito&quot;)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;altexps_ERCC_percent&quot;, &quot;subsets_Mt_percent&quot;), nmads=3) sce.zeisel &lt;- sce.zeisel[,!qc$discard] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.zeisel) sce.zeisel &lt;- computeSumFactors(sce.zeisel, cluster=clusters) sce.zeisel &lt;- logNormCounts(sce.zeisel) ### variance-modelling ### dec.zeisel &lt;- modelGeneVarWithSpikes(sce.zeisel, &quot;ERCC&quot;) sce.zeisel ## class: SingleCellExperiment ## dim: 19839 2816 ## metadata(0): ## assays(2): counts logcounts ## rownames(19839): 0610005C13Rik 0610007N19Rik ... mt-Tw mt-Ty ## rowData names(2): featureType ENSEMBL ## colnames(2816): 1772071015_C02 1772071017_G12 ... 1772063068_D01 ## 1772066098_A12 ## colData names(10): tissue group # ... level1class level2class ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(2): ERCC repeat 9.2 Principal components analysis 9.2.1 Background Principal components analysis (PCA) discovers axes in high-dimensional space that capture the largest amount of variation. This is best understood by imagining each axis as a line. Say we draw a line anywhere, and we move all cells in our data set onto this line by the shortest path. The variance captured by this axis is defined as the variance across cells along that line. In PCA, the first axis (or “principal component”, PC) is chosen such that it captures the greatest variance across cells. The next PC is chosen such that it is orthogonal to the first and captures the greatest remaining amount of variation, and so on. By definition, the top PCs capture the dominant factors of heterogeneity in the data set. Thus, we can perform dimensionality reduction by restricting downstream analyses to the top PCs. This strategy is simple, highly effective and widely used throughout the data sciences. It takes advantage of the well-studied theoretical properties of the PCA - namely, that a low-rank approximation formed from the top PCs is the optimal approximation of the original data for a given matrix rank. It also allows us to use a wide range of fast PCA implementations for scalable and efficient data analysis. When applying PCA to scRNA-seq data, our assumption is that biological processes affect multiple genes in a coordinated manner. This means that the earlier PCs are likely to represent biological structure as more variation can be captured by considering the correlated behaviour of many genes. By comparison, random technical or biological noise is expected to affect each gene independently. There is unlikely to be an axis that can capture random variation across many genes, meaning that noise should mostly be concentrated in the later PCs. This motivates the use of the earlier PCs in our downstream analyses, which concentrates the biological signal to simultaneously reduce computational work and remove noise. 9.2.2 Performing the PCA We perform the PCA on the log-normalized expression values using the runPCA() function from scater. This is based on a mathematical technique called the singular value decomposition (SVD). By default, runPCA() will use an exact SVD based on base R’s svd() function and return the first 50 PCs for downstream analysis. These PCs are stored in the reducedDims() of the output SingleCellExperiment object, as shown below. # Using the top 2000 HVGs. chosen.hvgs &lt;- head(order(dec.zeisel$bio, decreasing=TRUE), 2000) library(scater) sce.zeisel &lt;- runPCA(sce.zeisel, subset_row=chosen.hvgs) reducedDimNames(sce.zeisel) ## [1] &quot;PCA&quot; dim(reducedDim(sce.zeisel, &quot;PCA&quot;)) ## [1] 2816 50 In the example above, the PCA is performed on the top 2000 genes with the largest biological components to reduce computational work and noise. Specifically, PCA is generally robust to random noise but an excess of it may cause the earlier PCs to capture noise instead of biological structure. This effect can be avoided - or at least mitigated - by restricting the PCA to HVGs with large biological components. Any of the strategies described in Chapter 8 could be used for feature selection here. For large data sets, greater efficiency is obtained by using approximate SVD algorithms that only compute the top PCs. Here, we can use methods from the irlba package to perform the SVD by passing an IrlbaParam object (from the BiocSingular package) to the BSPARAM= argument (see Section 18.2.2 for more details). Many of these approximate algorithms are based on randomization and thus require set.seed() to obtain reproducible results. library(BiocSingular) set.seed(1000) sce.zeisel &lt;- runPCA(sce.zeisel, subset_row=chosen.hvgs, BSPARAM=IrlbaParam(), name=&quot;IRLBA&quot;) reducedDimNames(sce.zeisel) ## [1] &quot;PCA&quot; &quot;IRLBA&quot; 9.2.3 Choosing the number of PCs 9.2.3.1 Motivation How many of the top PCs should we retain for downstream analyses? The choice of the number of PCs \\(d\\) is a decision that is analogous to the choice of the number of HVGs to use. Using more PCs will avoid discarding biological signal in later PCs, at the cost of retaining more noise. Most practitioners will simply set \\(d\\) to a “reasonable” but arbitrary value, typically ranging from 10 to 50. This is often satisfactory provided it is coupled with sufficient testing of alternative values to explore other perspectives of the data at a different bias-variance trade-off. Nonetheless, we will describe some more data-driven strategies to guide a suitable choice of \\(d\\). 9.2.3.2 Using the elbow point A simple heuristic for choosing \\(d\\) involves identifying the elbow point in the percentage of variance explained by successive PCs. This refers to the “elbow” in the curve of a scree plot as shown in Figure 9.1. # Percentage of variance explained is tucked away in the attributes. percent.var &lt;- attr(reducedDim(sce.zeisel), &quot;percentVar&quot;) chosen.elbow &lt;- PCAtools::findElbowPoint(percent.var) chosen.elbow ## [1] 7 plot(percent.var, xlab=&quot;PC&quot;, ylab=&quot;Variance explained (%)&quot;) abline(v=chosen.elbow, col=&quot;red&quot;) Figure 9.1: Percentage of variance explained by successive PCs in the Zeisel brain data. The identified elbow point is marked with a red line. Our assumption is that each of the top PCs capturing biological signal should explain much more variance than the remaining PCs. Thus, there should be a sharp drop in the percentage of variance explained when we move past the last “biological” PC. This manifests as an elbow in the scree plot, the location of which serves as a natural choice for \\(d\\). From a practical perspective, the use of the elbow point tends to retain fewer PCs compared to other methods. The definition of “much more variance” is relative so, in order to be retained, later PCs must explain a amount of variance that is comparable to that explained by the first few PCs. Strong biological variation in the early PCs will shift the elbow to the left, potentially excluding weaker (but still interesting) variation in the next PCs immediately following the elbow. 9.2.3.3 Using the technical noise Another strategy is to retain all PCs until the percentage of total variation explained reaches some threshold \\(T\\). For example, we might retain the top set of PCs that explains 80% of the total variation in the data. Of course, it would be pointless to swap one arbitrary parameter \\(d\\) for another \\(T\\). Instead, we derive a suitable value for \\(T\\) by calculating the proportion of variance in the data that is attributed to the biological component. This is done using the denoisePCA() function with the variance modelling results from modelGeneVar() or related functions, where \\(T\\) is defined as the ratio of the sum of the biological components to the sum of total variances. To illustrate, we use this strategy to pick the number of PCs in the 10X PBMC dataset. Note that explicit feature selection is not strictly necessary, as denoisePCA() will automatically restrict the PCA to genes with positive biological components (Section 8.3.4) to ensure that \\(T\\) is always a positive value. We also use IrlbaParam() to speed up the SVD as previously described. View history ### loading ### library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) ### gene-annotation ### library(scater) rownames(sce.pbmc) &lt;- uniquifyFeatureNames( rowData(sce.pbmc)$ID, rowData(sce.pbmc)$Symbol) library(EnsDb.Hsapiens.v86) location &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce.pbmc)$ID, column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) ### cell-detection ### set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] ### quality-control ### stats &lt;- perCellQCMetrics(sce.pbmc, subsets=list(Mito=which(location==&quot;MT&quot;))) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) sce.pbmc &lt;- sce.pbmc[,!high.mito] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.pbmc) sce.pbmc &lt;- computeSumFactors(sce.pbmc, cluster=clusters) sce.pbmc &lt;- logNormCounts(sce.pbmc) ### variance-modelling ### set.seed(1001) dec.pbmc &lt;- modelGeneVarByPoisson(sce.pbmc) library(scran) set.seed(111001001) denoised.pbmc &lt;- denoisePCA(sce.pbmc, technical=dec.pbmc, BSPARAM=IrlbaParam()) ncol(reducedDim(denoised.pbmc)) ## [1] 14 The dimensionality of the output represents the lower bound on the number of PCs required to retain all biological variation. Any fewer PCs will definitely discard some aspect of biological signal. Note that the converse is not true, i.e., there is no guarantee that the retained PCs capture all of the signal, which is only generally possible if no dimensionality reduction is performed at all. The returned value of \\(d\\) provides a reasonable choice of rank when we want to retain as much signal as possible while still removing some noise. From a practical perspective, the denoisePCA() approach retains more PCs than the elbow point method. This is because the former does not compare PCs to each other and thus does not discard PCs corresponding to secondary factors of variation. The downside is that many minor aspects of variation may not be interesting (e.g., transcriptional bursting) and their retention would only add irrelevant noise. Thus, whether this is a “better” approach depends on the analyst’s willingness to increase noise in order to preserve weaker biological signals. Incidentally, denoisePCA() imposes internal caps on the number of PCs that can be chosen in this manner. By default, the number is bounded within the “reasonable” limits of 5 and 50 to avoid selection of too few PCs (when technical noise is high relative to biological variation) or too many PCs (when technical noise is very low). For example, applying this function to the Zeisel brain data hits the upper limit: set.seed(001001001) denoised.zeisel &lt;- denoisePCA(sce.zeisel, technical=dec.zeisel, subset.row=chosen.hvgs, BSPARAM=IrlbaParam()) ncol(reducedDim(denoised.zeisel)) ## [1] 50 9.2.3.4 Based on population structure Yet another method to choose \\(d\\) uses information about the number of subpopulations in the data. Consider a situation where each subpopulation differs from the others along a different axis in the high-dimensional space (e.g., because it is defined by a unique set of marker genes). This suggests that we should set \\(d\\) to the number of unique subpopulations minus 1, which guarantees separation of all subpopulations while retaining as few dimensions (and noise) as possible. We can use this reasoning to loosely motivate an a priori choice for \\(d\\) - for example, if we expect around 10 different cell types in our population, we would set \\(d \\approx 10\\). In practice, the number of subpopulations is usually not known in advance. Rather, we use a heuristic approach that uses the number of clusters as a proxy for the number of subpopulations. We perform clustering (graph-based by default, see Chapter 10) on the first \\(d^*\\) PCs and only consider the values of \\(d^*\\) that yield no more than \\(d^*+1\\) clusters. If we detect more clusters with fewer dimensions, we consider this to represent overclustering rather than distinct subpopulations, assuming that multiple subpopulations should not be distinguishable on the same axes. We test a range of \\(d^*\\) and set \\(d\\) to the value that maximizes the number of clusters while satisfying the above condition. This attempts to capture as many distinct (putative) subpopulations as possible by retaining biological signal in later PCs, up until the point that the additional noise reduces resolution. pcs &lt;- reducedDim(sce.zeisel) choices &lt;- getClusteredPCs(pcs) metadata(choices)$chosen ## [1] 27 plot(choices$n.pcs, choices$n.clusters, xlab=&quot;Number of PCs&quot;, ylab=&quot;Number of clusters&quot;) abline(a=1, b=1, col=&quot;red&quot;) abline(v=metadata(choices)$chosen, col=&quot;grey80&quot;, lty=2) Figure 9.2: Number of clusters detected in the Zeisel brain dataset as a function of the number of PCs. The red unbroken line represents the theoretical upper constraint on the number of clusters, while the grey dashed line is the number of PCs suggested by getClusteredPCs(). This strategy is the most pragmatic as it directly addresses the role of the bias-variance trade-off in downstream analyses, specifically clustering. There is no need to preserve biological signal beyond what is distinguishable in later steps. However, it involves strong assumptions about the nature of the biological differences between subpopulations - and indeed, discrete subpopulations may not even exist in studies of continuous processes like differentiation. 9.2.4 Putting it together Once we have chosen \\(d\\), applying it is as simple as subsetting the PC matrix by column. We then use the reducedDim()&lt;- command to reassign the subsetted matrix back into the SingleCellExperiment object. For example, if we were to take the top 20 PCs, we would do: reducedDim(sce.zeisel, &quot;PCA&quot;) &lt;- reducedDim(sce.zeisel, &quot;PCA&quot;)[,1:20] ncol(reducedDim(sce.zeisel, &quot;PCA&quot;)) ## [1] 20 Downstream applications that use the &quot;PCA&quot; dimensionality reduction results in sce.zeisel will subsequently operate on the first 20 PCs only. Alternatively, some users may prefer to keep the full set of PCs, in which case the top set can be assigned to another name: reducedDim(sce.zeisel, &quot;PCA_20&quot;) &lt;- reducedDim(sce.zeisel, &quot;PCA&quot;)[,1:20] reducedDimNames(sce.zeisel) ## [1] &quot;PCA&quot; &quot;IRLBA&quot; &quot;PCA_20&quot; Note that this is not necessary if the desired number of PCs is directly specified in the initial call to runPCA(). Similarly, denoisePCA() will return its chosen number of PCs without requiring further user intervention. 9.3 Dimensionality reduction for visualization 9.3.1 Motivation Another application of dimensionality reduction is to compress the data into 2 (sometimes 3) dimensions for plotting. This serves a separate purpose to the PCA-based dimensionality reduction described above. Algorithms are more than happy to operate on 10-50 PCs, but these are still too many dimensions for human comprehension. Further dimensionality reduction strategies are required to pack the most salient features of the data into 2 or 3 dimensions, which we will discuss below. 9.3.2 Visualizating with PCA The simplest visualization approach is to plot the top 2 PCs (Figure 9.3): plotReducedDim(sce.zeisel, dimred=&quot;PCA&quot;, colour_by=&quot;level1class&quot;) Figure 9.3: PCA plot of the first two PCs in the Zeisel brain data. Each point is a cell, coloured according to the annotation provided by the original authors. The problem is that PCA is a linear technique, i.e., only variation along a line in high-dimensional space is captured by each PC. As such, it cannot efficiently pack differences in \\(d\\) dimensions into the first 2 PCs. This is demonstrated in Figure 9.3 where the top two PCs fail to resolve some subpopulations identified by Zeisel et al. (2015). If the first PC is devoted to resolving the biggest difference between subpopulations, and the second PC is devoted to resolving the next biggest difference, then the remaining differences will not be visible in the plot. One workaround is to plot several of the top PCs against each other in pairwise plots (Figure 9.4). However, it is difficult to interpret multiple plots simultaneously, and even this approach is not sufficient to separate some of the annotated subpopulations. plotReducedDim(sce.zeisel, dimred=&quot;PCA&quot;, ncomponents=4, colour_by=&quot;level1class&quot;) Figure 9.4: PCA plot of the first two PCs in the Zeisel brain data. Each point is a cell, coloured according to the annotation provided by the original authors. There are some advantages to the PCA for visualization. It is predictable and will not introduce artificial structure in the visualization. It is also deterministic and robust to small changes in the input values. However, as shown above, PCA is usually not satisfactory for visualization of complex populations. 9.3.3 t-stochastic neighbor embedding The de facto standard for visualization of scRNA-seq data is the \\(t\\)-stochastic neighbour embedding (\\(t\\)-SNE) method (Van der Maaten and Hinton 2008). This attempts to find a low-dimensional representation of the data that preserves the distances between each point and its neighbours in the high-dimensional space. Unlike PCA, it is not restricted to linear transformations, nor is it obliged to accurately represent distances between distance populations. This means that it has much more freedom in how it arranges cells in low-dimensional space, enabling it to separate many distinct clusters in a complex population (Figure 9.5). set.seed(00101001101) # runTSNE() stores the t-SNE coordinates in the reducedDims # for re-use across multiple plotReducedDim() calls. sce.zeisel &lt;- runTSNE(sce.zeisel, dimred=&quot;PCA&quot;) plotReducedDim(sce.zeisel, dimred=&quot;TSNE&quot;, colour_by=&quot;level1class&quot;) Figure 9.5: \\(t\\)-SNE plots constructed from the top PCs in the Zeisel brain dataset. Each point represents a cell, coloured according to the published annotation. One of the main disadvantages of \\(t\\)-SNE is that it is much more computationally intensive than other visualization methods. We mitigate this effect by performing the calculations on the top PCs with dimred=&quot;PCA&quot; in runtTSNE(). This takes advantage of the PCA to compact the data and remove noise, followed by \\(t\\)-SNE to create the visualization. It is possible to run \\(t\\)-SNE on the original expression matrix but this is less efficient. Another issue with \\(t\\)-SNE is that it requires the user to be aware of additional parameters (discussed here in some depth). It involves a random initialization so we need to (i) repeat the visualization several times to ensure that the results are representative and (ii) set the seed to ensure that the chosen results are reproducible. The “perplexity” is another important parameter that determines the granularity of the visualization (Figure 9.6). Low perplexities will favour resolution of finer structure, possibly to the point that the visualization is compromised by random noise. Thus, it is advisable to test different perplexity values to ensure that the choice of perplexity does not drive the interpretation of the plot. set.seed(100) sce.zeisel &lt;- runTSNE(sce.zeisel, dimred=&quot;PCA&quot;, perplexity=5) out5 &lt;- plotReducedDim(sce.zeisel, dimred=&quot;TSNE&quot;, colour_by=&quot;level1class&quot;) + ggtitle(&quot;perplexity = 5&quot;) set.seed(100) sce.zeisel &lt;- runTSNE(sce.zeisel, dimred=&quot;PCA&quot;, perplexity=20) out20 &lt;- plotReducedDim(sce.zeisel, dimred=&quot;TSNE&quot;, colour_by=&quot;level1class&quot;) + ggtitle(&quot;perplexity = 20&quot;) set.seed(100) sce.zeisel &lt;- runTSNE(sce.zeisel, dimred=&quot;PCA&quot;, perplexity=80) out80 &lt;- plotReducedDim(sce.zeisel, dimred=&quot;TSNE&quot;, colour_by=&quot;level1class&quot;) + ggtitle(&quot;perplexity = 80&quot;) multiplot(out5, out20, out80, cols=3) Figure 9.6: \\(t\\)-SNE plots constructed from the top PCs in the Zeisel brain dataset, using a range of perplexity values. Each point represents a cell, coloured according to its annotation. Despite its shortcomings, \\(t\\)-SNE is proven tool for general-purpose visualization of scRNA-seq data. It sees routine use in many analysis pipelines and will likely continue to do so for some time. 9.3.4 Uniform manifold approximation and projection The uniform manifold approximation and projection (UMAP) method (McInnes, Healy, and Melville 2018) is an alternative to \\(t\\)-SNE for non-linear dimensionality reduction. It is roughly similar to \\(t\\)-SNE in that it also tries to find a low-dimensional representation that preserves relationships between neighbors in high-dimensional space. However, the two methods are based on different theory, represented by differences in the various graph weighting equations. This manifests as a different visualization as shown in Figure 9.7. set.seed(1100101001) sce.zeisel &lt;- runUMAP(sce.zeisel, dimred=&quot;PCA&quot;) plotReducedDim(sce.zeisel, dimred=&quot;UMAP&quot;, colour_by=&quot;level1class&quot;) Figure 9.7: UMAP plots constructed from the top PCs in the Zeisel brain dataset. Each point represents a cell, coloured according to the published annotation. Compared to \\(t\\)-SNE, the UMAP visualization tends to have more compact visual clusters with more empty space between them. It also attempts to preserve more of the global structure than \\(t\\)-SNE. From a practical perspective, UMAP is much faster than \\(t\\)-SNE, which may be an important consideration for large datasets. (Nonetheless, we have still run UMAP on the top 20 PCs here for consistency.) UMAP also involves a series of randomization steps so setting the seed is critical. Like \\(t\\)-SNE, UMAP has its own suite of hyperparameters that affect the visualization. Of these, the number of neighbours (n_neighbors) and the minimum distance between embedded points (min_dist) have the greatest effect on the granularity of the output. If these values are too low, random noise will be incorrectly treated as high-resolution structure, while values that are too high will discard fine structure altogether in favour of obtaining an accurate overview of the entire dataset. Again, it is a good idea to test a range of values for these parameters to ensure that they do not compromise any conclusions drawn from a UMAP plot. It is arguable whether the UMAP or \\(t\\)-SNE visualizations are more useful or aesthetically pleasing. However, it is clear that UMAP is much faster. For that reason alone, it is increasingly displacing \\(t\\)-SNE as the method of choice for visualizing large scRNA-seq data sets. 9.3.5 Interpreting the plots Dimensionality reduction for visualization necessarily involves discarding information and distorting the distances between cells. One might wonder whether the results of such extreme data compression can be trusted. Indeed, it would probably be unwise to directly analyze the low-dimensional coordinates used for plotting. Rather, the plots should only be used to interpret or communicate the results of quantitative analyses based on a more accurate higher-rank representation of the data. To illustrate, consider the interaction between clustering and \\(t\\)-SNE. As a general rule, we would not perform clustering on the \\(t\\)-SNE coordinates. Rather, we would cluster on the first 10-50 PCs (Chapter (clustering)) and then visualize the cluster identities on the \\(t\\)-SNE plot. This ensures that clustering makes use of the information that was lost during compression into two dimensions. Given a discrepancy between the visible clusters on a \\(t\\)-SNE plot and those identified by our clustering, we would be inclined to favour the latter. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] scran_1.13.25 BiocSingular_1.1.7 [3] scater_1.13.20 ggplot2_3.2.1 [5] SingleCellExperiment_1.7.10 SummarizedExperiment_1.15.9 [7] DelayedArray_0.11.6 BiocParallel_1.19.2 [9] matrixStats_0.55.0 Biobase_2.45.1 [11] GenomicRanges_1.37.16 GenomeInfoDb_1.21.1 [13] IRanges_2.19.16 S4Vectors_0.23.23 [15] BiocGenerics_0.31.6 Cairo_1.5-10 [17] BiocStyle_2.13.2 OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] viridis_0.5.1 edgeR_3.27.13 [3] viridisLite_0.3.0 DelayedMatrixStats_1.7.2 [5] RcppParallel_4.4.3 assertthat_0.2.1 [7] statmod_1.4.32 highr_0.8 [9] BiocManager_1.30.4 dqrng_0.2.1 [11] GenomeInfoDbData_1.2.1 vipor_0.4.5 [13] yaml_2.2.0 ggrepel_0.8.1 [15] pillar_1.4.2 lattice_0.20-38 [17] glue_1.3.1 limma_3.41.16 [19] digest_0.6.21 XVector_0.25.0 [21] colorspace_1.4-1 plyr_1.8.4 [23] cowplot_1.0.0 htmltools_0.3.6 [25] Matrix_1.2-17 pkgconfig_2.0.3 [27] bookdown_0.13 zlibbioc_1.31.0 [29] purrr_0.3.2 scales_1.0.0 [31] RSpectra_0.15-0 Rtsne_0.15 [33] tibble_2.1.3 withr_2.1.2 [35] lazyeval_0.2.2 magrittr_1.5 [37] crayon_1.3.4 evaluate_0.14 [39] FNN_1.1.3 beeswarm_0.2.3 [41] tools_3.6.1 stringr_1.4.0 [43] munsell_0.5.0 locfit_1.5-9.1 [45] irlba_2.3.3 compiler_3.6.1 [47] rsvd_1.0.2 rlang_0.4.0 [49] grid_3.6.1 RCurl_1.95-4.12 [51] BiocNeighbors_1.3.5 igraph_1.2.4.1 [53] labeling_0.3 bitops_1.0-6 [55] rmarkdown_1.15 gtable_0.3.0 [57] reshape2_1.4.3 PCAtools_1.1.10 [59] R6_2.4.0 gridExtra_2.3 [61] knitr_1.25 dplyr_0.8.3 [63] uwot_0.1.4 stringi_1.4.3 [65] ggbeeswarm_0.6.0 Rcpp_1.0.2 [67] tidyselect_0.2.5 xfun_0.9 Bibliography "],
["clustering.html", "Chapter 10 Clustering 10.1 Motivation 10.2 What is the “true clustering”? 10.3 Graph-based clustering 10.4 \\(k\\)-means clustering 10.5 Hierarchical clustering 10.6 Nested clustering Session Info", " Chapter 10 Clustering .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 10.1 Motivation Clustering is an unsupervised learning procedure that is used in scRNA-seq data analysis to empirically define groups of cells with similar expression profiles. Its primary purpose is to summarize the data in a digestible format for human interpretation. This allows us to describe population heterogeneity in terms of discrete labels that are easily understood, rather than attempting to comprehend the high-dimensional manifold on which the cells truly reside. After annotation based on marker genes, the clusters can be treated as proxies for more abstract biological concepts such as cell types or states. Clustering is thus a critical step for extracting biological insights from scRNA-seq data. Here, we demonstrate the application of several commonly used methods with the 10X PBMC dataset. View history ### loading ### library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) ### gene-annotation ### library(scater) rownames(sce.pbmc) &lt;- uniquifyFeatureNames( rowData(sce.pbmc)$ID, rowData(sce.pbmc)$Symbol) library(EnsDb.Hsapiens.v86) location &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce.pbmc)$ID, column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) ### cell-detection ### set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] ### quality-control ### stats &lt;- perCellQCMetrics(sce.pbmc, subsets=list(Mito=which(location==&quot;MT&quot;))) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) sce.pbmc &lt;- sce.pbmc[,!high.mito] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.pbmc) sce.pbmc &lt;- computeSumFactors(sce.pbmc, cluster=clusters) sce.pbmc &lt;- logNormCounts(sce.pbmc) ### variance-modelling ### set.seed(1001) dec.pbmc &lt;- modelGeneVarByPoisson(sce.pbmc) ### dimensionality-reduction ### set.seed(10000) sce.pbmc &lt;- denoisePCA(sce.pbmc, technical=dec.pbmc) set.seed(100000) sce.pbmc &lt;- runTSNE(sce.pbmc, use_dimred=&quot;PCA&quot;) set.seed(1000000) sce.pbmc &lt;- runUMAP(sce.pbmc, use_dimred=&quot;PCA&quot;) sce.pbmc ## class: SingleCellExperiment ## dim: 33694 3922 ## metadata(1): Samples ## assays(2): counts logcounts ## rownames(33694): RP11-34P13.3 FAM138A ... AC213203.1 FAM231B ## rowData names(2): ID Symbol ## colnames(3922): AAACCTGAGAAGGCCT-1 AAACCTGAGACAGACC-1 ... ## TTTGTCACAGGTCCAC-1 TTTGTCATCCCAAGAT-1 ## colData names(2): Sample Barcode ## reducedDimNames(3): PCA TSNE UMAP ## spikeNames(0): ## altExpNames(0): 10.2 What is the “true clustering”? At this point, it is worth stressing the distinction between clusters and cell types. The former is an empirical construct while the latter is a biological truth (albeit a vaguely defined one). For this reason, questions like “what is the true number of clusters?” are usually meaningless. We can define as many clusters as we like, with whatever algorithm we like - each clustering will represent its own partitioning of the high-dimensional expression space, and is as “real” as any other clustering. A more relevant question is “how well do the clusters approximate the cell types?” Unfortunately, this is difficult to answer given the context-dependent interpretation of biological truth. Some analysts will be satisfied with resolution of the major cell types; other analysts may want resolution of subtypes; and others still may require resolution of different states (e.g., metabolic activity, stress) within those subtypes. Moreover, two clusterings can be highly inconsistent yet both valid, simply partitioning the cells based on different aspects of biology. Indeed, asking for an unqualified “best” clustering is akin to asking for the best magnification on a microscope without any context. It is helpful to realize that clustering, like a microscope, is simply a tool to explore the data. We can zoom in and out by changing the resolution of the clustering parameters, and we can experiment with different clustering algorithms to obtain alternative perspectives of the data. This iterative approach is entirely permissible for data exploration, which constitutes the majority of all scRNA-seq data analysis. 10.3 Graph-based clustering 10.3.1 Background Popularized by its use in Seurat, graph-based clustering is a flexible and scalable technique for clustering large scRNA-seq datasets. We first build a graph where each node is a cell that is connected to its nearest neighbours in the high-dimensional space. Edges are weighted based on the similarity between the cells involved, with higher weight given to cells that are more closely related. We then apply algorithms to identify “communities” of cells that are more connected to cells in the same community than they are to cells of different communities. Each community represents a cluster that we can use for downstream interpretation. The major advantage of graph-based clustering lies in its scalability. It only requires a \\(k\\)-nearest neighbor search that can be done in log-linear time on average, in contrast to hierachical clustering methods with runtimes that are quadratic with respect to the number of cells. Graph construction avoids making strong assumptions about the shape of the clusters or the distribution of cells within each cluster, compared to other methods like \\(k\\)-means (that favor spherical clusters) or Gaussian mixture models (that require normality). From a practical perspective, each cell is forcibly connected to a minimum number of neighboring cells, which reduces the risk of generating many uninformative clusters consisting of one or two outlier cells. The main drawback of graph-based methods is that, after graph construction, no information is retained about relationships beyond the neighbouring cells1. This has some practical consequences in datasets that exhibit differences in cell density, as more steps through the graph are required to move the same distance through a region of higher cell density. From the perspective of community detection algorithms, this effect “inflates” the high-density regions such that any internal substructure or noise is more likely to cause formation of subclusters. The resolution of clustering thus becomes dependent on the density of cells, which can occasionally be misleading if it overstates the heterogeneity in the data. 10.3.2 Implementation There are several considerations in the practical execution of a graph-based clustering method: How many neighbors are considered when constructing the graph. What scheme is used to weight the edges. Which community detection algorithm is used to define the clusters. For example, the following code uses the 10 nearest neighbors of each cell to construct a shared nearest neighbor graph. Two cells are connected by an edge if any of their nearest neighbors are shared, with the edge weight defined from the highest average rank of the shared neighbors (Xu and Su 2015). The Walktrap method from the igraph package is then used to identify communities. All calculations are performed using the top PCs to take advantage of data compression and denoising. library(scran) g &lt;- buildSNNGraph(sce.pbmc, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership table(clust) ## clust ## 1 2 3 4 5 6 7 8 9 10 11 12 13 ## 785 198 56 541 529 516 128 824 45 151 92 21 36 We assign the cluster assignments back into our SingleCellExperiment object as a factor in the column metadata. This allows us to conveniently visualize the distribution of clusters in a \\(t\\)-SNE plot (Figure 10.1). library(scater) sce.pbmc$cluster &lt;- factor(clust) plotReducedDim(sce.pbmc, &quot;TSNE&quot;, colour_by=&quot;cluster&quot;) Figure 10.1: \\(t\\)-SNE plot of the 10X PBMC dataset, where each point represents a cell and is coloured according to the identity of the assigned cluster from graph-based clustering. One of the most important parameters is k, the number of nearest neighbors used to construct the graph. This controls the resolution of the clustering where higher k yields a more inter-connected graph and broader clusters. Users can exploit this by experimenting with different values of k to obtain a satisfactory resolution. # More resolved. g.5 &lt;- buildSNNGraph(sce.pbmc, k=5, use.dimred = &#39;PCA&#39;) clust.5 &lt;- igraph::cluster_walktrap(g.5)$membership table(clust.5) ## clust.5 ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## 40 45 499 487 335 121 171 620 18 825 202 55 73 142 81 41 54 29 ## 19 20 21 22 ## 21 17 10 36 # Less resolved. g.50 &lt;- buildSNNGraph(sce.pbmc, k=50, use.dimred = &#39;PCA&#39;) clust.50 &lt;- igraph::cluster_walktrap(g.50)$membership table(clust.50) ## clust.50 ## 1 2 3 4 5 6 7 8 9 ## 553 832 198 121 1114 455 498 106 45 The graph itself can be visualized using a force-directed layout (Figure 10.2). This yields a dimensionality reduction result that is closely related to \\(t\\)-SNE and UMAP, though which of these is the most aesthetically pleasing is left to the eye of the beholder. set.seed(2000) reducedDim(sce.pbmc, &quot;force&quot;) &lt;- igraph::layout_with_fr(g) plotReducedDim(sce.pbmc, colour_by=&quot;cluster&quot;, use_dimred=&quot;force&quot;) Figure 10.2: Force-directed layout for the shared nearest-neighbour graph of the PBMC dataset. Each point represents a cell and is coloured according to its assigned cluster identity. 10.3.3 Other parameters Further tweaking can be performed by changing the edge weighting scheme during graph construction. Setting type=&quot;number&quot; will weight edges based on the number of nearest neighbors that are shared between two cells. Similarly, type=&quot;jaccard&quot; will weight edges according to the Jaccard index of the two sets of neighbors. We can also disable weighting altogether by using buildKNNGraph(), which is occasionally useful for downstream graph operations that do not support weights. g.num &lt;- buildSNNGraph(sce.pbmc, use.dimred=&quot;PCA&quot;, type=&quot;number&quot;) g.jaccard &lt;- buildSNNGraph(sce.pbmc, use.dimred=&quot;PCA&quot;, type=&quot;jaccard&quot;) g.none &lt;- buildKNNGraph(sce.pbmc, use.dimred=&quot;PCA&quot;) All of these g variables are graph objects from the igraph package and can be used with any of the community detection algorithms provided by igraph. We have already mentioned the Walktrap approach, but many others are available to choose from: clust.louvain &lt;- igraph::cluster_louvain(g)$membership clust.infomap &lt;- igraph::cluster_infomap(g)$membership clust.fast &lt;- igraph::cluster_fast_greedy(g)$membership clust.labprop &lt;- igraph::cluster_label_prop(g)$membership clust.eigen &lt;- igraph::cluster_leading_eigen(g)$membership It is then straightforward to compare two clustering strategies to see how they differ. For example, the results below suggest that Louvain is similar to Walktrap; fast-greedy yields coarser clusters; and Infomap provides higher resolution. table(Louvain=clust.louvain, Walktrap=clust) ## Walktrap ## Louvain 1 2 3 4 5 6 7 8 9 10 11 12 13 ## 1 0 198 0 1 0 0 0 0 0 0 0 0 0 ## 2 0 0 0 0 3 0 0 810 0 9 0 0 0 ## 3 1 0 0 516 4 0 0 0 0 0 0 0 0 ## 4 0 0 0 1 400 0 0 14 0 1 0 0 0 ## 5 0 0 0 23 122 0 0 0 0 141 0 0 0 ## 6 0 0 0 0 0 0 0 0 0 0 0 0 36 ## 7 0 0 0 0 0 516 0 0 0 0 0 0 0 ## 8 0 0 0 0 0 0 0 0 0 0 0 21 0 ## 9 29 0 37 0 0 0 0 0 0 0 92 0 0 ## 10 1 0 0 0 0 0 0 0 45 0 0 0 0 ## 11 1 0 0 0 0 0 128 0 0 0 0 0 0 ## 12 753 0 19 0 0 0 0 0 0 0 0 0 0 table(Infomap=clust.infomap, Walktrap=clust) ## Walktrap ## Infomap 1 2 3 4 5 6 7 8 9 10 11 12 13 ## 1 0 0 0 0 0 0 0 503 0 7 0 0 0 ## 2 0 0 0 0 1 0 0 303 0 1 0 0 0 ## 3 0 0 0 0 0 231 0 0 0 0 0 0 0 ## 4 210 0 0 0 0 0 0 0 0 0 0 0 0 ## 5 0 0 0 0 0 199 0 0 0 0 0 0 0 ## 6 0 0 0 183 0 0 0 0 0 0 0 0 0 ## 7 164 0 0 0 0 0 0 0 0 0 0 0 0 ## 8 0 169 0 0 0 0 0 0 0 0 0 0 0 ## 9 0 0 0 149 0 0 0 0 0 0 0 0 0 ## 10 135 0 0 0 0 0 0 0 0 0 0 0 0 ## 11 0 0 0 0 6 0 0 0 0 137 0 0 0 ## 12 0 0 0 27 99 0 0 0 0 2 0 0 0 ## 13 0 0 0 0 0 0 128 0 0 0 0 0 0 ## 14 130 0 0 0 0 0 0 0 0 0 0 0 0 ## 15 0 0 0 0 114 0 0 0 0 0 0 0 0 ## [ reached getOption(&quot;max.print&quot;) -- omitted 22 rows ] table(Fast=clust.fast, Walktrap=clust) ## Walktrap ## Fast 1 2 3 4 5 6 7 8 9 10 11 12 13 ## 1 0 0 0 0 0 0 0 771 0 0 0 0 0 ## 2 0 0 0 0 0 0 0 0 0 0 0 0 36 ## 3 0 0 0 0 0 0 0 0 45 0 0 0 0 ## 4 0 0 0 0 0 515 0 0 0 0 0 0 0 ## 5 0 194 0 0 0 1 0 0 0 0 0 21 0 ## 6 0 4 0 541 529 0 0 53 0 151 0 0 0 ## 7 785 0 56 0 0 0 128 0 0 0 92 0 0 Pipelines involving scran default to rank-based weights followed by Walktrap clustering. In contrast, Seurat uses Jaccard-based weights followed by Louvain clustering. Both of these strategies work well, and it is likely that the same could be said for many other combinations of weighting schemes and community detection algorithms. 10.3.4 Assessing cluster separation When dealing with graphs, the modularity is a natural metric for evaluating the separation between communities/clusters. This is defined as the (scaled) difference between the observed total weight of edges between nodes in the same cluster and the expected total weight if edge weights were randomly distributed across all pairs of nodes. Larger modularity values indicate that there most edges occur within clusters, suggesting that the clusters are sufficiently well separated to avoid edges forming between neighboring cells in different clusters. The standard approach is to report a single modularity value for a clustering on a given graph. This is useful for comparing different clusterings on the same graph - and indeed, some community detection algorithms are designed with the aim of maximizing the modularity - but it is less helpful for interpreting a given clustering. Rather, we use the clusterModularity() function with as.ratio=TRUE, which returns the ratio of the observed to expected sum of weights between each pair of clusters. We use the ratio instead of the difference as the former is less dependent on the number of cells in each cluster. ratio &lt;- clusterModularity(g, clust, as.ratio=TRUE) ratio ## 1 2 3 4 5 6 7 8 ## 1 4.747 0.00 0.9718 0.001922 0.0006179 0.0005444 0.182848 0.0000000 ## 2 NaN 24.15 0.0000 0.100412 0.0082216 0.0054301 0.000000 0.0003150 ## 3 NaN NaN 110.8276 0.000000 0.0000000 0.0000000 0.655614 0.0035376 ## 4 NaN NaN NaN 7.499941 0.3127186 0.0019267 0.000000 0.0006704 ## 5 NaN NaN NaN NaN 7.2359911 0.0051028 0.007241 0.2307472 ## 6 NaN NaN NaN NaN NaN 7.3736323 0.000000 0.0000000 ## 7 NaN NaN NaN NaN NaN NaN 44.094696 0.0000000 ## 8 NaN NaN NaN NaN NaN NaN NaN 3.5142511 ## 9 NaN NaN NaN NaN NaN NaN NaN NaN ## 10 NaN NaN NaN NaN NaN NaN NaN NaN ## 11 NaN NaN NaN NaN NaN NaN NaN NaN ## 12 NaN NaN NaN NaN NaN NaN NaN NaN ## 13 NaN NaN NaN NaN NaN NaN NaN NaN ## 9 10 11 12 13 ## 1 0.02839 0.000000 0.1947 0.00000 4.357e-03 ## 2 0.00000 0.004791 0.0000 0.54527 0.000e+00 ## 3 0.00000 0.000000 0.9157 0.00000 0.000e+00 ## 4 0.00000 0.103582 0.0000 0.00000 0.000e+00 ## 5 0.00000 0.393945 0.0000 0.08774 1.040e-02 ## 6 0.00000 0.000000 0.0000 0.00000 0.000e+00 ## 7 0.00000 0.000000 0.0000 0.00000 0.000e+00 ## 8 0.00000 0.320243 0.0000 0.00000 0.000e+00 ## 9 171.65490 0.000000 0.0000 0.00000 0.000e+00 ## 10 NaN 23.689777 0.0000 0.00000 0.000e+00 ## 11 NaN NaN 57.8148 0.00000 0.000e+00 ## 12 NaN NaN NaN 514.42466 0.000e+00 ## 13 NaN NaN NaN NaN 1.887e+02 In each matrix, each row/column corresponds to a cluster, and each entry of the matrix contains the ratio of the observed to total weight of edges between cells in the respective clusters. A dataset containing well-separated clusters should contain most of the observed total weight on the diagonal entries, i.e., most edges occur between cells in the same cluster. Indeed, concentration of the weight on the diagonal of (Figure 10.3) indicates that most of the clusters are well-separated, while some modest off-diagonal entries represent closely related clusters with more inter-connecting edges. library(pheatmap) pheatmap(log2(ratio+1), cluster_rows=FALSE, cluster_cols=FALSE, color=colorRampPalette(c(&quot;white&quot;, &quot;blue&quot;))(100)) Figure 10.3: Heatmap of the log2-ratio of the total weight between nodes in the same cluster or in different clusters, relative to the total weight expected under a null model of random links. One useful approach is to use the ratio matrix to form another graph where the nodes are clusters rather than cells. Edges between nodes are weighted according to the ratio of observed to expected edge weights between cells in those clusters. We can then repeat our graph operations on this new cluster-level graph. For example, we could obtain clusters of clusters, or we could simply create a new cluster-based layout for visualization (Figure 10.4). This is analogous to the “graph abstraction” approach described by Wolf et al. (2017). cluster.gr &lt;- igraph::graph_from_adjacency_matrix(ratio, mode=&quot;upper&quot;, weighted=TRUE, diag=FALSE) set.seed(11001010) plot(cluster.gr, edge.width=igraph::E(cluster.gr)$weight*20) Figure 10.4: Force-directed layout showing the relationships between clusters based on the log-ratio of observed to expected total weights between nodes in different clusters. The thickness of the edge between a pair of clusters is proportional to the corresponding log-ratio. Incidentally, some readers may have noticed that all igraph commands were prefixed with igraph::. We have done this deliberately to avoid bringing igraph::normalize into the global namespace. Rather unfortunately, this normalize function accepts any argument and returns NULL, which causes difficult-to-diagnose bugs when it overwrites our intended normalize from scater. 10.4 \\(k\\)-means clustering 10.4.1 Background \\(k\\)-means clustering is a classic technique that aims to partition cells into \\(k\\) clusters. Each cell is assigned to the cluster with the closest centroid, which is done by minimizing the within-cluster sum of squares using a random starting configuration for the \\(k\\) centroids. The main advantage of this approach lies in its speed, given the simplicity and ease of implementation of the algorithm. However, it suffers from a number of serious shortcomings that reduce its appeal for obtaining interpretable clusters: It implicitly favours spherical clusters of equal radius. This can lead to unintuitive partitionings on real datasets that contain groupings with irregular sizes and shapes. The number of clusters \\(k\\) must be specified beforehand and represents a hard cap on the resolution of the clustering.. For example, setting \\(k\\) to be below the number of cell types will always lead to co-clustering of two cell types, regardless of how well separated they are. In contrast, other methods like graph-based clustering will respect strong separation even if the relevant resolution parameter is set to a low value. It is dependent on the randomly chosen initial coordinates. This requires multiple runs to verify that the clustering is stable. That said, \\(k\\)-means clustering is still one of the best approaches for sample-based data compression. In this application, we set \\(k\\) to a large value such as the square root of the number of cells to obtain fine-grained clusters. These are not meant to be interpreted directly, but rather, the centroids are treated as “samples” for further analyses. The idea here is to obtain a single representative of each region of the expression space, reducing the number of samples and computational work in later steps like, e.g., trajectory reconstruction (Ji and Ji 2016). This approach will also eliminate differences in cell density across the expression space, ensuring that the most abundant cell type does not dominate downstream results. 10.4.2 Base implementation Base R provides the kmeans() function that does as its name suggests. We call this on our top PCs to obtain a clustering for a specified number of clusters in the centers= argument, after setting the random seed to ensure that the results are reproducible. In general, the \\(k\\)-means clusters correspond to the visual clusters on the \\(t\\)-SNE plot in Figure 10.5, though there are some divergences that are not observed in, say, Figure 10.1. (This is at least partially due to the fact that \\(t\\)-SNE is itself graph-based and so will naturally agree more with a graph-based clustering strategy.) set.seed(100) clust.kmeans &lt;- kmeans(reducedDim(sce.pbmc, &quot;PCA&quot;), centers=10) table(clust.kmeans$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 ## 539 188 59 515 39 375 191 605 1054 357 sce.pbmc$cluster &lt;- factor(clust.kmeans$cluster) plotReducedDim(sce.pbmc, &quot;TSNE&quot;, colour_by=&quot;cluster&quot;) Figure 10.5: \\(t\\)-SNE plot of the 10X PBMC dataset, where each point represents a cell and is coloured according to the identity of the assigned cluster from \\(k\\)-means clustering. If we were so inclined, we could obtain a “reasonable” choice of \\(k\\) by computing the gap statistic using methods from the cluster package. This is the log-ratio of the expected to observed within-cluster sum of squares, where the expected value is computed by randomly distributing cells within the minimum bounding box of the original data. A larger gap statistic represents a lower observed sum of squares - and thus better clustering - compared to a population with no structure. Ideally, we would choose the \\(k\\) that maximizes the gap statistic, but this is often unhelpful as the tendency of \\(k\\)-means to favour spherical clusters results in a large choice \\(k\\) to capture different cluster shapes. Instead, we choose the most parsimonious \\(k\\) beyond which the increases in the gap statistic are considered insignificant (Figure 10.6). library(cluster) set.seed(110010101) gaps &lt;- clusGap(reducedDim(sce.pbmc, &quot;PCA&quot;), kmeans, K.max=20) best.k &lt;- maxSE(gaps$Tab[,&quot;gap&quot;], gaps$Tab[,&quot;SE.sim&quot;]) best.k ## [1] 8 plot(gaps$Tab[,&quot;gap&quot;], xlab=&quot;Number of clusters&quot;, ylab=&quot;Gap statistic&quot;) abline(v=best.k, col=&quot;red&quot;) Figure 10.6: Gap statistic with respect to increasing number of \\(k\\)-means clusters in the 10X PBMC dataset. The red line represents the chosen \\(k\\). A more practical use of \\(k\\)-means is to deliberately set \\(k\\) to a large value to achieve overclustering. This will forcibly partition cells inside broad clusters that do not have well-defined internal structure. For example, we might be interested in the change in expression from one “side” of a cluster to the other, but the lack of any clear separation within the cluster makes it difficult to separate with graph-based methods, even at the highest resolution. \\(k\\)-means has no such problems and will readily split these broad clusters for greater resolution, though obviously one must be prepared for the additional work involved in interpreting a greater number of clusters. set.seed(100) clust.kmeans2 &lt;- kmeans(reducedDim(sce.pbmc, &quot;PCA&quot;), centers=20) table(clust.kmeans2$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## 114 177 36 209 266 186 150 317 126 83 225 47 318 128 190 182 224 579 ## 19 20 ## 59 306 sce.pbmc$cluster &lt;- factor(clust.kmeans2$cluster) plotReducedDim(sce.pbmc, &quot;TSNE&quot;, colour_by=&quot;cluster&quot;, text_by=&quot;cluster&quot;) Figure 10.7: \\(t\\)-SNE plot of the 10X PBMC dataset, where each point represents a cell and is coloured according to the identity of the assigned cluster from \\(k\\)-means clustering with \\(k=20\\). 10.4.3 Assessing cluster separation The within-cluster sum of squares (WCSS) for each cluster is the most relevant diagnostic for \\(k\\)-means, given that the algorithm aims to find a clustering that minimizes the WCSS. Specifically, we use the WCSS to compute the root-mean-squared deviation (RMSD) that represents the spread of cells within each cluster. A cluster is more likely to have a low RMSD if it has no internal structure and is separated from other clusters (such that there are not many cells on the boundaries between clusters, which would result in a higher sum of squares from the centroid). ncells &lt;- tabulate(clust.kmeans2$cluster) tab &lt;- data.frame(wcss=clust.kmeans2$withinss, ncells=ncells) tab$rms &lt;- sqrt(tab$wcss/tab$ncells) tab ## wcss ncells rms ## 1 2935.0 114 5.074 ## 2 5668.2 177 5.659 ## 3 760.4 36 4.596 ## 4 5487.7 209 5.124 ## 5 4464.8 266 4.097 ## 6 7006.3 186 6.137 ## 7 2903.3 150 4.399 ## 8 4023.6 317 3.563 ## 9 4024.9 126 5.652 ## 10 4724.4 83 7.545 ## 11 8740.7 225 6.233 ## 12 2449.3 47 7.219 ## 13 4551.5 318 3.783 ## 14 4728.0 128 6.078 ## 15 5106.8 190 5.184 ## 16 9818.2 182 7.345 ## 17 5044.2 224 4.745 ## 18 19913.4 579 5.865 ## 19 15070.1 59 15.982 ## 20 7704.8 306 5.018 (As an aside, the cluster with the largest RMSD also appears to be the least dispersed in Figure 10.7. This highlights the risks of attempting to quantitatively interpret the shape of visual clusters in \\(t\\)-SNE plots.) To explore the relationships between \\(k\\)-means clusters, a natural approach is to compute distances between their centroids. This directly lends itself to visualization as a tree after hierarchical clustering (Figure 10.8). cent.tree &lt;- hclust(dist(clust.kmeans2$centers), &quot;ward.D2&quot;) plot(cent.tree) Figure 10.8: Hierarchy of \\(k\\)-means cluster centroids, using Ward’s minimum variance method. 10.5 Hierarchical clustering 10.5.1 Background Hierarchical clustering is an ancient technique that aims to generate a dendrogram containing a hierarchy of samples. This is most commonly done by greedily agglomerating samples into clusters, then agglomerating those clusters into larger clusters, and so on until all samples belong to a single cluster. Variants of hierarchical clustering methods primarily differ in how they choose to perform the agglomerations. For example, complete linkage aims to merge clusters with the smallest maximum distance between their elements, while Ward’s method aims to minimize the increase in within-cluster variance. In the context of scRNA-seq, the main advantage of hierarchical clustering lies in the production of the dendrogram. This is a rich summary that describes not only the relationships between cells but also the relationships between clusters at varying resolution. Users can easily “cut” the tree at different heights to define clusters with different granularity, where clusters defined at high resolution are guaranteed to be nested within those defined at a lower resolution. The dendrogram is also a natural representation of the data in situations where cells have descended from a relatively recent common ancestor. In practice, hierachical clustering is too slow to be used for anything but the smallest scRNA-seq datasets. Most variants require a cell-cell distance matrix that is prohibitively expensive to compute for many cells. Greedy agglomeration is also likely to result in a quantitatively suboptimal partitioning (as defined by the agglomeration measure) at higher levels of the dendrogram when the number of cells and merge steps is high. Nonetheless, we will still demonstrate the application of hierarchical clustering here, as it can occasionally be useful for squeezing more information out of datasets with very few cells. 10.5.2 Implementation As the PBMC dataset is too large, we will demonstrate on the 416B dataset instead. View history ### loading ### library(scRNAseq) sce.416b &lt;- LunSpikeInData(which=&quot;416b&quot;) sce.416b$block &lt;- factor(sce.416b$block) ### gene-annotation ### library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] rowData(sce.416b)$ENSEMBL &lt;- rownames(sce.416b) rowData(sce.416b)$SYMBOL &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SYMBOL&quot;) rowData(sce.416b)$SEQNAME &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) library(scater) rownames(sce.416b) &lt;- uniquifyFeatureNames(rowData(sce.416b)$ENSEMBL, rowData(sce.416b)$SYMBOL) ### quality-control ### mito &lt;- which(rowData(sce.416b)$SEQNAME==&quot;MT&quot;) stats &lt;- perCellQCMetrics(sce.416b, subsets=list(Mt=mito)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;subsets_Mt_percent&quot;, &quot;altexps_ERCC_percent&quot;), nmads=3, batch=sce.416b$block) sce.416b &lt;- sce.416b[,!qc$discard] ### normalization ### library(scran) sce.416b &lt;- computeSumFactors(sce.416b) sce.416b &lt;- logNormCounts(sce.416b) ### variance-modelling ### dec.416b &lt;- modelGeneVarWithSpikes(sce.416b, &quot;ERCC&quot;, block=sce.416b$block) ### batch-correction ### library(limma) assay(sce.416b, &quot;corrected&quot;) &lt;- removeBatchEffect(logcounts(sce.416b), design=model.matrix(~sce.416b$phenotype), batch=sce.416b$block) ### dimensionality-reduction ### sce.416b &lt;- denoisePCA(sce.416b, technical=dec.416b, assay.type=&quot;corrected&quot;, BSPARAM=BiocSingular::ExactParam()) set.seed(1010) sce.416b &lt;- runTSNE(sce.416b, dimred=&quot;PCA&quot;, perplexity=10) sce.416b ## class: SingleCellExperiment ## dim: 46604 185 ## metadata(0): ## assays(3): counts logcounts corrected ## rownames(46604): 4933401J01Rik Gm26206 ... CAAA01147332.1 ## CBFB-MYH11-mcherry ## rowData names(4): Length ENSEMBL SYMBOL SEQNAME ## colnames(185): SLX-9555.N701_S502.C89V9ANXX.s_1.r_1 ## SLX-9555.N701_S503.C89V9ANXX.s_1.r_1 ... ## SLX-11312.N712_S507.H5H5YBBXX.s_8.r_1 ## SLX-11312.N712_S517.H5H5YBBXX.s_8.r_1 ## colData names(9): Source Name cell line ... spike-in addition ## block ## reducedDimNames(2): PCA TSNE ## spikeNames(0): ## altExpNames(2): ERCC SIRV We compute a cell-cell distance matrix using the top PCs and we apply hierarchical clustering with Ward’s method. The resulting tree in Figure 10.9 shows a clear split in the population caused by oncogene induction. While both Ward’s method and complete linkage (hclust()’s default) yield compact clusters, we prefer the former it is less affected by differences in variance between clusters. dist.416b &lt;- dist(reducedDim(sce.416b, &quot;PCA&quot;)) tree.416b &lt;- hclust(dist.416b, &quot;ward.D2&quot;) # Making a prettier dendrogram. library(dendextend) tree.416b$labels &lt;- seq_along(tree.416b$labels) dend &lt;- as.dendrogram(tree.416b, hang=0.1) combined.fac &lt;- paste0(sce.416b$block, &quot;.&quot;, sub(&quot; .*&quot;, &quot;&quot;, sce.416b$phenotype)) labels_colors(dend) &lt;- c( `20160113.wild`=&quot;blue&quot;, `20160113.induced`=&quot;red&quot;, `20160325.wild`=&quot;dodgerblue&quot;, `20160325.induced`=&quot;salmon&quot; )[combined.fac][order.dendrogram(dend)] plot(dend) Figure 10.9: Hierarchy of cells in the 416B data set after hierarchical clustering, where each leaf node is a cell that is coloured according to its oncogene induction status (red is induced, blue is control) and plate of origin (light or dark). To obtain explicit clusters, we “cut” the tree by removing internal branches such that every subtree represents a distinct cluster. This is most simply done by removing internal branches above a certain height of the tree, as performed by the cutree() function. We generally prefer to use the dynamicTreeCut package, which uses the shape of the branches to obtain a more suitable partitioning for complex dendrograms (Figure 10.10). library(dynamicTreeCut) # minClusterSize needs to be turned down for small datasets. # deepSplit controls the resolution of the partitioning. clust.416b &lt;- cutreeDynamic(tree.416b, distM=as.matrix(dist.416b), minClusterSize=10, deepSplit=1) ## ..cutHeight not given, setting it to 1280 ===&gt; 99% of the (truncated) height range in dendro. ## ..done. table(clust.416b) ## clust.416b ## 1 2 3 4 5 ## 80 36 32 24 13 labels_colors(dend) &lt;- clust.416b[order.dendrogram(dend)] plot(dend) Figure 10.10: Hierarchy of cells in the 416B data set after hierarchical clustering, where each leaf node is a cell that is coloured according to its assigned cluster identity from a dynamic tree cut. This generally corresponds well to the grouping of cells on a \\(t\\)-SNE plot (Figure 10.11). sce.416b$cluster &lt;- factor(clust.416b) plotReducedDim(sce.416b, &quot;TSNE&quot;, colour_by=&quot;cluster&quot;) Figure 10.11: \\(t\\)-SNE plot of the 416B dataset, where each point represents a cell and is coloured according to the identity of the assigned cluster from hierarchical clustering. 10.5.3 Assessing cluster separation We check the separation of the clusters using the silhouette width (Figure 10.12). For each cell, we compute the average distance to cells in each other cluster. We then compute the minimum of these average distances across all clusters, as well as the average distance to cells in the same cluster. The silhouette width for each cell is defined as the difference between these two values divided by their maximum. Cells with large positive silhouette widths are closer to other cells in the same cluster than to cells in different clusters. Each cluster would ideally contain large positive silhouette widths, indicating that it is well-separated from other clusters. In Figure 10.12, some clusters are well-separated while others have a substantial proportion of negative widths. These can arise from the presence of internal subclusters, which inflates the within-cluster distance; or overclustering, where cells at the boundary of a partition are closer to the neighboring cluster than their own cluster. sil &lt;- silhouette(clust.416b, dist = dist.416b) plot(sil) Figure 10.12: Silhouette widths for cells in each cluster in the 416B dataset. Each bar represents a cell, grouped by the cluster to which it is assigned. For a more detailed examination, we identify the closest neighboring cluster for cells with negative widths. This provides a perspective on the relationships between clusters that is closer to the raw data than the dendrogram in Figure 10.10. neg.widths &lt;- sil[,3] &lt; 0 table(Cluster=sil[neg.widths,1], Neighbor=sil[neg.widths,2]) ## Neighbor ## Cluster 2 3 4 5 ## 1 0 1 17 10 ## 3 5 0 0 0 ## 4 5 2 0 0 The average silhouette width across all cells can also be used to choose clustering parameters. The aim is to maximize the average silhouette width in order to obtain well-separated clusters. This can be helpful to automatically obtain a “reasonable” clustering, though in practice, the clustering that yields the strongest separation often does not provide the most biological insight. 10.6 Nested clustering Another simple approach to improving resolution is to repeat the feature selection and clustering within a single cluster. This aims to select HVGs and PCs that are more relevant to internal structure, improving resolution by avoiding noise from unnecessary features. Subsetting also encourages clustering methods to separate cells according to more modest heterogeneity in the absence of distinct subpopulations. We demonstrate with a cluster of putative memory T cells from the PBMC dataset, identified according to several markers (Figure ??). g.full &lt;- buildSNNGraph(sce.pbmc, k=10, use.dimred = &#39;PCA&#39;) clust.full &lt;- igraph::cluster_walktrap(g.full)$membership plotExpression(sce.pbmc, features=c(&quot;CD3E&quot;, &quot;CCR7&quot;, &quot;CD69&quot;, &quot;CD44&quot;), x=I(factor(clust.full)), colour_by=I(factor(clust.full))) Figure 10.13: Distribution of log-normalized expression values for several T cell markers within each cluster in the 10X PBMC dataset. Each cluster is color-coded for convenience. # Repeating modelling and PCA on the subset. memory &lt;- 8L sce.memory &lt;- sce.pbmc[,clust.full==memory] dec.memory &lt;- modelGeneVar(sce.memory) sce.memory &lt;- denoisePCA(sce.memory, technical=dec.memory, BSPARAM=BiocSingular::IrlbaParam()) sce.memory &lt;- runTSNE(sce.memory) We apply graph-based clustering within this memory subset to obtain CD4+ and CD8+ subclusters (Figure ??). Admittedly, the expression of CD4 is so low that the change is rather modest, but the interpretation is clear enough. g.memory &lt;- buildSNNGraph(sce.memory, use.dimred=&quot;PCA&quot;) clust.memory &lt;- igraph::cluster_walktrap(g.memory)$membership plotExpression(sce.memory, features=c(&quot;CD8A&quot;, &quot;CD4&quot;), x=I(factor(clust.memory))) Figure 10.14: Distribution of CD4 and CD8A log-normalized expression values within each cluster in the memory T cell subset of the 10X PBMC dataset. Nested clustering is a general and conceptually straightforward procedure for increasing resolution. It also simplifies the interpretation of the subclusters, which only need to be considered in the context of the parent cluster’s identity. On the other hand, it tends to encourage the construction of a “house of cards” of cell type assignments, simply because it is difficult for practitioners to consider the uncertainty of identification for parent clusters when working with deep nesting. We tend to avoid nested clustering as a routine procedure, though it has its uses when the parent clusters can be well-defined. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] dynamicTreeCut_1.63-1 dendextend_1.12.0 [3] cluster_2.1.0 pheatmap_1.0.12 [5] scater_1.13.20 ggplot2_3.2.1 [7] scran_1.13.25 SingleCellExperiment_1.7.10 [9] SummarizedExperiment_1.15.9 DelayedArray_0.11.6 [11] BiocParallel_1.19.2 matrixStats_0.55.0 [13] Biobase_2.45.1 GenomicRanges_1.37.16 [15] GenomeInfoDb_1.21.1 IRanges_2.19.16 [17] S4Vectors_0.23.23 BiocGenerics_0.31.6 [19] Cairo_1.5-10 BiocStyle_2.13.2 [21] OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] viridis_0.5.1 edgeR_3.27.13 [3] BiocSingular_1.1.7 viridisLite_0.3.0 [5] DelayedMatrixStats_1.7.2 assertthat_0.2.1 [7] statmod_1.4.32 BiocManager_1.30.4 [9] highr_0.8 dqrng_0.2.1 [11] GenomeInfoDbData_1.2.1 vipor_0.4.5 [13] yaml_2.2.0 pillar_1.4.2 [15] lattice_0.20-38 glue_1.3.1 [17] limma_3.41.16 digest_0.6.21 [19] RColorBrewer_1.1-2 XVector_0.25.0 [21] colorspace_1.4-1 cowplot_1.0.0 [23] htmltools_0.3.6 Matrix_1.2-17 [25] pkgconfig_2.0.3 bookdown_0.13 [27] zlibbioc_1.31.0 purrr_0.3.2 [29] scales_1.0.0 Rtsne_0.15 [31] tibble_2.1.3 withr_2.1.2 [33] lazyeval_0.2.2 magrittr_1.5 [35] crayon_1.3.4 evaluate_0.14 [37] beeswarm_0.2.3 tools_3.6.1 [39] stringr_1.4.0 munsell_0.5.0 [41] locfit_1.5-9.1 irlba_2.3.3 [43] compiler_3.6.1 rsvd_1.0.2 [45] rlang_0.4.0 grid_3.6.1 [47] RCurl_1.95-4.12 BiocNeighbors_1.3.5 [49] igraph_1.2.4.1 bitops_1.0-6 [51] labeling_0.3 rmarkdown_1.15 [53] gtable_0.3.0 R6_2.4.0 [55] gridExtra_2.3 knitr_1.25 [57] dplyr_0.8.3 stringi_1.4.3 [59] ggbeeswarm_0.6.0 Rcpp_1.0.2 [61] tidyselect_0.2.5 xfun_0.9 Bibliography "],
["marker-gene-detection.html", "Chapter 11 Marker gene detection 11.1 Motivation 11.2 Using pairwise \\(t\\)-tests 11.3 Alternative testing regimes 11.4 Handling blocking factors 11.5 Using the block= argument 11.6 Using the design= argument 11.7 Invalidity of \\(p\\)-values Session Info", " Chapter 11 Marker gene detection .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 11.1 Motivation To interpret our clustering results from Chapter 10, we identify the genes that drive separation between clusters. These marker genes allow us to assign biological meaning to each cluster based on their functional annotation. In the most obvious case, the marker genes for each cluster are a priori associated with particular cell types, allowing us to treat the clustering as a proxy for cell type identity. The same principle can be applied to more subtle differences in activation status or differentiation state. Identification of marker genes is usually based around the retrospective detection of differential expression between clusters. Genes that are more strongly DE are more likely to have driven cluster separation in the first place. Several different statistical tests are available to quantify the differences in expression profiles, and different approaches can be used to consolidate test results into a single ranking of genes for each cluster. These choices parametrize the theroetical differences between the various marker detection strategies presented in this chapter. We will demonstrate using the 10X PBMC dataset: View history ### loading ### library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) ### gene-annotation ### library(scater) rownames(sce.pbmc) &lt;- uniquifyFeatureNames( rowData(sce.pbmc)$ID, rowData(sce.pbmc)$Symbol) library(EnsDb.Hsapiens.v86) location &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce.pbmc)$ID, column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) ### cell-detection ### set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] ### quality-control ### stats &lt;- perCellQCMetrics(sce.pbmc, subsets=list(Mito=which(location==&quot;MT&quot;))) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) sce.pbmc &lt;- sce.pbmc[,!high.mito] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.pbmc) sce.pbmc &lt;- computeSumFactors(sce.pbmc, cluster=clusters) sce.pbmc &lt;- logNormCounts(sce.pbmc) ### variance-modelling ### set.seed(1001) dec.pbmc &lt;- modelGeneVarByPoisson(sce.pbmc) ### dimensionality-reduction ### set.seed(10000) sce.pbmc &lt;- denoisePCA(sce.pbmc, technical=dec.pbmc) set.seed(100000) sce.pbmc &lt;- runTSNE(sce.pbmc, use_dimred=&quot;PCA&quot;) set.seed(1000000) sce.pbmc &lt;- runUMAP(sce.pbmc, use_dimred=&quot;PCA&quot;) ### clustering ### g &lt;- buildSNNGraph(sce.pbmc, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership sce.pbmc$cluster &lt;- factor(clust) sce.pbmc ## class: SingleCellExperiment ## dim: 33694 3922 ## metadata(1): Samples ## assays(2): counts logcounts ## rownames(33694): RP11-34P13.3 FAM138A ... AC213203.1 FAM231B ## rowData names(2): ID Symbol ## colnames(3922): AAACCTGAGAAGGCCT-1 AAACCTGAGACAGACC-1 ... ## TTTGTCACAGGTCCAC-1 TTTGTCATCCCAAGAT-1 ## colData names(3): Sample Barcode cluster ## reducedDimNames(3): PCA TSNE UMAP ## spikeNames(0): ## altExpNames(0): 11.2 Using pairwise \\(t\\)-tests 11.2.1 Standard application The Welch \\(t\\)-test is an obvious choice of statistical method to test for differences in expression between clusters. It is quickly computed and has good statistical properties for large numbers of cells (Soneson and Robinson 2018). We use the findMarkers() function to perform pairwise comparisons between clusters for each gene. This yields a list of DataFrames containing ranked candidate markers for each cluster. library(scran) markers.pbmc &lt;- findMarkers(sce.pbmc, sce.pbmc$cluster) markers.pbmc ## List of length 13 ## names(13): 1 2 3 4 5 6 7 8 9 10 11 12 13 To demonstrate, we use cluster 9 as our cluster of interest for this section. The relevant DataFrame contains log2-fold changes of expression in cluster 9 over each other cluster, along with several statistics obtained by combining \\(p\\)-values (Simes 1986) across the pairwise comparisons involving 9. chosen &lt;- &quot;9&quot; interesting &lt;- markers.pbmc[[chosen]] colnames(interesting) ## [1] &quot;Top&quot; &quot;p.value&quot; &quot;FDR&quot; &quot;logFC.1&quot; &quot;logFC.2&quot; &quot;logFC.3&quot; ## [7] &quot;logFC.4&quot; &quot;logFC.5&quot; &quot;logFC.6&quot; &quot;logFC.7&quot; &quot;logFC.8&quot; &quot;logFC.10&quot; ## [13] &quot;logFC.11&quot; &quot;logFC.12&quot; &quot;logFC.13&quot; Of particular interest is the Top field, which contains the highest2 rank for each gene across all pairwise comparisons involving cluster 9. The set of genes with Top values of 1 contains the gene with the lowest \\(p\\)-value from each comparison. Similarly, the set of genes with Top values less than or equal to 10 contains the top 10 genes from each comparison. Each DataFrame produced by findMarkers() will order genes based on the Top value. interesting[1:10,1:3] ## DataFrame with 10 rows and 3 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## RPL17 1 0 0 ## FCN1 1 0 0 ## CD79A 1 4.94065645841247e-324 3.10026192765382e-320 ## GZMA 1 1.37083742804146e-182 1.44340613438842e-179 ## HLA-DQA1 1 5.35073483016664e-102 1.33546414346397e-99 ## SERPINA1 1 3.25017479146583e-70 3.52126654095339e-68 ## RPS21 1 2.1210843180971e-59 1.60963547328749e-57 ## PF4 1 1.52287603660092e-34 4.54488796963962e-33 ## TAGLN2 1 1.17809170326906e-24 2.12497975642118e-23 ## TRAC 2 0 0 We use the Top value to identify a set of genes that is guaranteed to distinguish cluster 9 from any other cluster. Here, we examine the top 5 genes from each pairwise comparison (Figure 11.1). Some inspection of the most upregulated genes suggest that cluster 9 contains platelets or their precursors, based on the expression of platelet factor 4 (PF4) and pro-platelet basic protein (PPBP). best.set &lt;- interesting[interesting$Top &lt;= 6,] logFCs &lt;- as.matrix(best.set[,-(1:3)]) colnames(logFCs) &lt;- sub(&quot;logFC.&quot;, &quot;&quot;, colnames(logFCs)) library(pheatmap) pheatmap(logFCs, breaks=seq(-5, 5, length.out=101)) Figure 11.1: Heatmap of log-fold changes for cluster 9 over all other clusters. Colours are capped at -5 and 5 to preserve dynamic range. We intentionally use pairwise comparisons between clusters rather than comparing each cluster to the average of all other cells. The latter approach is sensitive to the population composition, potentially resulting in substantially different sets of markers when cell type abundances change in different contexts. In the worst case, the presence of a single dominant subpopulation will drive the selection of top markers for every other cluster, pushing out useful genes that can resolve the various minor subpopulations. Moreover, pairwise comparisons naturally provide more information to interpret of the utility of a marker, e.g., by providing log-fold changes to indicate which clusters are distinguished by each gene. 11.2.2 Using the log-fold change Our previous findMarkers() call considers both up- and downregulated genes to be potential markers. However, downregulated genes are less appealing as markers as it is more difficult to interpret and experimentally validate an absence of expression. To focus on up-regulated markers, we can instead perform a one-sided \\(t\\)-test to identify genes that are upregulated in each cluster compared to the others. This is achieved by setting direction=&quot;up&quot; in the findMarkers() call. markers.pbmc.up &lt;- findMarkers(sce.pbmc, sce.pbmc$cluster, direction=&quot;up&quot;) interesting.up &lt;- markers.pbmc.up[[chosen]] interesting.up[1:10,1:3] ## DataFrame with 10 rows and 3 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## PF4 1 7.61438018300458e-35 2.56558925886156e-30 ## TAGLN2 1 5.89045851634529e-25 6.61577030832462e-21 ## TMSB4X 2 9.43069564959569e-29 1.58878929608738e-24 ## SDPR 2 2.29014386984465e-21 1.92910268876363e-17 ## GPX1 2 1.26846364063111e-20 8.5479227814849e-17 ## NRGN 3 1.52237314064039e-20 8.5491401001229e-17 ## PPBP 3 2.51604788284947e-20 1.211081676639e-16 ## CCL5 5 2.89814903962751e-18 1.08500259712455e-14 ## GNG11 6 2.14726740611927e-18 9.04375349772286e-15 ## HIST1H2AC 8 1.20139521482572e-17 4.04798103683378e-14 The \\(t\\)-test also allows us to specify a non-zero log-fold change as the null hypothesis. This allows us to consider the magnitude of the log-fold change in our \\(p\\)-value calculations, in a manner that is more rigorous than simply filtering directly on the log-fold changes (McCarthy and Smyth 2009). (Specifically, a simple threshold does not consider the variance and can enrich for genes that have both large log-fold changes and large variances.) We perform this by setting lfc= in our findMarkers() call - when combined with direction=, this tests for genes with log-fold changes that are significantly greater than 1: markers.pbmc.up2 &lt;- findMarkers(sce.pbmc, sce.pbmc$cluster, direction=&quot;up&quot;, lfc=1) interesting.up2 &lt;- markers.pbmc.up2[[chosen]] interesting.up2[1:10,1:3] ## DataFrame with 10 rows and 3 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## PF4 1 2.47914071210115e-30 8.35321671535361e-26 ## TAGLN2 1 3.53618505519327e-20 3.97160730832274e-16 ## TMSB4X 2 9.05483585111085e-21 1.52546819583664e-16 ## SDPR 2 1.24358967592959e-17 1.04753776351929e-13 ## PPBP 3 3.25906892859222e-17 2.19622136959972e-13 ## NRGN 4 2.36955118201336e-16 1.3306609587793e-12 ## GPX1 5 2.97170317345641e-16 1.430408096092e-12 ## GNG11 5 1.0126662067301e-14 4.26509689619549e-11 ## CCL5 6 1.74016687637855e-14 6.51479808141098e-11 ## HIST1H2AC 7 4.01129147859347e-14 1.35156455079729e-10 These two settings yield a more focused set of candidate marker genes that are upregulated in cluster 9 (Figure 11.2). best.set &lt;- interesting.up2[interesting.up2$Top &lt;= 5,] logFCs &lt;- as.matrix(best.set[,-(1:3)]) colnames(logFCs) &lt;- sub(&quot;logFC.&quot;, &quot;&quot;, colnames(logFCs)) library(pheatmap) pheatmap(logFCs, breaks=seq(-5, 5, length.out=101)) Figure 11.2: Heatmap of log-fold changes for cluster 9 over all other clusters. Colours are capped at -5 and 5 to preserve dynamic range. Of course, this increased stringency is not without cost. If only upregulated genes are requested from findMarkers(), any cluster defined by downregulation of a marker gene will not contain that gene among the top set of features in its DataFrame. This is occasionally relevant for subtypes or other states that are distinguished by high versus low expression of particular genes3. Similarly, setting an excessively high log-fold change threshold may discard otherwise useful genes. For example, a gene upregulated in a small proportion of cells of a cluster will have a small log-fold change but can still be an effective marker if the focus is on specificity rather than sensitivity. 11.2.3 Finding cluster-specific markers By default, findMarkers() will give a high ranking to genes that are differentially expressed in any pairwise comparison. This is because a gene only needs a very low \\(p\\)-value in a single pairwise comparison to achieve a low Top value. A more stringent approach would only consider genes that are differentially expressed in all pairwise comparisons involving the cluster of interest. To achieve this, we set pval.type=&quot;all&quot; in findMarkers() to use an intersection-union test (Berger and Hsu 1996) where the combined \\(p\\)-value for each gene is the maximum of the \\(p\\)-values from all pairwise comparisons. A gene will only achieve a low combined \\(p\\)-value if it is strongly DE in all comparisons to other clusters. # We can combine this with &#39;direction=&#39;. markers.pbmc.up3 &lt;- findMarkers(sce.pbmc, sce.pbmc$cluster, pval.type=&quot;all&quot;, direction=&quot;up&quot;) interesting.up3 &lt;- markers.pbmc.up3[[chosen]] interesting.up3[1:10,1:2] ## DataFrame with 10 rows and 2 columns ## p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; ## SDPR 2.64542208645325e-21 8.91348517809558e-17 ## PF4 5.78149277110582e-21 9.74008087148196e-17 ## PPBP 3.96127718259098e-20 4.44904244634069e-16 ## NRGN 7.15349687737025e-20 6.02574809465284e-16 ## GNG11 2.16841693101845e-18 1.46125280147471e-14 ## HIST1H2AC 1.3567820455231e-17 7.6192357069759e-14 ## TUBB1 1.97176194003573e-17 9.49093525822337e-14 ## TAGLN2 3.60037071481044e-16 1.51638613581029e-12 ## CLU 3.32361900613725e-12 1.24428909769765e-08 ## MAP3K7CL 9.6425591324996e-11 3.24896387410442e-07 This strategy will only report genes that are highly specific to the cluster of interest. When it works, it can be highly effective as it generates a small focused set of candidate markers. However, any gene that is expressed at the same level in two or more clusters will simply not be detected. This is likely to discard many interesting genes, especially if the clusters are finely resolved with weak separation. To give a concrete example, consider a mixed population of CD4+-only, CD8+-only, double-positive and double-negative T cells. With pval.type=&quot;all&quot;, neither Cd4 or Cd8 would be detected as subpopulation-specific markers because each gene is expressed in two subpopulations. In comparison, pval.type=&quot;any&quot; will detect both of these genes as they will be DE between at least one pair of subpopulations. If pval.type=&quot;all&quot; is too stringent yet pval.type=&quot;any&quot; is too generous, a compromise is to set pval.type=&quot;some&quot;. For each gene, we apply the Holm-Bonferroni correction across its \\(p\\)-values and take the middle-most value as the combined \\(p\\)-value. This effectively tests the global null hypothesis that at least 50% of the individual pairwise comparisons exhibit no DE. We then rank the genes by their combined \\(p\\)-values to obtain an ordered set of marker candidates. The aim is to improve the conciseness of the top markers for defining a cluster while mitigating the risk of discarding useful genes that are not DE to all other clusters. The downside is that taking this compromise position sacrifices the theoretical guarantees offered at the other two extremes. markers.pbmc.up4 &lt;- findMarkers(sce.pbmc, sce.pbmc$cluster, pval.type=&quot;some&quot;, direction=&quot;up&quot;) interesting.up4 &lt;- markers.pbmc.up4[[chosen]] interesting.up4[1:10,1:2] ## DataFrame with 10 rows and 2 columns ## p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; ## PF4 1.34171594707861e-30 4.52077771208666e-26 ## TAGLN2 1.70785368525785e-20 2.21374764917867e-16 ## SDPR 1.97104616475812e-20 2.21374764917867e-16 ## NRGN 9.53525684636241e-20 8.03202360453334e-16 ## PPBP 2.0785213983819e-19 1.40067399994159e-15 ## TMSB4X 2.17861222131455e-18 1.22343600308287e-14 ## CCL5 1.22167377577337e-17 5.88043945727257e-14 ## GNG11 1.64141245721697e-17 6.91321891668358e-14 ## GPX1 3.062257061009e-17 1.14644099348486e-13 ## HIST1H2AC 7.11952649219178e-17 2.3988532562791e-13 11.3 Alternative testing regimes 11.3.1 Using the Wilcoxon rank sum test The Wilcoxon rank sum test (also known as the Wilcoxon-Mann-Whitney test, or WMW test) is another widely used method for pairwise comparisons between groups of observations. Its strength lies in the fact that it directly assesses separation between the expression distributions of different clusters. The WMW test statistic is proportional to the area-under-the-curve (AUC), i.e., the concordance probability, which is the probability of a random cell from one cluster having higher expression than a random cell from another cluster. In a pairwise comparison, AUCs of 1 or 0 indicate that the two clusters have perfectly separated expression distributions. Thus, the WMW test directly addresses the most desirable property of a candidate marker gene, while the \\(t\\) test only does so indirectly via the difference in the means and the intra-group variance. We perform WMW tests using the overlapExprs() function. This returns a list of DataFrames containing ranked candidate markers for each cluster. The direction=, lfc= and pval.type= arguments can be specified and have the same interpretation as described for \\(t\\) tests. We demonstrate below by detecting upregulated genes in each cluster with direction=&quot;up&quot;. markers.pbmc.wmw &lt;- findMarkers(sce.pbmc, test=&quot;wilcox&quot;, sce.pbmc$cluster, direction=&quot;up&quot;) names(markers.pbmc.wmw) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; &quot;11&quot; &quot;12&quot; &quot;13&quot; To explore the results in more detail, we focus on the DataFrame for cluster 9. The interpretation of Top is the same as described for \\(t\\) tests, and Simes’ method is again used to combine \\(p\\)-values across pairwise comparisons. interesting.wmw &lt;- markers.pbmc.wmw[[chosen]] interesting.wmw[1:10,1:3] ## DataFrame with 10 rows and 3 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## PF4 1 8.08836814327471e-171 2.72529476219502e-166 ## TMSB4X 1 4.35567099549791e-27 1.78975583563788e-24 ## SDPR 2 2.22549729387729e-154 3.74929529099511e-150 ## NRGN 2 1.23257738444852e-134 8.30609247832188e-131 ## TUBB1 3 2.51972786764474e-141 2.82999035908077e-137 ## PPBP 3 1.32349036700182e-139 1.11484211064399e-135 ## TAGLN2 3 6.93330922792726e-29 3.03390806656859e-26 ## GNG11 4 1.91716980133711e-131 1.07661865477089e-127 ## CLU 5 1.36333326086643e-125 6.56230727023318e-122 ## HIST1H2AC 5 3.49987765494615e-95 9.82707314214643e-92 The DataFrame contains the AUCs from comparing cluster 9 to every other cluster (Figure 11.3). A value greater than 0.5 indicates that the gene is upregulated in the current cluster compared to the other cluster, while values less than 0.5 correspond to downregulation. We would typically expect AUCs of 0.7-0.8 for a strongly upregulated candidate marker. best.set &lt;- interesting.wmw[interesting.wmw$Top &lt;= 5,] AUCs &lt;- as.matrix(best.set[,-(1:3)]) colnames(AUCs) &lt;- sub(&quot;AUC.&quot;, &quot;&quot;, colnames(AUCs)) library(pheatmap) pheatmap(AUCs, breaks=seq(0, 1, length.out=21), color=viridis::viridis(21)) Figure 11.3: Heatmap of AUCs for cluster 9 compared to all other clusters. The main disadvantage of the WMW test is that the AUCs are much slower to compute compared to \\(t\\)-statistics. This may be inconvenient for interactive analyses involving multiple iterations of marker detection. We can mitigate this to some extent by parallelizing these calculations using the BPPARAM= argument in overlapExprs(). 11.3.2 Using a binomial test The binomial test identifies genes that differ in the proportion of expressing cells between clusters. (For the purposes of this section, a cell is considered to express a gene simply if it has non-zero expression for that gene.) This represents a much more stringent definition of marker genes compared to the other methods, as differences in expression between clusters are effectively ignored if both distributions of expression values are not near zero. The premise is that genes are more likely to contribute to important biological decisions if they were active in one cluster and silent in another, compared to more subtle “tuning” effects from changing the expression of an active gene. From a practical perspective, a binary measure of presence/absence is easier to validate. We perform pairwise binomial tests between clusters using the pairwiseBinom() function. This returns a list of DataFrames containing marker statistics for each cluster, such as the Top rank and its \\(p\\)-value. Here, the effect size is reported as the log-fold change in this proportion between each pair of clusters. Large positive log-fold changes indicate that the gene is more frequently expressed in one cluster compared to the other. Here, we focus on genes that are upregulated in each cluster compared to the others by setting direction=&quot;up&quot;. markers.pbmc.binom &lt;- findMarkers(sce.pbmc, test=&quot;binom&quot;, sce.pbmc$cluster, direction=&quot;up&quot;) names(markers.pbmc.binom) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; &quot;11&quot; &quot;12&quot; &quot;13&quot; interesting.binom &lt;- markers.pbmc.binom[[chosen]] colnames(interesting.binom) ## [1] &quot;Top&quot; &quot;p.value&quot; &quot;FDR&quot; &quot;logFC.1&quot; &quot;logFC.2&quot; &quot;logFC.3&quot; ## [7] &quot;logFC.4&quot; &quot;logFC.5&quot; &quot;logFC.6&quot; &quot;logFC.7&quot; &quot;logFC.8&quot; &quot;logFC.10&quot; ## [13] &quot;logFC.11&quot; &quot;logFC.12&quot; &quot;logFC.13&quot; Figure 11.4 confirms that the top genes exhibit strong differences in the proportion of expressing cells in cluster 9 compared to the others. library(scater) top.genes &lt;- head(rownames(interesting.binom)) plotExpression(sce.pbmc, x=&quot;cluster&quot;, features=top.genes) Figure 11.4: Distribution of log-normalized expression values for the top 10 DE genes involving cluster 9 with the binomial test, stratified by cluster assignment and coloured by the plate of origin for each cell. The disadvantage of the binomial test is that its increased stringency can lead to the loss of good candidate markers. For example, GCG is a known marker for pancreatic alpha cells but is expressed in almost every other cell of the Lawlor et al. (2017) pancreas data (Figure 11.5) and would not be highly ranked by the binomial test. View history ### loading ### library(scRNAseq) sce.lawlor &lt;- LawlorPancreasData() ### gene-annotation ### library(AnnotationHub) edb &lt;- AnnotationHub()[[&quot;AH73881&quot;]] anno &lt;- select(edb, keys=rownames(sce.lawlor), keytype=&quot;GENEID&quot;, columns=c(&quot;SYMBOL&quot;, &quot;SEQNAME&quot;)) rowData(sce.lawlor) &lt;- anno[match(rownames(sce.lawlor), anno[,1]),-1] ### quality-control ### library(scater) stats &lt;- perCellQCMetrics(sce.lawlor, subsets=list(Mito=which(rowData(sce.lawlor)$SEQNAME==&quot;MT&quot;))) qc &lt;- quickCellQC(stats, percent_subsets=&quot;subsets_Mito_percent&quot;, nmads=3) sce.lawlor &lt;- sce.lawlor[,!qc$discard] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.lawlor) sce.lawlor &lt;- computeSumFactors(sce.lawlor, clusters=clusters) sce.lawlor &lt;- logNormCounts(sce.lawlor) plotExpression(sce.lawlor, x=&quot;cell type&quot;, features=&quot;ENSG00000115263&quot;) Figure 11.5: Distribution of log-normalized expression values for GCG across different pancreatic cell types in GSE86469. Another property of the binomial test is that it will not respond to scaling normalization. Systematic differences in library size between clusters will not be considered when computing \\(p\\)-values or effect sizes. This is not necessarily problematic for marker gene detection - users can treat this as retaining information about the total RNA content, analogous to spike-in normalization. 11.3.3 Using custom DE methods It is possible to perform marker gene detection based on precomputed DE statistics. This allows us to take advantage of more sophisticated tests in dedicated DE analysis packages. To demonstrate, consider the voom() approach from the limma package (Law et al. 2014). We first process our SingleCellExperiment to obtain a fit object as shown below. library(limma) design &lt;- model.matrix(~0 + cluster, data=colData(sce.pbmc)) colnames(design) ## [1] &quot;cluster1&quot; &quot;cluster2&quot; &quot;cluster3&quot; &quot;cluster4&quot; &quot;cluster5&quot; ## [6] &quot;cluster6&quot; &quot;cluster7&quot; &quot;cluster8&quot; &quot;cluster9&quot; &quot;cluster10&quot; ## [11] &quot;cluster11&quot; &quot;cluster12&quot; &quot;cluster13&quot; # Removing very low-abundance genes. keep &lt;- calculateAverage(sce.pbmc) &gt; 0.1 summary(keep) ## Mode FALSE TRUE ## logical 29480 4214 y &lt;- convertTo(sce.pbmc, subset.row=keep) v &lt;- voom(y, design) fit &lt;- lmFit(v, design) We then perform pairwise comparisons between clusters using the TREAT strategy (McCarthy and Smyth 2009) to test for log-fold changes that are significantly greater than 0.5. For each comparison, we store the corresponding data frame of statistics in all.results, along with the identities of the clusters involved in all.pairs. nclust &lt;- length(unique(sce.pbmc$cluster)) all.results &lt;- all.pairs &lt;- list() counter &lt;- 1L # Iterating across the first &#39;nclust&#39; coefficients in design, # and comparing them to each other in a pairwise manner. for (x in seq_len(nclust)) { for (y in seq_len(x-1L)) { con &lt;- integer(ncol(design)) con[x] &lt;- 1 con[y] &lt;- -1 fit2 &lt;- contrasts.fit(fit, con) fit2 &lt;- treat(fit2, robust=TRUE, lfc=0.5) res &lt;- topTreat(fit2, n=Inf, sort.by=&quot;none&quot;) all.results[[counter]] &lt;- res all.pairs[[counter]] &lt;- colnames(design)[c(x, y)] counter &lt;- counter+1L # Also filling the reverse comparison. res$logFC &lt;- -res$logFC all.results[[counter]] &lt;- res all.pairs[[counter]] &lt;- colnames(design)[c(y, x)] counter &lt;- counter+1L } } These custom results are consolidated into a single marker list for each cluster with the combineMarkers() function. This combines test statistics across all pairwise comparisons involving a single cluster, yielding a per-cluster DataFrame that can be interpreted in the same manner as discussed previously. all.pairs &lt;- do.call(rbind, all.pairs) combined &lt;- combineMarkers(all.results, all.pairs, pval.field=&quot;P.Value&quot;) # Inspecting results for our cluster of interest again. interesting.voom &lt;- combined[[paste0(&quot;cluster&quot;, chosen)]] colnames(interesting.voom) ## [1] &quot;Top&quot; &quot;p.value&quot; &quot;FDR&quot; ## [4] &quot;logFC.cluster1&quot; &quot;logFC.cluster2&quot; &quot;logFC.cluster3&quot; ## [7] &quot;logFC.cluster4&quot; &quot;logFC.cluster5&quot; &quot;logFC.cluster6&quot; ## [10] &quot;logFC.cluster7&quot; &quot;logFC.cluster8&quot; &quot;logFC.cluster10&quot; ## [13] &quot;logFC.cluster11&quot; &quot;logFC.cluster12&quot; &quot;logFC.cluster13&quot; head(interesting.voom[,1:3]) ## DataFrame with 6 rows and 3 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## CD160 1 0 0 ## RGS18 1 0 0 ## C2orf88 1 0 0 ## SDPR 1 0 0 ## PPBP 1 0 0 ## HIST2H2BE 2 0 0 By default, we do not use custom DE methods to perform marker detection, for several reasons. Many of these methods rely on empirical Bayes shrinkage to share information across genes in the presence of limited replication. However, this is unnecessary when there are large numbers of “replicate” cells in each group (Section 11.7.2). These methods also make stronger assumptions about the data (e.g., equal variances for linear models, the distribution of variances during empirical Bayes) that are more likely to be violated in noisy scRNA-seq contexts. From a practical perspective, they require more work to set up and take more time to run. Nonetheless, some custom methods (e.g., MAST) may provide a useful point of difference from the simpler tests, in which case they can be converted into a marker detection scheme as described above. 11.4 Handling blocking factors 11.5 Using the block= argument Large studies may contain factors of variation that are known and not interesting (e.g., batch effects, sex differences). If these are not modelled, they can interfere with marker gene detection - most obviously by inflating the variance within each cluster, but also by distorting the log-fold changes if the cluster composition varies across levels of the blocking factor. To avoid these issues, we set the block= argument in the findMarkers() call, as demonstrated below for the 416B data set. View history ### loading ### library(scRNAseq) sce.416b &lt;- LunSpikeInData(which=&quot;416b&quot;) sce.416b$block &lt;- factor(sce.416b$block) ### gene-annotation ### library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] rowData(sce.416b)$ENSEMBL &lt;- rownames(sce.416b) rowData(sce.416b)$SYMBOL &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SYMBOL&quot;) rowData(sce.416b)$SEQNAME &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) library(scater) rownames(sce.416b) &lt;- uniquifyFeatureNames(rowData(sce.416b)$ENSEMBL, rowData(sce.416b)$SYMBOL) ### quality-control ### mito &lt;- which(rowData(sce.416b)$SEQNAME==&quot;MT&quot;) stats &lt;- perCellQCMetrics(sce.416b, subsets=list(Mt=mito)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;subsets_Mt_percent&quot;, &quot;altexps_ERCC_percent&quot;), nmads=3, batch=sce.416b$block) sce.416b &lt;- sce.416b[,!qc$discard] ### normalization ### library(scran) sce.416b &lt;- computeSumFactors(sce.416b) sce.416b &lt;- logNormCounts(sce.416b) ### variance-modelling ### dec.416b &lt;- modelGeneVarWithSpikes(sce.416b, &quot;ERCC&quot;, block=sce.416b$block) ### batch-correction ### library(limma) assay(sce.416b, &quot;corrected&quot;) &lt;- removeBatchEffect(logcounts(sce.416b), design=model.matrix(~sce.416b$phenotype), batch=sce.416b$block) ### dimensionality-reduction ### sce.416b &lt;- denoisePCA(sce.416b, technical=dec.416b, assay.type=&quot;corrected&quot;, BSPARAM=BiocSingular::ExactParam()) set.seed(1010) sce.416b &lt;- runTSNE(sce.416b, dimred=&quot;PCA&quot;, perplexity=10) ### clustering ### my.dist &lt;- dist(reducedDim(sce.416b, &quot;PCA&quot;)) my.tree &lt;- hclust(my.dist, method=&quot;ward.D2&quot;) library(dynamicTreeCut) my.clusters &lt;- unname(cutreeDynamic(my.tree, distM=as.matrix(my.dist), minClusterSize=10, verbose=0)) sce.416b$cluster &lt;- factor(my.clusters) m.out &lt;- findMarkers(sce.416b, sce.416b$cluster, block=sce.416b$block, direction=&quot;up&quot;) For each gene, each pairwise comparion between clusters is performed separately in each level of the blocking factor - in this case, the plate of origin. The function will then combine \\(p\\)-values from different plates using Stouffer’s Z method to obtain a single \\(p\\)-value per pairwise comparison. (These \\(p\\)-values are further combined across comparisons to obtain a single \\(p\\)-value per gene, using either Simes’ method or an intersection-union test depending on the value of pval.type=.) This approach favours genes that exhibit consistent DE in the same direction in each plate. demo &lt;- m.out[[&quot;1&quot;]] demo[demo$Top &lt;= 5,1:3] ## DataFrame with 13 rows and 3 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## Myh11 1 8.70379353665452e-50 4.05631593982246e-45 ## Foxs1 1 5.70065284566248e-12 2.45993727054865e-09 ## Pirb 2 3.9893384208383e-35 9.29595638823736e-31 ## Pi16 2 5.87787756676202e-30 9.13108687071258e-26 ## Ctsd 2 8.7964905427809e-25 5.12439556569701e-21 ## ... ... ... ... ## Tob1 3 1.2226704656241e-08 2.57834092216949e-06 ## Capn3 4 4.02212797192884e-08 7.6509082450519e-06 ## Cd200r3 5 9.59924230550639e-29 7.45605147343032e-25 ## Actb 5 1.58583399956688e-24 8.2118008573128e-21 ## Ftl1 5 2.39096821095955e-21 6.96429265647241e-18 The block= argument works with all tests shown above and is robust to difference in the log-fold changes or variance between batches. However, it assumes that each pair of clusters is present in at least one batch. In scenarios where cells from two clusters never co-occur in the same batch, the comparison will be impossible and NAs will be reported in the output. 11.6 Using the design= argument Another approach is to define a design matrix containing the batch of origin as the sole factor. findMarkers() will then fit a linear model to the log-expression values, similar to the use of limma for bulk RNA sequencing data (Ritchie et al. 2015). This handles situations where multiple batches contain unique clusters, as comparisons can be implicitly performed via shared cell types in each batch. There is also a slight increase in power when information is shared across clusters for variance estimation. # Setting up the design matrix (we remove intercept for full rank # in the final design matrix with the cluster-specific terms). design &lt;- model.matrix(~sce.416b$block) design &lt;- design[,-1,drop=FALSE] m.alt &lt;- findMarkers(sce.416b, sce.416b$cluster, design=design, direction=&quot;up&quot;) demo &lt;- m.alt[[&quot;1&quot;]] demo[demo$Top &lt;= 5,1:3] ## DataFrame with 13 rows and 3 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## Myh11 1 3.2940708772022e-54 1.53516879161131e-49 ## Cd63-ps 1 9.88458944329369e-13 4.4724408389831e-10 ## Cd200r3 2 1.6929567812913e-40 3.94492789176498e-36 ## Tmsb4x 2 5.95298117666334e-40 9.2477578252406e-36 ## Cd63 2 2.35199836630116e-13 1.17862937487204e-10 ## ... ... ... ... ## Itga6 4 3.31744129988919e-30 2.20865763342909e-26 ## Pirb 4 3.449405470832e-27 1.14825780401896e-23 ## CBFB-MYH11-mcherry 5 1.64972827264695e-33 1.53767872836876e-29 ## Capg 5 4.93283561269364e-28 2.29889870893975e-24 ## Fth1 5 8.32037154463384e-20 1.10789312990319e-16 The use of a linear model makes some strong assumptions, necessitating some caution when interpreting the results. If the batch effect is not consistent across clusters, the variance will be inflated and the log-fold change estimates will be distorted. Variances are also assumed to be equal across groups, which is not true in general. In particular, the presence of clusters in which a gene is silent will shrink the residual variance towards zero, preventing the model from penalizing genes with high variance in other clusters. Thus, we generally recommend the use of block= where possible. 11.7 Invalidity of \\(p\\)-values 11.7.1 From data snooping All of our DE strategies for detecting marker genes between clusters are statistically flawed to some extent. The DE analysis is performed on the same data used to obtain the clusters, which represents “data dredging” (also known as fishing or data snooping). The hypothesis of interest - are there differences between clusters? - is formulated from the data, so we are more likely to get a positive result when we re-use the data set to test that hypothesis. The practical effect of data dredging is best illustrated with a simple simulation. We simulate i.i.d. normal values, perform \\(k\\)-means clustering and test for DE between clusters of cells with findMarkers(). The resulting distribution of \\(p\\)-values is heavily skewed towards low values (Figure 11.6). Thus, we can detect “significant” differences between clusters even in the absence of any real substructure in the data. This effect arises from the fact that clustering, by definition, yields groups of cells that are separated in expression space. Testing for DE genes between clusters will inevitably yield some significant results as that is how the clusters were defined. library(scran) set.seed(0) y &lt;- matrix(rnorm(100000), ncol=200) clusters &lt;- kmeans(t(y), centers=2)$cluster out &lt;- findMarkers(y, clusters) hist(out[[1]]$p.value, col=&quot;grey80&quot;, xlab=&quot;p-value&quot;) Figure 11.6: Distribution of \\(p\\)-values from a DE analysis between two clusters in a simulation with no true subpopulation structure. For marker gene detection, this effect is largely harmless as the \\(p\\)-values are used only for ranking. However, it becomes an issue when the \\(p\\)-values are used to define “significant differences” between clusters with respect to an error rate threshold. Meaningful interpretation of error rates require consideration of the long-run behaviour, i.e., the rate of incorrect rejections if the experiment were repeated many times. The concept of statistical significance for differences between clusters is not applicable if clusters and their interpretations are not stably reproducible across (hypothetical) replicate experiments. 11.7.2 Nature of replication The naive application of DE analysis methods will treat counts from the same cluster of cells as replicate observations. This is not the most relevant level of replication when cells are derived from the same biological sample (i.e., cell culture, animal or patient). DE analyses that treat cells as replicates fail to properly model the sample-to-sample variability (A. T. L. Lun and Marioni 2017). The latter is arguably the more important level of replication as different samples will necessarily be generated if the experiment is to be replicated. Indeed, the use of cells as replicates only masks the fact that the sample size is actually one in an experiment involving a single biological sample. This reinforces the inappropriateness of using the marker gene \\(p\\)-values to perform statistical inference. We strongly recommend selecting some markers for use in validation studies with an independent replicate population of cells. A typical strategy is to identify a corresponding subset of cells that express the upregulated markers and do not express the downregulated markers. Ideally, a different technique for quantifying expression would also be used during validation, e.g., fluorescent in situ hybridisation or quantitative PCR. This confirms that the subpopulation genuinely exists and is not an artifact of the scRNA-seq protocol or the computational analysis. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] limma_3.41.16 scater_1.13.20 [3] ggplot2_3.2.1 pheatmap_1.0.12 [5] scran_1.13.25 SingleCellExperiment_1.7.10 [7] SummarizedExperiment_1.15.9 DelayedArray_0.11.6 [9] BiocParallel_1.19.2 matrixStats_0.55.0 [11] Biobase_2.45.1 GenomicRanges_1.37.16 [13] GenomeInfoDb_1.21.1 IRanges_2.19.16 [15] S4Vectors_0.23.23 BiocGenerics_0.31.6 [17] Cairo_1.5-10 BiocStyle_2.13.2 [19] OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] viridis_0.5.1 edgeR_3.27.13 [3] BiocSingular_1.1.7 viridisLite_0.3.0 [5] DelayedMatrixStats_1.7.2 assertthat_0.2.1 [7] statmod_1.4.32 BiocManager_1.30.4 [9] highr_0.8 dqrng_0.2.1 [11] GenomeInfoDbData_1.2.1 vipor_0.4.5 [13] yaml_2.2.0 pillar_1.4.2 [15] lattice_0.20-38 glue_1.3.1 [17] digest_0.6.21 RColorBrewer_1.1-2 [19] XVector_0.25.0 colorspace_1.4-1 [21] cowplot_1.0.0 htmltools_0.3.6 [23] Matrix_1.2-17 pkgconfig_2.0.3 [25] bookdown_0.13 zlibbioc_1.31.0 [27] purrr_0.3.2 scales_1.0.0 [29] tibble_2.1.3 withr_2.1.2 [31] lazyeval_0.2.2 magrittr_1.5 [33] crayon_1.3.4 evaluate_0.14 [35] beeswarm_0.2.3 tools_3.6.1 [37] stringr_1.4.0 munsell_0.5.0 [39] locfit_1.5-9.1 irlba_2.3.3 [41] compiler_3.6.1 rsvd_1.0.2 [43] rlang_0.4.0 grid_3.6.1 [45] RCurl_1.95-4.12 BiocNeighbors_1.3.5 [47] igraph_1.2.4.1 labeling_0.3 [49] bitops_1.0-6 rmarkdown_1.15 [51] gtable_0.3.0 R6_2.4.0 [53] gridExtra_2.3 knitr_1.25 [55] dplyr_0.8.3 stringi_1.4.3 [57] ggbeeswarm_0.6.0 Rcpp_1.0.2 [59] tidyselect_0.2.5 xfun_0.9 Bibliography "],
["cell-type-annotation.html", "Chapter 12 Cell type annotation 12.1 Motivation 12.2 Assigning cell labels from reference data 12.3 Assigning cell labels from gene sets 12.4 Assigning cluster labels from markers Session Info", " Chapter 12 Cell type annotation .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 12.1 Motivation The most challenging task in scRNA-seq data analysis is arguably the interpretation of the results. Obtaining clusters of cells is fairly straightforward, but it is more difficult to determine what biological state is represented by each of those clusters. Doing so requires us to bridge the gap between the current dataset and prior biological knowledge, and the latter is not always available in a consistent and quantitative manner4. Indeed, even the concept of a “cell type” is not clearly defined, with most practitioners possessing a “I’ll know it when I see it” intuition that is not amenable to computational analysis. As such, intepretation of scRNA-seq data is often manual and a common bottleneck in the analysis workflow. To expedite this step, we can use various computational approaches that exploit prior information to assign meaning to an uncharacterized scRNA-seq dataset. The most obvious sources of prior information are the curated gene sets associated with particular biological processes, e.g., from the Gene Ontology (GO) or the Kyoto Encyclopedia of Genes and Genomes (KEGG) collections. Alternatively, we can directly compare our expression profiles to published reference datasets where each sample or cell has already been annotated with its putative biological state by domain experts. Here, we will demonstrate both approaches with several different scRNA-seq datasets. 12.2 Assigning cell labels from reference data 12.2.1 Overview A conceptually straightforward annotation approach is to compare the single-cell expression profiles with previously annotated reference datasets. Labels can then be assigned to each cell in our uncharacterized test dataset based on the most similar reference sample(s), for some definition of “similar”. This is a standard classification challenge that can be tackled by standard machine learning techniques such as random forests and support vector machines. Any published and labelled RNA-seq dataset (bulk or single-cell) can be used as a reference, though its reliability depends greatly on the expertise of the original authors who assigned the labels in the first place. In this section, we will demonstrate the use of the SingleR method (Aran et al. 2019) for cell type annotation. This method assigns labels to cells based on the reference samples with the highest Spearman rank correlations, and thus can be considered a rank-based variant of \\(k\\)-nearest-neighbor classification. To reduce noise, SingleR identifies marker genes between pairs of labels and computes the correlation using only those markers. It also performs a fine-tuning step for each cell where calculation of the correlations is repeated with just the marker genes for the top-scoring labels. This aims to resolve any ambiguity between those labels by removing noise from irrelevant markers for other labels. 12.2.2 Using the in-built references SingleR contains a number of built-in reference datasets, mostly assembled from bulk RNA-seq or microarray data of sorted cell types. These built-in references are often good enough for most applications, provided that they contain the cell types that are expected in the test population. We will demonstrate on the 10X PBMC dataset using a reference constructed from Blueprint and ENCODE data (Martens and Stunnenberg 2013; The ENCODE Project Consortium 2012). View history ### loading ### library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) ### gene-annotation ### library(scater) rownames(sce.pbmc) &lt;- uniquifyFeatureNames( rowData(sce.pbmc)$ID, rowData(sce.pbmc)$Symbol) library(EnsDb.Hsapiens.v86) location &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce.pbmc)$ID, column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) ### cell-detection ### set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] ### quality-control ### stats &lt;- perCellQCMetrics(sce.pbmc, subsets=list(Mito=which(location==&quot;MT&quot;))) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) sce.pbmc &lt;- sce.pbmc[,!high.mito] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.pbmc) sce.pbmc &lt;- computeSumFactors(sce.pbmc, cluster=clusters) sce.pbmc &lt;- logNormCounts(sce.pbmc) ### variance-modelling ### set.seed(1001) dec.pbmc &lt;- modelGeneVarByPoisson(sce.pbmc) ### dimensionality-reduction ### set.seed(10000) sce.pbmc &lt;- denoisePCA(sce.pbmc, technical=dec.pbmc) set.seed(100000) sce.pbmc &lt;- runTSNE(sce.pbmc, use_dimred=&quot;PCA&quot;) set.seed(1000000) sce.pbmc &lt;- runUMAP(sce.pbmc, use_dimred=&quot;PCA&quot;) ### clustering ### g &lt;- buildSNNGraph(sce.pbmc, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership sce.pbmc$cluster &lt;- factor(clust) sce.pbmc ## class: SingleCellExperiment ## dim: 33694 3922 ## metadata(1): Samples ## assays(2): counts logcounts ## rownames(33694): RP11-34P13.3 FAM138A ... AC213203.1 FAM231B ## rowData names(2): ID Symbol ## colnames(3922): AAACCTGAGAAGGCCT-1 AAACCTGAGACAGACC-1 ... ## TTTGTCACAGGTCCAC-1 TTTGTCATCCCAAGAT-1 ## colData names(3): Sample Barcode cluster ## reducedDimNames(3): PCA TSNE UMAP ## spikeNames(0): ## altExpNames(0): We label our PBMCs using the SingleR() function with the main cell type labels in the reference. This returns a DataFrame where each row corresponds to a cell in the test dataset and contains its label assignments. Alternatively, we could use the labels in ref$label.fine, which provide more resolution at the cost of speed and increased ambiguity in the assignments. library(SingleR) ref &lt;- BlueprintEncodeData() pred &lt;- SingleR(test=sce.pbmc, ref=ref, labels=ref$label.main) table(pred$labels) ## ## B-cells CD4+ T-cells CD8+ T-cells Erythrocytes HSC ## 527 749 1257 3 15 ## Macrophages Monocytes NK cells ## 1 1116 254 We inspect the results using a heatmap of the per-cell and label scores (Figure 12.1). Ideally, each cell should exhibit a high score in one label relative to all of the others, indicating that the assignment to that label was unambiguous. This is largely the case for monocytes and B cells, whereas we see more ambiguity between CD4+ and CD8+ T cells (and to a lesser extent, NK cells). plotScoreHeatmap(pred) Figure 12.1: Heatmap of the assignment score for each cell (column) and label (row). Scores are shown before any fine-tuning and are normalized to [0, 1] within each cell. SingleR() will attempt to prune out low-quality assignments by marking them as NA. This is done based on the difference \\(\\Delta_{med}\\) of the assigned label’s score from the median score within each cell. Small \\(\\Delta_{med}\\) values indicate that the cell assignment was so uncertain that the reported label is not much better than the bulk of other labels in the reference. We set a minimum threshold on the acceptable \\(\\Delta_{med}\\) using an outlier-based approach for each label, where labels with \\(\\Delta_{med}\\) that are substantially lower than the majority of values for a given label are marked as NA (Figure 12.2). If necessary, more control over the pruning can be achieved by supplying custom parameters to the pruneScores() function. sum(is.na(pred$pruned.labels)) ## [1] 83 plotScoreDistribution(pred) Figure 12.2: Distribution of the per-cell \\(\\Delta_{med}\\) for each label. Each panel corresponds to one label and stratifies the population into cells that were assigned to that label and not pruned; cells that were assigned to that label and pruned out; and cells that were not assigned to that label. We compare the assignments with the clustering results to determine the identity of each cluster. Ideally, clusters and labels would have a 1:1 relationship, though some nesting is likely depending on the resolution of the clustering algorithm. For example, several clusters are nested within the monocyte and B cell labels, suggesting the the former represent finer subdivisions within the latter. Interestingly, our clustering does not effectively distinguish between CD4+ and CD8+ T cell labels. We attribute this to the presence of other factors of heterogeneity within the T cell subpopulation (specifically, naive versus stimulated) that have a stronger influence on unsupervised methods than the a priori expected CD4/CD8 distinction. table(Assigned=pred$pruned.labels, Cluster=sce.pbmc$cluster) ## Cluster ## Assigned 1 2 3 4 5 6 7 8 9 10 11 12 13 ## B-cells 0 0 0 0 1 503 0 0 0 0 0 0 16 ## CD4+ T-cells 0 0 1 1 239 0 0 423 0 76 0 2 0 ## CD8+ T-cells 1 4 0 485 272 8 0 401 0 74 0 2 0 ## Erythrocytes 0 0 0 0 0 0 0 0 2 0 0 1 0 ## HSC 0 0 0 0 9 0 0 0 0 0 0 0 6 ## Macrophages 0 0 0 0 0 0 1 0 0 0 0 0 0 ## Monocytes 778 0 54 0 0 0 127 0 0 0 92 0 14 ## NK cells 0 190 1 52 1 2 0 0 0 0 0 0 0 This episode highlights some of the differences between reference-based annotation and unsupervised clustering. The former explicitly focuses on aspects of the data that are known to be interesting, simplifying the process of biological interpretation. However, the cost is that the downstream analysis is restricted by the diversity and resolution of the available labels. We suggest applying both strategies and, if major disagreements are present between reference label and cluster assignments, using those discrepancies as the basis for further investigation to discover novel effects. 12.2.3 Using custom references It is also straightforward to apply SingleR to user-supplied reference datasets. For bulk references, the same code shown above can be used, while some additional work is required for single-cell references. To illustrate, we will use the Muraro et al. (2016) human pancreas dataset as our reference. View history ### loading ### library(scRNAseq) sce.muraro &lt;- MuraroPancreasData() ### gene-annotation ### library(AnnotationHub) edb &lt;- AnnotationHub()[[&quot;AH73881&quot;]] gene.symb &lt;- sub(&quot;__chr.*$&quot;, &quot;&quot;, rownames(sce.muraro)) gene.ids &lt;- mapIds(edb, keys=gene.symb, keytype=&quot;SYMBOL&quot;, column=&quot;GENEID&quot;) # Removing duplicated genes or genes without Ensembl IDs. keep &lt;- !is.na(gene.ids) &amp; !duplicated(gene.ids) sce.muraro &lt;- sce.muraro[keep,] rownames(sce.muraro) &lt;- gene.ids[keep] ### quality-control ### library(scater) stats &lt;- perCellQCMetrics(sce.muraro) qc &lt;- quickCellQC(stats, nmads=3, percent_subsets=&quot;altexps_ERCC_percent&quot;) sce.muraro &lt;- sce.muraro[,!qc$discard] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.muraro) sce.muraro &lt;- computeSumFactors(sce.muraro, min.mean=0.1, clusters=clusters) sce.muraro &lt;- logNormCounts(sce.muraro) sce.muraro ## class: SingleCellExperiment ## dim: 16940 2346 ## metadata(0): ## assays(2): counts logcounts ## rownames(16940): ENSG00000268895 ENSG00000121410 ... ## ENSG00000159840 ENSG00000074755 ## rowData names(2): symbol chr ## colnames(2346): D28-1_1 D28-1_2 ... D30-8_93 D30-8_94 ## colData names(3): label donor plate ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(1): ERCC sce.muraro &lt;- sce.muraro[,!is.na(sce.muraro$label) &amp; sce.muraro$label!=&quot;unclear&quot;] table(sce.muraro$label) ## ## acinar alpha beta delta duct endothelial ## 218 803 446 191 242 20 ## epsilon mesenchymal pp ## 3 80 99 We use methods from scran to generate marker sets for every reference label (Chapter 29.2.8). Here, we use the pairwiseWilcox() and getTopMarkers() functions to take the top 10 upregulated genes from each pairwise comparison between reference labels, using the Wilcoxon test with a log-fold change threshold of 1. This enables us to select a custom set of marker genes that is both discriminative and concise, which is faster to run and often more effective for single-cell references than the default marker set that is auto-generated inside SingleR(). (We could also use this custom approach for our bulk references, but the default is more convenient and often works well enough.) library(scran) pairwise.muraro &lt;- pairwiseWilcox(logcounts(sce.muraro), sce.muraro$label, direction=&quot;up&quot;, lfc=1) muraro.markers &lt;- getTopMarkers(pairwise.muraro$statistics, pairwise.muraro$pairs, n=10) muraro.markers ## List of length 9 ## names(9): acinar alpha beta delta duct endothelial epsilon mesenchymal pp We use these newly identified markers in SingleR() to assign labels to our test dataset from Segerstolpe et al. (2016). As it so happens, we are in the fortunate position where our test dataset also contains independently defined labels. We see strong consistency between the two sets of labels (Figure 12.3), indicating that our automatic annotation is comparable to that generated manually by domain experts. View history ### loading ### library(scRNAseq) sce.seger &lt;- SegerstolpePancreasData() ### gene-annotation ### library(AnnotationHub) edb &lt;- AnnotationHub()[[&quot;AH73881&quot;]] symbols &lt;- rowData(sce.seger)$symbol ens.id &lt;- mapIds(edb, keys=symbols, keytype=&quot;SYMBOL&quot;, column=&quot;GENEID&quot;) ens.id &lt;- ifelse(is.na(ens.id), symbols, ens.id) # Removing duplicated rows. keep &lt;- !duplicated(ens.id) sce.seger &lt;- sce.seger[keep,] rownames(sce.seger) &lt;- ens.id[keep] ### sample-annotation ### emtab.meta &lt;- colData(sce.seger)[,c(&quot;cell type&quot;, &quot;individual&quot;, &quot;single cell well quality&quot;)] colnames(emtab.meta) &lt;- c(&quot;CellType&quot;, &quot;Donor&quot;, &quot;Quality&quot;) colData(sce.seger) &lt;- emtab.meta sce.seger$CellType &lt;- gsub(&quot; cell&quot;, &quot;&quot;, sce.seger$CellType) sce.seger$CellType &lt;- paste0( toupper(substr(sce.seger$CellType, 1, 1)), substring(sce.seger$CellType, 2)) ### quality-control ### low.qual &lt;- sce.seger$Quality == &quot;low quality cell&quot; library(scater) stats &lt;- perCellQCMetrics(sce.seger) qc &lt;- quickCellQC(stats, nmads=3, percent_subsets=&quot;altexps_ERCC_percent&quot;) sce.seger &lt;- sce.seger[,!(qc$discard | low.qual)] ### normalization ### library(scran) clusters &lt;- quickCluster(sce.seger) sce.seger &lt;- computeSumFactors(sce.seger, clusters=clusters) sce.seger &lt;- logNormCounts(sce.seger, use_altexps=FALSE) pred.seger &lt;- SingleR(test=sce.seger, ref=sce.muraro, labels=sce.muraro$label, genes=muraro.markers) table(pred.seger$labels) ## ## acinar alpha beta delta duct endothelial ## 193 898 301 110 392 17 ## epsilon mesenchymal pp ## 7 54 197 tab &lt;- table(pred.seger$pruned.labels, sce.seger$CellType) library(pheatmap) pheatmap(log2(tab+1), color=colorRampPalette(c(&quot;white&quot;, &quot;blue&quot;))(101)) Figure 12.3: Heatmap of the confusion matrix between the predicted labels (rows) and the independently defined labels (columns) in the Segerstolpe dataset. The color is proportinal to the log-transformed number of cells with a given combination of labels from each set. An interesting question is - given a single-cell reference dataset, is it better to use it directly or convert it to pseudo-bulk values? A single-cell reference preserves the “shape” of the subpopulation in high-dimensional expression space, potentially yielding more accurate predictions when the differences between labels are subtle (or at least capturing ambiguity more accurately to avoid grossly incorrect predictions). However, it also requires more computational work to assign each cell in the test dataset. We tend to prefer using a single-cell reference directly when one is available, though it is unlikely to make much difference when the labels are well-separated. 12.3 Assigning cell labels from gene sets A related strategy is to explicitly identify sets of marker genes that are highly expressed in each individual cell. This does not require matching of individual cells to the expression values of the reference dataset, which is faster and more convenient when only the identities of the markers are available. We demonstrate this approach using neuronal cell type markers derived from the Zeisel et al. (2015) study. View history ### loading ### library(scRNAseq) sce.zeisel &lt;- ZeiselBrainData() sce.zeisel &lt;- sce.zeisel[rowData(sce.zeisel)$featureType!=&quot;repeat&quot;,] library(scater) sce.zeisel &lt;- aggregateAcrossFeatures(sce.zeisel, id=sub(&quot;_loc[0-9]+$&quot;, &quot;&quot;, rownames(sce.zeisel))) ### gene-annotation ### library(org.Mm.eg.db) ensembl &lt;- mapIds(org.Mm.eg.db, keys=rownames(sce.zeisel), keytype=&quot;SYMBOL&quot;, column=&quot;ENSEMBL&quot;) rowData(sce.zeisel)$ENSEMBL &lt;- ensembl ### quality-control ### stats &lt;- perCellQCMetrics(sce.zeisel, subsets=list( Mt=rowData(sce.zeisel)$featureType==&quot;mito&quot;)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;altexps_ERCC_percent&quot;, &quot;subsets_Mt_percent&quot;), nmads=3) sce.zeisel &lt;- sce.zeisel[,!qc$discard] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.zeisel) sce.zeisel &lt;- computeSumFactors(sce.zeisel, cluster=clusters) sce.zeisel &lt;- logNormCounts(sce.zeisel) library(scran) wilcox.z &lt;- pairwiseWilcox(logcounts(sce.zeisel), sce.zeisel$level1class, lfc=1, direction=&quot;up&quot;) markers.z &lt;- getTopMarkers(wilcox.z$statistics, wilcox.z$pairs, pairwise=FALSE, n=50) lengths(markers.z) ## astrocytes_ependymal endothelial-mural interneurons ## 78 89 120 ## microglia oligodendrocytes pyramidal CA1 ## 69 81 124 ## pyramidal SS ## 154 Our test dataset will be another brain scRNA-seq experiment from Tasic et al. (2016). library(scRNAseq) sce.tasic &lt;- TasicBrainData() sce.tasic ## class: SingleCellExperiment ## dim: 24058 1809 ## metadata(0): ## assays(1): counts ## rownames(24058): 0610005C13Rik 0610007C21Rik ... mt_X57780 ## tdTomato ## rowData names(0): ## colnames(1809): Calb2_tdTpositive_cell_1 Calb2_tdTpositive_cell_2 ## ... Rbp4_CTX_250ng_2 Trib2_CTX_250ng_1 ## colData names(13): sample_title mouse_line ... secondary_type ## aibs_vignette_id ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(1): ERCC We use the AUCell package to identify marker sets that are highly expressed in each cell. This method ranks genes by their expression values within each cell and constructs a response curve of the number of genes from each marker set that are present with increasing rank. It then computes the area under the curve (AUC) for each marker set, quantifying the enrichment of those markers among the most highly expressed genes in that cell. This is roughly similar to performing a Wilcoxon rank sum test between genes in and outside of the set, but involving only the top ranking genes by expression in each cell. library(GSEABase) all.sets &lt;- lapply(names(markers.z), function(x) { GeneSet(markers.z[[x]], setName=x) }) all.sets &lt;- GeneSetCollection(all.sets) library(AUCell) rankings &lt;- AUCell_buildRankings(counts(sce.tasic), plotStats=FALSE, verbose=FALSE) cell.aucs &lt;- AUCell_calcAUC(all.sets, rankings) results &lt;- t(assay(cell.aucs)) head(results) ## gene sets ## cells astrocytes_ependymal endothelial-mural ## Calb2_tdTpositive_cell_1 0.1286 0.05707 ## Calb2_tdTpositive_cell_2 0.1262 0.05860 ## Calb2_tdTpositive_cell_3 0.1030 0.08734 ## Calb2_tdTpositive_cell_4 0.1221 0.05945 ## Calb2_tdTpositive_cell_5 0.1532 0.07937 ## Calb2_tdTpositive_cell_6 0.1237 0.10873 ## gene sets ## cells interneurons microglia oligodendrocytes ## Calb2_tdTpositive_cell_1 0.5302 0.04845 0.1318 ## Calb2_tdTpositive_cell_2 0.4531 0.02683 0.1211 ## Calb2_tdTpositive_cell_3 0.3479 0.03582 0.1567 ## Calb2_tdTpositive_cell_4 0.5114 0.05388 0.1481 ## Calb2_tdTpositive_cell_5 0.4851 0.06656 0.1386 ## Calb2_tdTpositive_cell_6 0.3402 0.03201 0.1553 ## gene sets ## cells pyramidal CA1 pyramidal SS ## Calb2_tdTpositive_cell_1 0.2351 0.3353 ## Calb2_tdTpositive_cell_2 0.2037 0.2641 ## Calb2_tdTpositive_cell_3 0.3089 0.5078 ## Calb2_tdTpositive_cell_4 0.2472 0.3381 ## Calb2_tdTpositive_cell_5 0.2151 0.2887 ## Calb2_tdTpositive_cell_6 0.3999 0.5224 We assign cell type identity to each cell in the test dataset by taking the marker set with the top AUC as the label for that cell. Our new labels mostly agree with the original annotation from Tasic et al. (2016), which is encouraging. The only exception involves misassignment of oligodendrocyte precursors to astrocytes, which may be understandable given that they are derived from a common lineage. In the absence of prior annotation, a more general diagnostic check is to compare the assigned labels to cluster identities, under the expectation that most cells of a single cluster would have the same label (or, if multiple labels are present, they should at least represent closely related cell states). new.labels &lt;- colnames(results)[max.col(results)] tab &lt;- table(new.labels, sce.tasic$broad_type) tab ## ## new.labels Astrocyte Endothelial Cell GABA-ergic Neuron ## astrocytes_ependymal 43 2 0 ## endothelial-mural 0 27 0 ## interneurons 0 0 759 ## microglia 0 0 0 ## oligodendrocytes 0 0 1 ## pyramidal SS 0 0 1 ## ## new.labels Glutamatergic Neuron Microglia Oligodendrocyte ## astrocytes_ependymal 0 0 0 ## endothelial-mural 0 0 0 ## interneurons 3 0 0 ## microglia 0 22 0 ## oligodendrocytes 0 0 38 ## pyramidal SS 809 0 0 ## ## new.labels Oligodendrocyte Precursor Cell Unclassified ## astrocytes_ependymal 19 4 ## endothelial-mural 0 2 ## interneurons 0 15 ## microglia 0 1 ## oligodendrocytes 3 0 ## pyramidal SS 0 60 Another simple diagnostic metric is the difference \\(\\Delta_{AUC}\\) between the maximum and median AUCs for each cell. An umambiguous assignment should manifest as a large \\(\\Delta_{AUC}\\) for that cell (Figure 12.4), while small differences indicate that the assignment is uncertain. If necessary, we can remove uncertain assignments by applying a minimum threshold on the \\(\\Delta_{AUC}\\), e.g., to achieve greater agreement with the clustering results or prior annotation. The example below identifies small outlier \\(\\Delta_{AUC}\\) values under the assumption that most cells are correctly assigned and that there is only modest heterogeneity within each label. library(scater) library(DelayedMatrixStats) deltas &lt;- rowMaxs(results) - rowMedians(results) discard &lt;- isOutlier(deltas, nmads=3, type=&quot;lower&quot;, batch=new.labels) table(new.labels[discard]) ## ## astrocytes_ependymal endothelial-mural interneurons ## 23 3 9 ## oligodendrocytes pyramidal SS ## 10 15 par(mar=c(10,4,1,1)) boxplot(split(deltas, new.labels), las=2) points(attr(discard, &quot;thresholds&quot;)[1,], col=&quot;red&quot;, pch=4, cex=2) Figure 12.4: Distribution of differences between the maximum and median AUCs for each cell, stratified by the assigned label. The red cross indicates the threshold below which outliers are pruned. Interpretation of the AUCell results is most straightforward when the marker sets are mutually exclusive, as shown above for the cell type markers. In other applications, one might consider computing AUCs for gene sets associated with signalling or metabolic pathways. It is likely that multiple pathways will be active in any given cell, and it is tempting to use the AUCs to quantify this activity for comparison across cells. However, such comparisons must be interpreted with much caution as the AUCs are competitive values - any increase in one pathway’s activity will naturally reduce the AUCs for all other pathways, potentially resulting in spurious differences across the population. As we mentioned previously, the advantage of the AUCell approach is that it does not require reference expression values. This is particularly useful when dealing with gene sets derived from the literature or other qualitative forms of biological knowledge. (In this particular example, we do have the original expression values, so we could have used SingleR directly. However, this may not always be the case.) The flipside is that information on relative expression is lost when only the marker identities are used. The net effect of ignoring expression values is difficult to predict - it may reduce performance for resolving more subtle cell types, but may also improve performance if the per-cell expression was too noisy to be useful. 12.4 Assigning cluster labels from markers Yet another strategy for annotation is to perform a gene set enrichment analysis on the marker genes defining each cluster. This identifies the pathways and processes that are (relatively) active in each cluster based on upregulation of the associated genes compared to other clusters. We demonstrate on the mouse mammary dataset from Bach et al. (2017), using markers that are identified by findMarkers() as being upregulated at a log-fold change threshold of 1. View history ### loading ### library(scRNAseq) sce.mam &lt;- BachMammaryData(samples=&quot;G_1&quot;) ### gene-annotation ### library(scater) rownames(sce.mam) &lt;- uniquifyFeatureNames( rowData(sce.mam)$Ensembl, rowData(sce.mam)$Symbol) library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] rowData(sce.mam)$SEQNAME &lt;- mapIds(ens.mm.v97, keys=rowData(sce.mam)$Ensembl, keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) ### quality-control ### is.mito &lt;- rowData(sce.mam)$SEQNAME == &quot;MT&quot; stats &lt;- perCellQCMetrics(sce.mam, subsets=list(Mito=which(is.mito))) qc &lt;- quickCellQC(stats, percent_subsets=&quot;subsets_Mito_percent&quot;, nmads=3) sce.mam &lt;- sce.mam[,!qc$discard] ### normalization ### library(scran) set.seed(101000110) clusters &lt;- quickCluster(sce.mam) sce.mam &lt;- computeSumFactors(sce.mam, clusters=clusters, min.mean=0.1) sce.mam &lt;- logNormCounts(sce.mam) ### variance-modelling ### set.seed(00010101) dec.mam &lt;- modelGeneVarByPoisson(sce.mam) ### dimensionality-reduction ### library(BiocSingular) set.seed(101010011) sce.mam &lt;- denoisePCA(sce.mam, technical=dec.mam, BSPARAM=IrlbaParam()) sce.mam &lt;- runTSNE(sce.mam, dimred=&quot;PCA&quot;) ### clustering ### snn.gr &lt;- buildSNNGraph(sce.mam, use.dimred=&quot;PCA&quot;, k=25) sce.mam$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) ### marker-detection ### markers.mam &lt;- findMarkers(sce.mam, cluster=sce.mam$cluster, direction=&quot;up&quot;, lfc=1) markers.mam ## List of length 11 ## names(11): 1 2 3 4 5 6 7 8 9 10 11 As an example, we obtain annotations for the marker genes that define cluster 4. We will use gene sets defined by the Gene Ontology (GO) project, which describe a comprehensive range of biological processes and functions. We define our subset of relevant marker genes at a FDR of 5% and apply the goana() function from the limma package. This performs a hypergeometric test to identify GO terms that are overrepresented in our marker subset. (The log-fold change threshold mentioned above is useful here, as it avoids including an excessive number of genes from the overpowered nature of per-cell DE comparisons.) chosen &lt;- &quot;4&quot; cur.markers &lt;- markers.mam[[chosen]] is.de &lt;- cur.markers$FDR &lt;= 0.05 summary(is.de) ## Mode FALSE TRUE ## logical 27824 174 # goana() requires Entrez IDs, some of which map to multiple # symbols - hence the unique() in the call below. library(org.Mm.eg.db) entrez.ids &lt;- mapIds(org.Mm.eg.db, keys=rownames(cur.markers), column=&quot;ENTREZID&quot;, keytype=&quot;SYMBOL&quot;) library(limma) go.out &lt;- goana(unique(entrez.ids[is.de]), species=&quot;Mm&quot;, universe=unique(entrez.ids)) # Only keeping biological process terms that are not overly general. go.out &lt;- go.out[order(go.out$P.DE),] go.useful &lt;- go.out[go.out$Ont==&quot;BP&quot; &amp; go.out$N &lt;= 200,] head(go.useful, 20) ## Term ## GO:0022408 negative regulation of cell-cell adhesion ## GO:0006119 oxidative phosphorylation ## GO:0006641 triglyceride metabolic process ## GO:0035148 tube formation ## GO:0050729 positive regulation of inflammatory response ## GO:0042775 mitochondrial ATP synthesis coupled electron transport ## GO:0042773 ATP synthesis coupled electron transport ## GO:0006639 acylglycerol metabolic process ## GO:0006638 neutral lipid metabolic process ## GO:0071404 cellular response to low-density lipoprotein particle stimulus ## GO:0019432 triglyceride biosynthetic process ## GO:0032760 positive regulation of tumor necrosis factor production ## GO:1903557 positive regulation of tumor necrosis factor superfamily cytokine production ## GO:0046460 neutral lipid biosynthetic process ## GO:0046463 acylglycerol biosynthetic process ## GO:0019915 lipid storage ## GO:0045333 cellular respiration ## GO:0022904 respiratory electron transport chain ## GO:0042098 T cell proliferation ## GO:0001838 embryonic epithelial tube formation ## Ont N DE P.DE ## GO:0022408 BP 183 11 6.782e-08 ## GO:0006119 BP 85 8 1.424e-07 ## GO:0006641 BP 95 8 3.391e-07 ## GO:0035148 BP 172 10 3.709e-07 ## GO:0050729 BP 135 9 4.572e-07 ## GO:0042775 BP 51 6 1.446e-06 ## GO:0042773 BP 52 6 1.625e-06 ## GO:0006639 BP 118 8 1.782e-06 ## GO:0006638 BP 120 8 2.023e-06 ## GO:0071404 BP 15 4 2.913e-06 ## GO:0019432 BP 34 5 3.640e-06 ## GO:0032760 BP 92 7 3.725e-06 ## GO:1903557 BP 93 7 4.005e-06 ## GO:0046460 BP 37 5 5.606e-06 ## GO:0046463 BP 37 5 5.606e-06 ## GO:0019915 BP 68 6 7.970e-06 ## GO:0045333 BP 148 8 9.619e-06 ## GO:0022904 BP 71 6 1.025e-05 ## GO:0042098 BP 197 9 1.037e-05 ## GO:0001838 BP 151 8 1.114e-05 We see an enrichment for genes involved in lipid synthesis, cell adhesion and tube formation. Given that this is a mammary gland experiment, we might guess that cluster 4 contains luminal epithelial cells responsible for milk production and secretion. Indeed, a closer examination of the marker list indicates that this cluster upregulates milk proteins Csn2 and Csn3 (Figure ??). plotExpression(sce.mam, features=c(&quot;Csn2&quot;, &quot;Csn3&quot;), x=&quot;cluster&quot;, colour_by=&quot;cluster&quot;) Further inspection of interesting GO terms is achieved by extracting the relevant genes. This is usually desirable to confirm that the interpretation of the annotated biological process is appropriate. Many terms have overlapping gene sets, so a term may only be highly ranked because it shares genes with a more relevant term that represents the active pathway. # Extract symbols for each GO term; done once. tab &lt;- select(org.Mm.eg.db, keytype=&quot;SYMBOL&quot;, keys=rownames(sce.mam), columns=&quot;GOALL&quot;) by.go &lt;- split(tab[,1], tab[,2]) # Identify genes associated with an interesting term. adhesion &lt;- unique(by.go[[&quot;GO:0022408&quot;]]) head(cur.markers[rownames(cur.markers) %in% adhesion,1:3], 10) ## DataFrame with 10 rows and 3 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## Spint2 8 2.35996156231144e-38 1.2466830909735e-35 ## Cebpb 16 1.13376598276496e-15 3.56664943656779e-13 ## Epcam 17 2.30150123283305e-92 2.38657153766147e-89 ## Btn1a1 20 2.38156689688023e-14 7.0935223381758e-12 ## Cd24a 22 4.69304874481581e-30 2.11928997995731e-27 ## Ceacam1 27 1.91068488757264e-30 8.76973040692769e-28 ## Cd9 52 5.55595158077947e-13 1.54015378572934e-10 ## Anxa1 57 2.41419091972851e-10 6.14477430641442e-08 ## Sdc4 62 4.23799113305402e-06 0.000785796528100969 ## Klf4 77 0.824685006791971 1 Gene set testing of marker lists is a reliable approach for determining if pathways are up- or down-regulated between clusters. As the top marker genes are simply DEGs, we can directly apply well-established procedures for testing gene enrichment in DEG lists (see here for relevant packages). This contrasts with the AUCell approach where scores are not easily comparable across cells. The downside is that all conclusions are made relative to the other clusters, making it more difficult to determine cell identity if an “outgroup” is not present in the same study. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] limma_3.41.16 org.Mm.eg.db_3.8.2 [3] DelayedMatrixStats_1.7.2 scater_1.13.20 [5] ggplot2_3.2.1 AUCell_1.7.2 [7] GSEABase_1.47.0 graph_1.63.0 [9] annotate_1.63.0 XML_3.98-1.20 [11] AnnotationDbi_1.47.1 scRNAseq_1.99.6 [13] fossil_0.3.7 shapefiles_0.7 [15] foreign_0.8-72 maps_3.3.0 [17] sp_1.3-1 pheatmap_1.0.12 [19] scran_1.13.25 SingleR_0.99.12 [21] SingleCellExperiment_1.7.10 SummarizedExperiment_1.15.9 [23] DelayedArray_0.11.6 BiocParallel_1.19.2 [25] matrixStats_0.55.0 Biobase_2.45.1 [27] GenomicRanges_1.37.16 GenomeInfoDb_1.21.1 [29] IRanges_2.19.16 S4Vectors_0.23.23 [31] BiocGenerics_0.31.6 Cairo_1.5-10 [33] BiocStyle_2.13.2 OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] ggbeeswarm_0.6.0 colorspace_1.4-1 [3] XVector_0.25.0 BiocNeighbors_1.3.5 [5] bit64_0.9-7 interactiveDisplayBase_1.23.0 [7] R.methodsS3_1.7.1 knitr_1.25 [9] zeallot_0.1.0 GO.db_3.8.2 [11] dbplyr_1.4.2 R.oo_1.22.0 [13] shiny_1.3.2 BiocManager_1.30.4 [15] compiler_3.6.1 httr_1.4.1 [17] dqrng_0.2.1 backports_1.1.4 [19] assertthat_0.2.1 Matrix_1.2-17 [21] lazyeval_0.2.2 later_0.8.0 [23] BiocSingular_1.1.7 htmltools_0.3.6 [25] tools_3.6.1 rsvd_1.0.2 [27] igraph_1.2.4.1 gtable_0.3.0 [29] glue_1.3.1 GenomeInfoDbData_1.2.1 [31] dplyr_0.8.3 rappdirs_0.3.1 [33] Rcpp_1.0.2 vctrs_0.2.0 [35] ExperimentHub_1.11.6 xfun_0.9 [37] stringr_1.4.0 mime_0.7 [39] irlba_2.3.3 statmod_1.4.32 [41] AnnotationHub_2.17.9 edgeR_3.27.13 [43] zlibbioc_1.31.0 scales_1.0.0 [45] promises_1.0.1 RColorBrewer_1.1-2 [47] yaml_2.2.0 curl_4.2 [49] memoise_1.1.0 gridExtra_2.3 [51] stringi_1.4.3 RSQLite_2.1.2 [53] highr_0.8 rlang_0.4.0 [55] pkgconfig_2.0.3 bitops_1.0-6 [57] evaluate_0.14 lattice_0.20-38 [59] purrr_0.3.2 labeling_0.3 [61] cowplot_1.0.0 bit_1.1-14 [63] tidyselect_0.2.5 magrittr_1.5 [65] bookdown_0.13 R6_2.4.0 [67] DBI_1.0.0 pillar_1.4.2 [69] withr_2.1.2 RCurl_1.95-4.12 [71] tibble_2.1.3 crayon_1.3.4 [73] BiocFileCache_1.9.1 rmarkdown_1.15 [75] viridis_0.5.1 locfit_1.5-9.1 [77] grid_3.6.1 data.table_1.12.2 [79] blob_1.2.0 digest_0.6.21 [81] xtable_1.8-4 httpuv_1.5.2 [83] R.utils_2.9.0 munsell_0.5.0 [85] beeswarm_0.2.3 viridisLite_0.3.0 [87] vipor_0.4.5 Bibliography "],
["integrating-datasets.html", "Chapter 13 Integrating Datasets 13.1 Motivation 13.2 Setting up the data 13.3 Diagnosing batch effects 13.4 Linear regression 13.5 Performing MNN correction 13.6 Preserving biological heterogeneity 13.7 Application to a pancreas dataset 13.8 Using the corrected values Session Info", " Chapter 13 Integrating Datasets .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 13.1 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 13.2 Setting up the data To demonstrate, we will use two separate 10X Genomics PBMC datasets generated in two different batches. Each dataset was obtained from the TENxPBMCData package and separately subjected to basic processing steps. Separate processing prior to the batch correction step is more convenient, scalable and (on occasion) more reliable. For example, outlier-based QC on the cells is more effective when performed within a batch (Section 6.3.2.3). The same can also be said for trend fitting when modelling the mean-variance relationship (Section 8.2.4.1). View history ### loading ### library(TENxPBMCData) pbmc3k &lt;- TENxPBMCData(&#39;pbmc3k&#39;) ### quality-control ### is.mito &lt;- grep(&quot;MT&quot;, rowData(pbmc3k)$Symbol_TENx) library(scater) stats &lt;- perCellQCMetrics(pbmc3k, subsets=list(Mito=is.mito)) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) pbmc3k &lt;- pbmc3k[,!high.mito] ### normalization ### pbmc3k &lt;- logNormCounts(pbmc3k) ### variance-modelling ### library(scran) dec3k &lt;- modelGeneVar(pbmc3k) ### feature-selection ### chosen.hvgs &lt;- which(dec3k$bio &gt; 0) ### dimensionality-reduction ### # Using randomized SVD, which is more efficient for file-backed matrices. set.seed(10000) pbmc3k &lt;- runPCA(pbmc3k, subset_row=chosen.hvgs, ncomponents=25, BSPARAM=BiocSingular::RandomParam()) set.seed(100000) pbmc3k &lt;- runTSNE(pbmc3k, dimred=&quot;PCA&quot;) set.seed(1000000) pbmc3k &lt;- runUMAP(pbmc3k, dimred=&quot;PCA&quot;) ### clustering ### g &lt;- buildSNNGraph(pbmc3k, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership pbmc3k$cluster &lt;- factor(clust) pbmc3k ## class: SingleCellExperiment ## dim: 32738 2609 ## metadata(0): ## assays(2): counts logcounts ## rownames(32738): ENSG00000243485 ENSG00000237613 ... ## ENSG00000215616 ENSG00000215611 ## rowData names(3): ENSEMBL_ID Symbol_TENx Symbol ## colnames: NULL ## colData names(12): Sample Barcode ... Date_published cluster ## reducedDimNames(3): PCA TSNE UMAP ## spikeNames(0): ## altExpNames(0): View history ### loading ### library(TENxPBMCData) pbmc4k &lt;- TENxPBMCData(&#39;pbmc4k&#39;) ### quality-control ### is.mito &lt;- grep(&quot;MT&quot;, rowData(pbmc4k)$Symbol_TENx) library(scater) stats &lt;- perCellQCMetrics(pbmc4k, subsets=list(Mito=is.mito)) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) pbmc4k &lt;- pbmc4k[,!high.mito] ### normalization ### pbmc4k &lt;- logNormCounts(pbmc4k) ### variance-modelling ### library(scran) dec4k &lt;- modelGeneVar(pbmc4k) ### feature-selection ### chosen.hvgs &lt;- which(dec4k$bio &gt; 0) ### dimensionality-reduction ### # Using randomized SVD, which is more efficient for file-backed matrices. set.seed(10000) pbmc4k &lt;- runPCA(pbmc4k, subset_row=chosen.hvgs, ncomponents=25, BSPARAM=BiocSingular::RandomParam()) set.seed(100000) pbmc4k &lt;- runTSNE(pbmc4k, dimred=&quot;PCA&quot;) set.seed(1000000) pbmc4k &lt;- runUMAP(pbmc4k, dimred=&quot;PCA&quot;) ### clustering ### g &lt;- buildSNNGraph(pbmc4k, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership pbmc4k$cluster &lt;- factor(clust) pbmc4k ## class: SingleCellExperiment ## dim: 33694 4182 ## metadata(0): ## assays(2): counts logcounts ## rownames(33694): ENSG00000243485 ENSG00000237613 ... ## ENSG00000277475 ENSG00000268674 ## rowData names(3): ENSEMBL_ID Symbol_TENx Symbol ## colnames: NULL ## colData names(12): Sample Barcode ... Date_published cluster ## reducedDimNames(3): PCA TSNE UMAP ## spikeNames(0): ## altExpNames(0): To prepare for the batch correction: We subset all batches to the common “universe” of features. In this case, it is straightforward as both batches use Ensembl gene annotation5. universe &lt;- intersect(rownames(pbmc3k), rownames(pbmc4k)) length(universe) ## [1] 31232 We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. library(batchelor) rescaled &lt;- multiBatchNorm(pbmc3k[universe,], pbmc4k[universe,]) pbmc3k &lt;- rescaled[[1]] pbmc4k &lt;- rescaled[[2]] We perform feature selection by averaging the variance components across all batches with the combineVar() function. We use the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. This allows us to use the same strategies described in Section 8.3 to select genes of interest. For example, if we were to retain all genes with positive biological components, convergence of the average towards zero for non-HVGs ensures that the expected number of retained genes is stable with more batches. In contrast, approaches based on taking the intersection or union of HVGs across batches become increasingly conservative or liberal, respectively, with an increasing number of batches. library(scran) combined.dec &lt;- combineVar(dec3k[universe,], dec4k[universe,]) chosen.hvgs &lt;- combined.dec$bio &gt; 0 combined.dec[,1:6] ## DataFrame with 31232 rows and 6 columns ## mean total ## &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000243485 0 0 ## ENSG00000237613 0 0 ## ENSG00000186092 0 0 ## ENSG00000238009 0.00104386992482179 0.00106138029098745 ## ENSG00000239945 0.000258798374840956 0.000281948894897105 ## ... ... ... ## ENSG00000212907 0.535233858583492 0.437804768744041 ## ENSG00000198886 3.01692549039158 0.617031726421764 ## ENSG00000198786 1.54198723959989 0.617834240701208 ## ENSG00000198695 0.127831201202011 0.129776187258376 ## ENSG00000198727 2.56240219438806 0.717304616025944 ## tech bio ## &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000243485 0 0 ## ENSG00000237613 0 0 ## ENSG00000186092 0 0 ## ENSG00000238009 0.00106590149926527 -4.52120827782246e-06 ## ENSG00000239945 0.000264260488048504 1.76884068486008e-05 ## ... ... ... ## ENSG00000212907 0.408040681424972 0.0297640873190686 ## ENSG00000198886 0.596769333970983 0.0202623924507815 ## ENSG00000198786 0.628483569144462 -0.010649328443254 ## ENSG00000198695 0.129278188931492 0.000497998326884352 ## ENSG00000198727 0.691490878206059 0.0258137378198841 ## p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000243485 NA NA ## ENSG00000237613 NA NA ## ENSG00000186092 NA NA ## ENSG00000238009 0.512246221415639 0.834032705754633 ## ENSG00000239945 0.314021259910558 0.834032705754633 ## ... ... ... ## ENSG00000212907 0.404607233389663 0.834032705754633 ## ENSG00000198886 0.215888743417311 0.834032705754633 ## ENSG00000198786 0.642327056813382 0.834072156711655 ## ENSG00000198695 0.585074623751064 0.834032705754633 ## ENSG00000198727 0.419767773645846 0.834032705754633 13.3 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the two SingleCellExperiments and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. rowData(pbmc3k) &lt;- rowData(pbmc4k) pbmc3k$batch &lt;- &quot;3k&quot; pbmc4k$batch &lt;- &quot;4k&quot; combined &lt;- cbind(pbmc3k, pbmc4k) # Using RandomParam() as it is more efficient for file-backed matrices. library(scater) set.seed(0010101010) combined &lt;- runPCA(combined, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) We use graph-based clustering on the components to obtain a summary of the population structure. As our two PBMC populations should be replicates, each cluster should ideally consist of cells from both batches. However, we instead see clusters that are comprised of cells from a single batch. This indicates that cells of the same type are artificially separated due to technical differences between batches. library(scran) snn.gr &lt;- buildSNNGraph(combined, use.dimred=&quot;PCA&quot;) clusters &lt;- igraph::cluster_walktrap(snn.gr)$membership tab &lt;- table(Cluster=clusters, Batch=combined$batch) tab ## Batch ## Cluster 3k 4k ## 1 0 126 ## 2 12 459 ## 3 1 776 ## 4 0 1310 ## 5 500 0 ## 6 0 536 ## 7 0 606 ## 8 1296 0 ## 9 0 176 ## 10 0 54 ## 11 149 0 ## 12 30 1 ## 13 0 89 ## 14 131 0 ## 15 342 0 ## 16 1 10 ## 17 134 0 ## 18 11 3 ## 19 2 36 We can also visualize the corrected coordinates using a \\(t\\)-SNE plot (Figure 13.1). The strong separation between cells from different batches is consistent with the clustering results. combined &lt;- runTSNE(combined, dimred=&quot;PCA&quot;) plotTSNE(combined, colour_by=&quot;batch&quot;) Figure 13.1: \\(t\\)-SNE plot of the PBMC datasets without any batch correction. Each point is a cell that is colored according to its batch of origin. Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations (which is not a consideration in the PBMC dataset, but the same cannot be said in general). If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. 13.4 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common6. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. library(batchelor) rescaled &lt;- rescaleBatches(pbmc3k, pbmc4k) rescaled ## class: SingleCellExperiment ## dim: 31232 6791 ## metadata(0): ## assays(1): corrected ## rownames(31232): ENSG00000243485 ENSG00000237613 ... ## ENSG00000198695 ENSG00000198727 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): After clustering, we observe that most clusters consist of mixtures of cells from the two replicate batches, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches in Figure 13.2. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches. set.seed(1010101010) rescaled &lt;- runPCA(rescaled, subset_row=chosen.hvgs, BSPARAM=BiocSingular::IrlbaParam(), exprs_values=&quot;corrected&quot;) snn.gr &lt;- buildSNNGraph(rescaled, use.dimred=&quot;PCA&quot;) clusters.resc &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled$batch) tab.resc ## Batch ## Cluster 1 2 ## 1 272 523 ## 2 336 606 ## 3 126 266 ## 4 643 560 ## 5 19 47 ## 6 12 3 ## 7 313 0 ## 8 8 50 ## 9 19 58 ## 10 15 70 ## 11 131 154 ## 12 37 511 ## 13 10 83 ## 14 100 207 ## 15 137 8 ## 16 16 25 ## 17 397 964 ## 18 3 36 ## 19 4 8 ## 20 11 3 rescaled &lt;- runTSNE(rescaled, dimred=&quot;PCA&quot;) rescaled$batch &lt;- factor(rescaled$batch) plotTSNE(rescaled, colour_by=&quot;batch&quot;) Figure 13.2: \\(t\\)-SNE plot of the PBMC datasets after correction with rescaleBatches(). Each point represents a cell and is colored according to the batch of origin. 13.5 Performing MNN correction 13.5.1 Application to the PBMC data Consider a cell \\(a\\) in batch \\(A\\), and identify the cells in batch \\(B\\) that are nearest neighbours to \\(a\\) in the expression space defined by the selected features. Repeat this for a cell \\(b\\) in batch \\(B\\), identifying its nearest neighbours in \\(A\\). Mutual nearest neighbours are pairs of cells from different batches that belong in each other’s set of nearest neighbours. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. The batchelor package provides an implementation of the MNN approach via the fastMNN() function. (Unlike the MNN method described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps.) We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN(pbmc3k, pbmc4k, d=50, k=20, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out ## class: SingleCellExperiment ## dim: 31232 6791 ## metadata(1): merge.info ## assays(1): reconstructed ## rownames(31232): ENSG00000243485 ENSG00000237613 ... ## ENSG00000198695 ENSG00000198727 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## spikeNames(0): ## altExpNames(0): The function returns a SingleCellExperiment object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. head(mnn.out$batch) ## [1] 1 1 1 1 1 1 The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses. dim(reducedDim(mnn.out, &quot;corrected&quot;)) ## [1] 6791 50 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbours to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. 13.5.2 Correction diagnostics We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the two batches are replicates of each other. library(scran) snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;) clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster 1 2 ## 1 282 507 ## 2 331 588 ## 3 301 633 ## 4 210 163 ## 5 675 622 ## 6 12 17 ## 7 19 74 ## 8 9 52 ## 9 7 18 ## 10 28 50 ## 11 14 47 ## 12 59 174 ## 13 410 982 ## 14 122 132 ## 15 4 36 ## 16 111 76 ## 17 4 8 ## 18 11 3 We can also visualize the corrected coordinates using a \\(t\\)-SNE plot (Figure 13.3). The presence of visual clusters containing cells from both batches provides a comforting illusion that the correction was successful. library(scater) set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, use_dimred=&quot;corrected&quot;) mnn.out$batch &lt;- factor(mnn.out$batch) plotTSNE(mnn.out, colour_by=&quot;batch&quot;) Figure 13.3: \\(t\\)-SNE plot of the PBMC datasets after MNN correction. Each point is a cell that is colored according to its batch of origin. For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). metadata(mnn.out)$merge.info$lost.var ## [,1] [,2] ## [1,] 0.004513 0.00327 Large proportions of lost variance suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. 13.6 Preserving biological heterogeneity Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries of the table()s below are zero, though this may depend on whether specific clusters of interest are gained or lost. # For the first batch. table(New=clusters.mnn[rescaled$batch==1], Old=pbmc3k$cluster) ## Old ## New 1 2 3 4 5 6 7 8 9 ## 1 0 275 0 3 0 4 0 0 0 ## 2 0 0 3 0 0 0 0 328 0 ## 3 300 0 0 0 0 0 1 0 0 ## 4 162 0 0 0 0 0 48 0 0 ## 5 0 47 487 141 0 0 0 0 0 ## 6 0 0 12 0 0 0 0 0 0 ## 7 0 0 0 0 19 0 0 0 0 ## 8 9 0 0 0 0 0 0 0 0 ## 9 0 1 1 1 0 0 0 4 0 ## 10 0 2 0 0 0 26 0 0 0 ## 11 0 0 0 0 14 0 0 0 0 ## 12 0 0 0 59 0 0 0 0 0 ## 13 0 4 4 402 0 0 0 0 0 ## 14 0 0 0 0 0 122 0 0 0 ## 15 0 0 3 0 1 0 0 0 0 ## 16 0 0 0 0 0 0 111 0 0 ## 17 0 0 0 4 0 0 0 0 0 ## 18 0 0 0 0 0 0 0 0 11 # For the second batch. table(New=clusters.mnn[rescaled$batch==2], Old=pbmc4k$cluster) ## Old ## New 1 2 3 4 5 6 7 8 9 10 11 12 ## 1 1 1 0 501 0 4 0 0 0 0 0 0 ## 2 0 0 0 0 221 0 367 0 0 0 0 0 ## 3 0 632 0 0 0 0 0 1 0 0 0 0 ## 4 0 146 8 0 0 0 0 2 0 0 7 0 ## 5 464 0 0 60 0 0 0 0 77 21 0 0 ## 6 14 0 0 1 1 0 1 0 0 0 0 0 ## 7 0 0 74 0 0 0 0 0 0 0 0 0 ## 8 0 6 0 0 0 0 0 46 0 0 0 0 ## 9 0 0 0 1 4 1 12 0 0 0 0 0 ## 10 0 0 0 0 0 50 0 0 0 0 0 0 ## 11 0 2 45 0 0 0 0 0 0 0 0 0 ## 12 3 0 0 0 0 0 0 0 13 158 0 0 ## 13 10 0 0 4 0 0 0 0 946 22 0 0 ## 14 0 0 0 0 0 132 0 0 0 0 0 0 ## 15 0 0 0 0 0 0 0 0 0 0 0 36 ## 16 0 6 0 0 0 0 0 0 0 0 70 0 ## [ reached getOption(&quot;max.print&quot;) -- omitted 2 rows ] We can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger Rand indices are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. library(fossil) rand.index(as.integer(clusters.mnn[rescaled$batch==1]), as.integer(pbmc3k$cluster)) ## [1] 0.9129 rand.index(as.integer(clusters.resc[rescaled$batch==1]), as.integer(pbmc3k$cluster)) ## [1] 0.9102 13.7 Application to a pancreas dataset We perform another demonstration with two human pancreas CEL-seq(2) datasets (Muraro et al. 2016; Grun et al. 2016). This is a more challenging application than the PBMC dataset as it involves different patients and protocols. View history ### loading ### library(scRNAseq) sce.grun &lt;- GrunPancreasData() ### gene-annotation ### library(org.Hs.eg.db) gene.ids &lt;- mapIds(org.Hs.eg.db, keys=rowData(sce.grun)$symbol, keytype=&quot;SYMBOL&quot;, column=&quot;ENSEMBL&quot;) keep &lt;- !is.na(gene.ids) &amp; !duplicated(gene.ids) sce.grun &lt;- sce.grun[keep,] rownames(sce.grun) &lt;- gene.ids[keep] ### quality-control ### library(scater) stats &lt;- perCellQCMetrics(sce.grun) qc &lt;- quickCellQC(stats, percent_subsets=&quot;altexps_ERCC_percent&quot;, nmads=3) sce.grun &lt;- sce.grun[,!qc$discard] ### normalization ### library(scran) set.seed(1000) # for irlba. clusters &lt;- quickCluster(sce.grun) sce.grun &lt;- computeSumFactors(sce.grun, min.mean=0.1, clusters=clusters) sce.grun &lt;- logNormCounts(sce.grun) ### variance-modelling ### block &lt;- paste0(sce.grun$sample, &quot;_&quot;, sce.grun$donor) dec.grun &lt;- modelGeneVarWithSpikes(sce.grun, spikes=&quot;ERCC&quot;, block=block) sce.grun ## class: SingleCellExperiment ## dim: 17692 1290 ## metadata(0): ## assays(2): counts logcounts ## rownames(17692): ENSG00000268895 ENSG00000121410 ... ## ENSG00000074755 ENSG00000036549 ## rowData names(2): symbol chr ## colnames(1290): D2ex_1 D2ex_2 ... D17TGFB_94 D17TGFB_95 ## colData names(2): donor sample ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(1): ERCC View history ### loading ### library(scRNAseq) sce.muraro &lt;- MuraroPancreasData() ### gene-annotation ### library(AnnotationHub) edb &lt;- AnnotationHub()[[&quot;AH73881&quot;]] gene.symb &lt;- sub(&quot;__chr.*$&quot;, &quot;&quot;, rownames(sce.muraro)) gene.ids &lt;- mapIds(edb, keys=gene.symb, keytype=&quot;SYMBOL&quot;, column=&quot;GENEID&quot;) # Removing duplicated genes or genes without Ensembl IDs. keep &lt;- !is.na(gene.ids) &amp; !duplicated(gene.ids) sce.muraro &lt;- sce.muraro[keep,] rownames(sce.muraro) &lt;- gene.ids[keep] ### quality-control ### library(scater) stats &lt;- perCellQCMetrics(sce.muraro) qc &lt;- quickCellQC(stats, nmads=3, percent_subsets=&quot;altexps_ERCC_percent&quot;) sce.muraro &lt;- sce.muraro[,!qc$discard] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.muraro) sce.muraro &lt;- computeSumFactors(sce.muraro, min.mean=0.1, clusters=clusters) sce.muraro &lt;- logNormCounts(sce.muraro) ### variance-modelling ### block &lt;- paste0(sce.muraro$plate, &quot;_&quot;, sce.muraro$donor) dec.muraro &lt;- modelGeneVarWithSpikes(sce.muraro, &quot;ERCC&quot;, block=block) sce.muraro ## class: SingleCellExperiment ## dim: 16940 2346 ## metadata(0): ## assays(2): counts logcounts ## rownames(16940): ENSG00000268895 ENSG00000121410 ... ## ENSG00000159840 ENSG00000074755 ## rowData names(2): symbol chr ## colnames(2346): D28-1_1 D28-1_2 ... D30-8_93 D30-8_94 ## colData names(3): label donor plate ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(1): ERCC We subset both batches to their common universe of genes; adjust their scaling to equalize sequencing coverage (not really necessary in this case, as the coverage is already similar, but we will do so anyway for consistency); and select those genes with positive average biological components for further use. universe &lt;- intersect(rownames(sce.grun), rownames(sce.muraro)) universe &lt;- universe[!grepl(&quot;^ERCC&quot;, universe)] normed.pancreas &lt;- multiBatchNorm(sce.grun[universe,], sce.muraro[universe,]) sce.grun &lt;- normed.pancreas[[1]] sce.muraro &lt;- normed.pancreas[[2]] combined.pan &lt;- combineVar(dec.grun[universe,], dec.muraro[universe,]) chosen.genes &lt;- universe[combined.pan$bio &gt; 0] We observe that rescaleBatches() is unable to align cells from different batches in Figure 13.4. This is attributable to differences in population composition between batches, with additional complications from non-linearities in the batch effect, e.g., when the magnitude or direction of the batch effect differs between cell types. rescaled.pancreas &lt;- rescaleBatches(sce.grun, sce.muraro) rescaled.pancreas &lt;- runPCA(rescaled.pancreas, subset_row=chosen.genes, BSPARAM=BiocSingular::IrlbaParam(), exprs_values=&quot;corrected&quot;) rescaled.pancreas &lt;- runTSNE(rescaled.pancreas, dimred=&quot;PCA&quot;) plotTSNE(rescaled.pancreas, colour_by=&quot;batch&quot;) Figure 13.4: \\(t\\)-SNE plot of the pancreas datasets after correction with rescaleBatches(). Each point represents a cell and is colored according to the batch of origin. Here, we use fastMNN() to merge together the two human pancreas datasets described earlier. Clustering on the merged datasets yields fewer batch-specific clusters, which is recapitulated as greater intermingling between batches in Figure 13.5. This improvement over Figure 13.4 represents the ability of fastMNN() to adapt to more complex situations involving differences in population composition between batches. mnn.pancreas &lt;- fastMNN(sce.grun, sce.muraro, subset.row=chosen.genes) snn.gr &lt;- buildSNNGraph(mnn.pancreas, use.dimred=&quot;corrected&quot;) clusters &lt;- igraph::cluster_walktrap(snn.gr)$membership tab &lt;- table(Cluster=clusters, Batch=mnn.pancreas$batch) tab ## Batch ## Cluster 1 2 ## 1 320 279 ## 2 343 265 ## 3 209 847 ## 4 61 197 ## 5 161 399 ## 6 42 1 ## 7 25 108 ## 8 22 127 ## 9 59 80 ## 10 33 0 ## 11 0 18 ## 12 8 4 ## 13 7 21 mnn.pancreas &lt;- runTSNE(mnn.pancreas, dimred=&quot;corrected&quot;) plotTSNE(mnn.pancreas, colour_by=&quot;batch&quot;) Figure 13.5: \\(t\\)-SNE plot of the pancreas datasets after correction with fastMNN(). Each point represents a cell and is colored according to the batch of origin. 13.8 Using the corrected values The greatest value of batch correction lies in facilitating cell-based analysis of population heterogeneity in a consistent manner across batches. Cluster 1 in batch A is the same as cluster 1 in batch B when the clustering is performed on the merged data. There is no need to identify mappings between separate clusterings, which might not even be possible when the clusters are not well-separated. The burden of interpretation is consolidated by generating a single set of clusters for all batches, rather than requiring separate examination of each batch’s clusters. Another benefit is that the available number of cells is increased when all batches are combined, which allows for greater resolution of population structure in downstream analyses7. We previously demonstrated the application of clustering methods to the batch-corrected data, but the same principles apply for other analyses like trajectory reconstruction. At this point, it is also tempting to use the batch-corrected values for gene-based analyses like DE-based marker gene detection. This is not generally recommended as an arbitrary correction algorithm is not obliged to preserve the magnitude (or even direction) of differences in per-gene expression when attempting to align multiple batches. For example, cosine normalization in fastMNN() shrinks the magnitude of the expression values so that the computed log-fold changes have no obvious interpretation. Of greater concern is the possibility that the correction introduces artificial agreement across batches. To illustrate: Consider a dataset (first batch) with two cell types, \\(A\\) and \\(B\\). Consider a second batch with the same cell types, denoted as \\(A&#39;\\) and \\(B&#39;\\). Assume that, for some reason, gene \\(X\\) is expressed in \\(A\\) but not in \\(A&#39;\\), \\(B\\) or \\(B&#39;\\) - possibly due to some difference in how the cells were treated, or maybe due to a donor effect. We then merge the batches together based on the shared cell types. This yields a result where \\(A\\) and \\(A&#39;\\) cells are intermingled and the difference due to \\(X\\) is eliminated. One can debate whether this should be the case, but in general, it is necessary for batch correction methods to smooth over small biological differences (as discussed in Section 13.3). Now, if we corrected the second batch to the first, we must have coerced the expression values of \\(X\\) in \\(A&#39;\\) to non-zero values to align with those of \\(A\\), while leaving the expression of \\(X\\) in \\(B&#39;\\) and \\(B\\) at zero. Thus, we have artificially introduced DE between \\(A&#39;\\) and \\(B&#39;\\) for \\(X\\) in the second batch to align with the DE between \\(A\\) and \\(B\\) in the first batch. (The converse is also possible where DE in the first batch is artificially removed to align with the second batch, depending on the order of merges.) The artificial DE has implications for the identification of the cell types and interpretation of the results. We would be misled into believing that both \\(A\\) and \\(A&#39;\\) are \\(X\\)-positive, when in fact this is only true for \\(A\\). At best, this is only a minor error - after all, we do actually have \\(X\\)-positive cells of that overall type, we simply do not see that \\(A&#39;\\) is \\(X\\)-negative. At worst, this can compromise the conclusions, e.g., if the first batch was drug treated and the second batch was a control, we might mistakenly think that a \\(X\\)-positive population exists in the latter and conclude that our drug has no effect. Rather, it is preferable to perform DE analyses using the uncorrected expression values with blocking on the batch, as discussed in Section 11.4. This strategy is based on the expectation that any genuine DE between clusters should still be present in a within-batch comparison where batch effects are absent. It penalizes genes that exhibit inconsistent DE across batches, thus protecting against misleading conclusions when a population in one batch is aligned to a similar-but-not-identical population in another batch. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] fossil_0.3.7 shapefiles_0.7 [3] foreign_0.8-72 maps_3.3.0 [5] sp_1.3-1 scater_1.13.20 [7] ggplot2_3.2.1 scran_1.13.25 [9] batchelor_1.1.12 SingleCellExperiment_1.7.10 [11] SummarizedExperiment_1.15.9 Biobase_2.45.1 [13] GenomicRanges_1.37.16 GenomeInfoDb_1.21.1 [15] HDF5Array_1.13.8 rhdf5_2.29.3 [17] DelayedArray_0.11.6 BiocParallel_1.19.2 [19] IRanges_2.19.16 S4Vectors_0.23.23 [21] BiocGenerics_0.31.6 matrixStats_0.55.0 [23] Cairo_1.5-10 BiocStyle_2.13.2 [25] OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] bitops_1.0-6 tools_3.6.1 [3] R6_2.4.0 irlba_2.3.3 [5] vipor_0.4.5 lazyeval_0.2.2 [7] colorspace_1.4-1 withr_2.1.2 [9] tidyselect_0.2.5 gridExtra_2.3 [11] compiler_3.6.1 BiocNeighbors_1.3.5 [13] labeling_0.3 bookdown_0.13 [15] scales_1.0.0 stringr_1.4.0 [17] digest_0.6.21 rmarkdown_1.15 [19] XVector_0.25.0 pkgconfig_2.0.3 [21] htmltools_0.3.6 limma_3.41.16 [23] highr_0.8 rlang_0.4.0 [25] DelayedMatrixStats_1.7.2 dplyr_0.8.3 [27] RCurl_1.95-4.12 magrittr_1.5 [29] BiocSingular_1.1.7 GenomeInfoDbData_1.2.1 [31] Matrix_1.2-17 Rcpp_1.0.2 [33] ggbeeswarm_0.6.0 munsell_0.5.0 [35] Rhdf5lib_1.7.5 viridis_0.5.1 [37] stringi_1.4.3 yaml_2.2.0 [39] edgeR_3.27.13 zlibbioc_1.31.0 [41] Rtsne_0.15 grid_3.6.1 [43] dqrng_0.2.1 crayon_1.3.4 [45] lattice_0.20-38 cowplot_1.0.0 [47] beachmat_2.1.2 locfit_1.5-9.1 [49] knitr_1.25 pillar_1.4.2 [51] igraph_1.2.4.1 glue_1.3.1 [53] evaluate_0.14 BiocManager_1.30.4 [55] gtable_0.3.0 purrr_0.3.2 [57] assertthat_0.2.1 xfun_0.9 [59] rsvd_1.0.2 viridisLite_0.3.0 [61] tibble_2.1.3 beeswarm_0.2.3 [63] statmod_1.4.32 Bibliography "],
["multi-sample-comparisons.html", "Chapter 14 Multi-sample comparisons 14.1 Motivation 14.2 Setting up the data 14.3 Differential expression between conditions 14.4 Differential abundance between conditions 14.5 DE or DA? Two sides of the same coin 14.6 Avoiding problems with ambient RNA Session Info", " Chapter 14 Multi-sample comparisons .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 14.1 Motivation A powerful use of scRNA-seq technology lies in the design of replicated multi-condition experiments to detect changes in composition or expression between conditions. For example, a researcher could use this strategy to detect changes in cell type abundance after drug treatment (Richard et al. 2018) or genetic modifications (Scialdone et al. 2016). This provides more biological insight than conventional scRNA-seq experiments involving only one biological condition, especially if we can relate population changes to specific experimental perturbations. Differential analyses of multi-condition scRNA-seq experiments can be broadly split into two categories - differential expression (DE) and differential abundance (DA) analyses. The former tests for changes in expression between conditions for cells of the same type that are present in both conditions, while the latter tests for changes in the composition of cell types (or states, etc.) between conditions. In this chapter, we will demonstrate both analyses using data from a study of the early mouse embryo (Pijuan-Sala et al. 2019). 14.2 Setting up the data Our demonstration scRNA-seq dataset was generated from chimeric mouse embryos at the E8.5 developmental stage. Each chimeric embryo was generated by injecting td-Tomato-positive embryonic stem cells (ESCs) into a wild-type (WT) blastocyst. Unlike in previous experiments (Scialdone et al. 2016), there is no genetic difference between the injected and background cells other than the expression of td-Tomato in the former. Instead, the aim of this “wild-type chimera” study is to determine whether the injection procedure itself introduces differences in lineage commitment compared to the background cells. The experiment used a paired design with three replicate batches of two samples each. Specifically, each batch contains one sample consisting of td-Tomato positive cells and another consisting of negative cells, obtained by fluorescence-activated cell sorting from a single pool of dissociated cells from 6-7 chimeric embryos. For each sample, scRNA-seq data was generated using the 10X Genomics protocol (Zheng et al. 2017) to obtain 2000-7000 cells. View history ### loading ### library(MouseGastrulationData) sce.chimera &lt;- WTChimeraData(samples=5:10) sce.chimera ### feature-annotation ### library(scater) rownames(sce.chimera) &lt;- uniquifyFeatureNames( rowData(sce.chimera)$ENSEMBL, rowData(sce.chimera)$SYMBOL) ### quality-control ### drop &lt;- sce.chimera$celltype.mapped %in% c(&quot;stripped&quot;, &quot;Doublet&quot;) sce.chimera &lt;- sce.chimera[,!drop] ### normalization ### sce.chimera &lt;- logNormCounts(sce.chimera) ### variance-modelling ### library(scran) dec.chimera &lt;- modelGeneVar(sce.chimera, block=sce.chimera$sample) chosen.hvgs &lt;- dec.chimera$bio &gt; 0 ### merging ### library(batchelor) merged &lt;- correctExperiments(sce.chimera, batch=sce.chimera$sample, subset.row=chosen.hvgs, PARAM=FastMnnParam( merge.order=list( list( list(1, 3), # WT (3 replicates) 5 ), list( list(2, 4), # td-Tomato (3 replicates) 6 ) ) ) ) ### clustering ### g &lt;- buildSNNGraph(merged, use.dimred=&quot;corrected&quot;) clusters &lt;- igraph::cluster_louvain(g) merged$cluster &lt;- factor(clusters$membership) ### dimensionality-reduction ### merged &lt;- runTSNE(merged, dimred=&quot;corrected&quot;, external_neighbors=TRUE) merged &lt;- runUMAP(merged, dimred=&quot;corrected&quot;, external_neighbors=TRUE) merged ## class: SingleCellExperiment ## dim: 14699 19426 ## metadata(1): merge.info ## assays(3): reconstructed counts logcounts ## rownames(14699): Xkr4 Rp1 ... Vmn2r122 CAAA01147332.1 ## rowData names(1): rotation ## colnames(19426): cell_9769 cell_9770 ... cell_30701 cell_30702 ## colData names(12): batch cell ... doub.density cluster ## reducedDimNames(3): corrected TSNE UMAP ## spikeNames(0): ## altExpNames(0): The differential analyses are predicated on many of the pre-processing steps covered in previous chapters. For brevity, we will not explicitly repeat them here, only noting that we have already merged cells from all samples into the same coordinate system (Chapter 19.2.6) and clustered the merged dataset to obtain a common partitioning across all samples (Chapter 10). A brief inspection of the results indicates that clusters contain similar contributions from all batches with only modest differences associated with td-Tomato expression (Figure ??). library(scater) table(merged$cluster, merged$tomato) ## ## FALSE TRUE ## 1 547 403 ## 2 62 52 ## 3 471 400 ## 4 465 207 ## 5 116 112 ## 6 258 249 ## 7 1119 795 ## 8 411 398 ## 9 200 220 ## 10 47 57 ## 11 891 1106 ## 12 419 310 ## 13 413 626 ## 14 58 0 ## 15 209 214 ## 16 363 509 ## 17 234 197 ## 18 660 608 ## 19 568 414 ## 20 218 481 ## 21 137 74 ## 22 82 78 ## 23 155 1 ## 24 627 624 ## 25 253 311 ## 26 1348 649 table(merged$cluster, merged$pool) ## ## 3 4 5 ## 1 225 173 552 ## 2 26 30 58 ## 3 226 174 471 ## 4 77 160 435 ## 5 36 78 114 ## 6 187 116 204 ## 7 259 743 912 ## 8 123 404 282 ## 9 69 133 218 ## 10 16 31 57 ## 11 261 537 1199 ## 12 179 169 381 ## 13 114 288 637 ## 14 2 51 5 ## 15 77 97 249 ## 16 183 242 447 ## 17 157 81 193 ## 18 123 309 836 ## 19 227 230 525 ## 20 220 169 310 ## 21 3 10 198 ## 22 27 29 104 ## 23 6 84 66 ## 24 226 420 605 ## 25 100 105 359 ## 26 175 781 1041 gridExtra::grid.arrange( plotTSNE(merged, colour_by=&quot;tomato&quot;, text_by=&quot;cluster&quot;), plotTSNE(merged, colour_by=data.frame(pool=factor(merged$pool))), ncol=2 ) Ordinarily, we would be obliged to perform marker detection to assign biological meaning to these clusters. For simplicity, we will skip this step by directly using the cell type labels provided by Pijuan-Sala et al. (2019). These were obtained by mapping the cells in this dataset to a larger, pre-annotated “atlas” of mouse early embryonic development. While broadly consistent, many of our clusters map to multiple labels (Figure @ref(fig:heat-cluster-label}), which reflects the difficulties in unambiguously resolving cell types undergoing differentiation. by.label &lt;- table(merged$cluster, merged$celltype.mapped) pheatmap::pheatmap(log2(by.label+1), cluster_cols=FALSE, cluster_rows=FALSE, color=viridis::viridis(101)) Figure 14.1: Heatmap showing the abundance of cells with each combination of cluster (row) and cell type label (column). The color scale represents the log2-count for each combination. 14.3 Differential expression between conditions 14.3.1 Creating pseudo-bulk samples The most obvious differential analysis is to look for changes in expression between conditions. We perform the DE analysis separately for each label to identify cell type-specific transcriptional effects of injection. The actual DE testing is performed on “pseudo-bulk” expression profiles (Tung et al. 2017), generated by summing counts together for all cells with the same combination of label and sample. This leverages the resolution offered by single-cell technologies to define the labels, and combines it with the statistical rigor of existing methods for DE analyses involving a small number of samples. # Using &#39;label&#39; and &#39;sample&#39; as our two factors; each column of the output # corresponds to one unique combination of these two factors. summed &lt;- aggregateAcrossCells(merged, id=DataFrame( label=merged$celltype.mapped, sample=merged$sample) ) summed ## class: SingleCellExperiment ## dim: 14699 186 ## metadata(1): merge.info ## assays(1): counts ## rownames(14699): Xkr4 Rp1 ... Vmn2r122 CAAA01147332.1 ## rowData names(1): rotation ## colnames: NULL ## colData names(14): batch cell ... label sample ## reducedDimNames(3): corrected TSNE UMAP ## spikeNames(0): ## altExpNames(0): At this point, it is worth reflecting on the motivations behind the use of pseudo-bulking: Larger counts are more amenable to downstream analysis with standard methods for bulk RNA-seq analysis. Normalization is more straightforward and certain approximations are more accurate for large counts. Collapsing cells into samples reflects the fact that our biological replication occurs at the sample level (A. T. L. Lun and Marioni 2017). Each sample is represented no more than once for each condition, avoiding problems from unmodelled correlations between samples. Supplying the per-cell counts directly would indicate that each cell is a biological replicate, which is not true from an experimental perspective. Variance between cells within each sample is masked, provided it does not affect variance across (replicate) samples. This avoids penalizing DEGs that are not uniformly up- or down-regulated for all cells in all samples of one condition. Masking is generally desirable as DEGs (unlike marker genes) do not need to have low within-sample variance to be interesting, e.g., if the treatment effect is consistent across populations but heterogeneous on a per-cell basis. 14.3.2 Performing the DE analysis 14.3.2.1 Introduction The DE analysis will be performed using quasi-likelihood (QL) methods from the edgeR package (Robinson, McCarthy, and Smyth 2010; Chen, Lun, and Smyth 2016). This uses a negative binomial generalized linear model (NB GLM) to handle overdispersed count data in experiments with limited replication. In our case, we have biological variation with three paired replicates per condition, so edgeR (or its contemporaries) is a natural choice for the analysis. We do not use all labels for GLM fitting as the strong DE between labels makes it difficult to compute a sensible average abundance to model the mean-dispersion trend. Moreover, label-specific batch effects would not be easily handled with a single additive term in the design matrix for the batch. Instead, we arbitrarily pick one of the labels to use for this demonstration. label &lt;- &quot;Mesenchyme&quot; current &lt;- summed[,label==summed$celltype.mapped] # Creating up a DGEList object for use in edgeR: library(edgeR) y &lt;- DGEList(counts(current), samples=colData(current)) y ## An object of class &quot;DGEList&quot; ## $counts ## Sample1 Sample2 Sample3 Sample4 Sample5 Sample6 ## Xkr4 2 0 0 0 3 0 ## Rp1 0 0 1 0 0 0 ## Sox17 7 0 3 0 14 9 ## Mrpl15 1420 271 1009 379 1578 749 ## Rgs20 3 0 1 1 0 0 ## 14694 more rows ... ## ## $samples ## group lib.size norm.factors batch cell barcode ## Sample1 1 4607053 1 5 cell_9769 AAACCTGAGACTGTAA ## Sample2 1 1064970 1 6 cell_12212 AAGGCAGAGATGCGAC ## Sample3 1 2494010 1 7 cell_13244 AAAGATGGTCATACTG ## Sample4 1 1028668 1 8 cell_16261 AAAGTAGAGCGATCCC ## Sample5 1 4290221 1 9 cell_19345 AAACGGGTCGTCTGAA ## Sample6 1 1950840 1 10 cell_23936 AAAGTAGTCTTGCCGT ## sample stage tomato pool stage.mapped celltype.mapped closest.cell ## Sample1 5 E8.5 TRUE 3 E8.25 Mesenchyme cell_24159 ## Sample2 6 E8.5 FALSE 3 E8.25 Mesenchyme cell_66561 ## Sample3 7 E8.5 TRUE 4 E8.25 Mesenchyme cell_137494 ## Sample4 8 E8.5 FALSE 4 E8.5 Mesenchyme cell_132462 ## Sample5 9 E8.5 TRUE 5 E7.25 Mesenchyme cell_17255 ## Sample6 10 E8.5 FALSE 5 E8.5 Mesenchyme cell_41003 ## doub.density cluster label sample.1 ## Sample1 0.029850 20 Mesenchyme 5 ## Sample2 0.001651 20 Mesenchyme 6 ## Sample3 0.079208 11 Mesenchyme 7 ## Sample4 0.014702 11 Mesenchyme 8 ## Sample5 0.111286 24 Mesenchyme 9 ## Sample6 0.000000 20 Mesenchyme 10 14.3.2.2 Pre-processing A typical step in bulk RNA-seq data analyses is to remove samples with very low library sizes corresponding to failed library preparation or sequencing. In our situation, this is equivalent to removing label-sample combinations that have very few or lowly-sequenced cells. The corresponding summed count vectors are likely to be highly variable and thus reduce power for DE detection. The exact definition of “very low” will vary, but in this case, we define it to be log-library sizes that are more than 3 median absolute deviations from the median. discarded &lt;- isOutlier(y$samples$lib.size, log=TRUE, type=&quot;lower&quot;, nmads=3) y &lt;- y[,!discarded] summary(discarded) ## Mode FALSE ## logical 6 Another typical step in bulk RNA-seq analyses is to remove genes that are lowly expressed. This reduces computational work, improves the accuracy of mean-variance trend modelling and decreases the severity of the multiple testing correction. Genes are discarded if they are not expressed above a log-CPM threshold in a minimum number of samples (determined from the size of the smallest treatment group in the experimental design). keep &lt;- filterByExpr(y, group=current$tomato) y &lt;- y[keep,] summary(keep) ## Mode FALSE TRUE ## logical 9011 5688 Finally, we correct for composition biases by computing normalization factors with the trimmed mean of M-values method (Robinson and Oshlack 2010). We do not need the bespoke single-cell methods described in Chapter 7, as the counts for our pseudo-bulk samples are large enough to apply bulk normalization methods. (Readers should be aware that edgeR normalization factors are closely related but not the same as the size factors described elsewhere in this book.) y &lt;- calcNormFactors(y) y$samples ## group lib.size norm.factors batch cell barcode ## Sample1 1 4607053 1.0683 5 cell_9769 AAACCTGAGACTGTAA ## Sample2 1 1064970 1.0487 6 cell_12212 AAGGCAGAGATGCGAC ## Sample3 1 2494010 0.9582 7 cell_13244 AAAGATGGTCATACTG ## Sample4 1 1028668 0.9774 8 cell_16261 AAAGTAGAGCGATCCC ## Sample5 1 4290221 0.9707 9 cell_19345 AAACGGGTCGTCTGAA ## Sample6 1 1950840 0.9817 10 cell_23936 AAAGTAGTCTTGCCGT ## sample stage tomato pool stage.mapped celltype.mapped closest.cell ## Sample1 5 E8.5 TRUE 3 E8.25 Mesenchyme cell_24159 ## Sample2 6 E8.5 FALSE 3 E8.25 Mesenchyme cell_66561 ## Sample3 7 E8.5 TRUE 4 E8.25 Mesenchyme cell_137494 ## Sample4 8 E8.5 FALSE 4 E8.5 Mesenchyme cell_132462 ## Sample5 9 E8.5 TRUE 5 E7.25 Mesenchyme cell_17255 ## Sample6 10 E8.5 FALSE 5 E8.5 Mesenchyme cell_41003 ## doub.density cluster label sample.1 ## Sample1 0.029850 20 Mesenchyme 5 ## Sample2 0.001651 20 Mesenchyme 6 ## Sample3 0.079208 11 Mesenchyme 7 ## Sample4 0.014702 11 Mesenchyme 8 ## Sample5 0.111286 24 Mesenchyme 9 ## Sample6 0.000000 20 Mesenchyme 10 14.3.2.3 Statistical modelling We set up the design matrix to block on the batch-to-batch differences across different embryo pools, while retaining an additive term that represents the effect of injection. The latter is represented in our model as the log-fold change in gene expression in td-Tomato-positive cells over their negative counterparts within the same label. Our aim is to test whether this log-fold change is significantly different from zero. design &lt;- model.matrix(~factor(pool) + factor(tomato), y$samples) design ## (Intercept) factor(pool)4 factor(pool)5 factor(tomato)TRUE ## Sample1 1 0 0 1 ## Sample2 1 0 0 0 ## Sample3 1 1 0 1 ## Sample4 1 1 0 0 ## Sample5 1 0 1 1 ## Sample6 1 0 1 0 ## attr(,&quot;assign&quot;) ## [1] 0 1 1 2 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$`factor(pool)` ## [1] &quot;contr.treatment&quot; ## ## attr(,&quot;contrasts&quot;)$`factor(tomato)` ## [1] &quot;contr.treatment&quot; We estimate the negative binomial (NB) dispersions with estimateDisp(). The role of the NB dispersion is to model the mean-variance trend (Figure 14.2), which is not easily accommodated by QL dispersions alone due to the quadratic nature of the NB mean-variance trend. y &lt;- estimateDisp(y, design) summary(y$trended.dispersion) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0103 0.0167 0.0213 0.0202 0.0235 0.0266 plotBCV(y) Figure 14.2: Biological coefficient of variation (BCV) for each gene as a function of the average abundance. The BCV is computed as the square root of the NB dispersion after empirical Bayes shrinkage towards the trend. Trended and common BCV estimates are shown in blue and red, respectively. We also estimate the quasi-likelihood dispersions with glmQLFit() (Chen, Lun, and Smyth 2016). This fits a GLM to the counts for each gene and estimates the QL dispersion from the GLM deviance. We set robust=TRUE to avoid distortions from highly variable clusters (Phipson et al. 2016). The QL dispersion models the uncertainty and variability of the per-gene variance (Figure 14.3) - which is not well handled by the NB dispersions, so the two dispersion types complement each other in the final analysis. fit &lt;- glmQLFit(y, design, robust=TRUE) summary(fit$var.prior) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.318 0.714 0.854 0.804 0.913 1.067 summary(fit$df.prior) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.227 12.675 12.675 12.339 12.675 12.675 plotQLDisp(fit) Figure 14.3: QL dispersion estimates for each gene as a function of abundance. Raw estimates (black) are shrunk towards the trend (blue) to yield squeezed estimates (red). We test for differences in expression due to injection using glmQLFTest(). DEGs are defined as those with non-zero log-fold changes at a false discovery rate of 5%. Very few genes are significantly DE, indicating that injection has little effect on the transcriptome of mesenchyme cells. (Note that this logic is somewhat circular, as a large transcriptional effect may have caused cells of this type to be re-assigned to a different label. We discuss this in more detail in Section 14.5 below.) res &lt;- glmQLFTest(fit, coef=ncol(design)) summary(decideTests(res)) ## factor(tomato)TRUE ## Down 8 ## NotSig 5672 ## Up 8 topTags(res) ## Coefficient: factor(tomato)TRUE ## logFC logCPM F PValue FDR ## Phlda2 -4.3874 9.934 1638.59 1.812e-16 1.031e-12 ## Erdr1 2.0691 8.833 356.37 1.061e-11 3.017e-08 ## Mid1 1.5191 6.931 120.15 1.844e-08 3.497e-05 ## H13 -1.0596 7.540 80.80 2.373e-07 2.527e-04 ## Kcnq1ot1 1.3763 7.242 83.31 2.392e-07 2.527e-04 ## Akr1e1 -1.7206 5.128 79.31 2.665e-07 2.527e-04 ## Zdbf2 1.8008 6.797 83.66 6.809e-07 5.533e-04 ## Asb4 -0.9235 7.341 53.45 2.918e-06 2.075e-03 ## Impact 0.8516 7.353 50.31 4.145e-06 2.620e-03 ## Lum -0.6031 9.275 41.67 1.205e-05 6.851e-03 14.3.3 Putting it all together We repeat this process for each of the labels to identify injection-induced DE in each cell type. This is mostly straightforward as we can write a loop that simply performs the DE analysis for each subset of columns in summed. However, some additional care is required to automatically deal with labels that are not represented in both injected and background cells, for which a DE analysis between conditions is meaningless; or are not represented in a sufficient number of replicate samples to enable modelling of biological variability. This is represented by the extra checks related to design in the code chunk below. de.results &lt;- list() for (i in unique(summed$celltype.mapped)) { current &lt;- summed[,i==summed$celltype.mapped] y &lt;- DGEList(counts(current), samples=colData(current)) discarded &lt;- isOutlier(colSums(counts(current)), log=TRUE, type=&quot;lower&quot;, nmads=3) y &lt;- y[,!discarded] y &lt;- y[filterByExpr(y, group=current$tomato),] y &lt;- calcNormFactors(y) design &lt;- try( model.matrix(~factor(pool) + factor(tomato), y$samples), silent=TRUE ) if (is(design, &quot;try-error&quot;) || qr(design)$rank==nrow(design) || qr(design)$rank &lt; ncol(design)) { # Skipping labels without contrasts or without # enough residual d.f. to estimate the dispersion. next } y &lt;- estimateDisp(y, design) fit &lt;- glmQLFit(y, design) res &lt;- glmQLFTest(fit, coef=ncol(design)) de.results[[i]] &lt;- res } We examine the numbers of DEGs at a FDR of 5% for each label. In general, there seems to be very little differential expression that is introduced by injection. summaries &lt;- lapply(de.results, FUN=function(x) summary(decideTests(x))[,1]) sum.tab &lt;- do.call(rbind, summaries) sum.tab ## Down NotSig Up ## Mesenchyme 8 5672 8 ## Endothelium 3 3224 4 ## Allantois 64 4779 65 ## Erythroid3 10 5056 11 ## Erythroid1 8 2784 12 ## Pharyngeal mesoderm 5 5080 8 ## Forebrain/Midbrain/Hindbrain 8 6225 12 ## Spinal cord 14 4552 36 ## Cardiomyocytes 6 4361 5 ## Somitic mesoderm 10 2940 18 ## NMP 6 4105 12 ## Paraxial mesoderm 4 4756 5 ## Erythroid2 4 3389 9 ## Haematoendothelial progenitors 4 4106 7 ## Neural crest 6 3314 5 ## Rostral neurectoderm 3 2691 3 ## Intermediate mesoderm 5 3070 5 ## ExE mesoderm 5 5045 11 ## Surface ectoderm 7 5557 9 ## Gut 7 4479 7 ## Caudal Mesoderm 3 1417 4 ## Blood progenitors 2 1 2124 3 ## Stripped 7 393 0 ## Def. endoderm 3 1280 1 ## Blood progenitors 1 1 1248 2 ## PGC 1 527 0 ## Caudal epiblast 0 1405 1 ## Visceral endoderm 4 245 1 ## ExE endoderm 2 502 2 A survey of the DEGs from all labels identifies Xist as being consistently downregulated in the injected cells. This is consistent with the fact that the injected cells are male while the background cells are derived from pools of male and female embryos (due to experimental difficulties with resolving sex at this stage). The consistent downregulation of Phlda2 and Cdkn1c in the injected cells is also interesting, given that both are imprinted genes. # TODO: easier consolidation. degs &lt;- lapply(de.results, FUN=function(x) rownames(topTags(x, p.value=0.05))) common.degs &lt;- sort(table(unlist(degs)), decreasing=TRUE) head(common.degs, 20) ## ## Erdr1 Xist Mid1 Cdkn1c Phlda2 Kcnq1ot1 Akr1e1 Nnat ## 25 24 22 20 20 18 12 8 ## Slc38a4 Hopx H13 Mcts2 Zdbf2 Hbb-y Asb4 Baiap2l1 ## 8 7 6 4 4 3 2 2 ## Hist1h1b Hist1h1e Impact Peg3 ## 2 2 2 2 We also list the labels that were skipped due to the absence of replicates or contrasts. If it is necessary to extract statistics in the absence of replicates, several strategies can be applied such as reducing the complexity of the model or using a predefined value for the NB dispersion. We refer readers to the edgeR user’s guide for more details. setdiff(unique(summed$celltype.mapped), names(summaries)) ## [1] &quot;ExE ectoderm&quot; &quot;Caudal neurectoderm&quot; &quot;Parietal endoderm&quot; ## [4] &quot;Notochord&quot; &quot;Mixed mesoderm&quot; 14.4 Differential abundance between conditions 14.4.1 Overview In a DA analysis, we test for significant changes in per-label cell abundance across conditions. This will reveal which cell types are depleted or enriched upon treatment, which is arguably just as interesting as changes in expression within each cell type. The DA analysis has a long history in flow cytometry (Finak et al. 2014; A. T. L. Lun, Richard, and Marioni 2017) where it is routinely used to examine the effects of different conditions on the composition of complex cell populations. By performing it here, we effectively treat scRNA-seq as a “super-FACS” technology for defining relevant subpopulations using the entire transcriptome. We prepare for the DA analysis by quantifying the number of cells assigned to each label (or cluster). In this case, we are aiming to identify labels that change in abundance among the compartment of injected cells compared to the background. abundances &lt;- table(merged$celltype.mapped, merged$sample) abundances &lt;- unclass(abundances) head(abundances) ## ## 5 6 7 8 9 10 ## Allantois 97 15 139 127 318 259 ## Blood progenitors 1 6 3 16 6 8 17 ## Blood progenitors 2 31 8 28 21 43 114 ## Cardiomyocytes 85 21 79 31 174 211 ## Caudal epiblast 2 2 0 0 22 45 ## Caudal Mesoderm 10 10 9 3 10 29 14.4.2 Performing the DA analysis Our DA analysis will again be performed with the edgeR package. This allows us to take advantage of the NB GLM methods to model overdispersed count data in the presence of limited replication - except that the counts are not of reads per gene, but of cells per label (A. T. L. Lun, Richard, and Marioni 2017). The aim is to share information across labels to improve our estimates of the biological variability in cell abundance between replicates. # Attaching some column metadata. extra.info &lt;- colData(merged)[match(colnames(abundances), merged$sample),] y.ab &lt;- DGEList(abundances, samples=extra.info) y.ab ## An object of class &quot;DGEList&quot; ## $counts ## ## 5 6 7 8 9 10 ## Allantois 97 15 139 127 318 259 ## Blood progenitors 1 6 3 16 6 8 17 ## Blood progenitors 2 31 8 28 21 43 114 ## Cardiomyocytes 85 21 79 31 174 211 ## Caudal epiblast 2 2 0 0 22 45 ## 29 more rows ... ## ## $samples ## group lib.size norm.factors batch cell barcode sample ## 5 1 2298 1 5 cell_9769 AAACCTGAGACTGTAA 5 ## 6 1 1026 1 6 cell_12180 AAACCTGCAGATGGCA 6 ## 7 1 2740 1 7 cell_13227 AAACCTGAGACAAGCC 7 ## 8 1 2904 1 8 cell_16234 AAACCTGCAAACCCAT 8 ## 9 1 4057 1 9 cell_19332 AAACCTGCAACGATCT 9 ## 10 1 6401 1 10 cell_23875 AAACCTGAGGCATGTG 10 ## stage tomato pool stage.mapped celltype.mapped ## 5 E8.5 TRUE 3 E8.25 Mesenchyme ## 6 E8.5 FALSE 3 E8.25 Somitic mesoderm ## 7 E8.5 TRUE 4 E8.5 Somitic mesoderm ## 8 E8.5 FALSE 4 E8.25 ExE mesoderm ## 9 E8.5 TRUE 5 E8.0 ExE mesoderm ## 10 E8.5 FALSE 5 E8.5 Forebrain/Midbrain/Hindbrain ## closest.cell doub.density cluster ## 5 cell_24159 0.029850 20 ## 6 cell_63247 0.291916 6 ## 7 cell_25454 0.601740 17 ## 8 cell_139075 0.004733 24 ## 9 cell_116116 0.079415 13 ## 10 cell_39343 0.040747 1 We filter out low-abundance labels as previously described. This avoids cluttering the result table with very rare subpopulations that contain only a handful of cells. For a DA analysis of cluster abundances, filtering is generally not required as most clusters will not be of low-abundance (otherwise there would not have been enough evidence to define the cluster in the first place). keep &lt;- filterByExpr(y.ab, group=y.ab$samples$tomato) y.ab &lt;- y.ab[keep,] summary(keep) ## Mode FALSE TRUE ## logical 10 24 Unlike DE analyses, we do not perform an additional normalization step with calcNormFactors(). This means that we are only normalizing based on the “library size”, i.e., the total number of cells in each sample. Any changes we detect between conditions will subsequently represent differences in the proportion of cells in each cluster. The motivation behind this decision is discussed in more detail in Section 14.4.3. We formulate the design matrix with a blocking factor for the batch of origin for each sample and an additive term for the td-Tomato status (i.e., injection effect). Here, the log-fold change in our model refers to the change in cell abundance after injection, rather than the change in gene expression. design &lt;- model.matrix(~factor(pool) + factor(tomato), y.ab$samples) We use the estimateDisp() function to estimate the NB dipersion for each cluster (Figure 14.4). We turn off the trend as we do not have enough points for its stable estimation. y.ab &lt;- estimateDisp(y.ab, design, trend=&quot;none&quot;) summary(y.ab$common.dispersion) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0614 0.0614 0.0614 0.0614 0.0614 0.0614 plotBCV(y.ab, cex=1) Figure 14.4: Biological coefficient of variation (BCV) for each label with respect to its average abundance. BCVs are defined as the square root of the NB dispersion. Common dispersion estimates are shown in red. We repeat this process with the QL dispersion, again disabling the trend (Figure 14.5). fit.ab &lt;- glmQLFit(y.ab, design, robust=TRUE, abundance.trend=FALSE) summary(fit.ab$var.prior) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.25 1.25 1.25 1.25 1.25 1.25 summary(fit.ab$df.prior) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## Inf Inf Inf Inf Inf Inf plotQLDisp(fit.ab, cex=1) Figure 14.5: QL dispersion estimates for each label with respect to its average abundance. Quarter-root values of the raw estimates are shown in black while the shrunken estimates are shown in red. Shrinkage is performed towards the common dispersion in blue. We test for differences in abundance between td-Tomato-positive and negative samples using glmQLFTest(). We see that extra-embryonic ectoderm is strongly depleted in the injected cells. This is consistent with the expectation that cells injected into the blastocyst should not contribute to extra-embryonic tissue. The injected cells also contribute more to the mesenchyme, which may also be of interest. res &lt;- glmQLFTest(fit.ab, coef=ncol(design)) summary(decideTests(res)) ## factor(tomato)TRUE ## Down 1 ## NotSig 22 ## Up 1 topTags(res) ## Coefficient: factor(tomato)TRUE ## logFC logCPM F PValue FDR ## ExE ectoderm -6.5663 13.02 66.267 1.352e-10 3.245e-09 ## Mesenchyme 1.1652 16.29 11.291 1.535e-03 1.841e-02 ## Allantois 0.8345 15.51 5.312 2.555e-02 1.621e-01 ## Cardiomyocytes 0.8484 14.86 5.204 2.701e-02 1.621e-01 ## Neural crest -0.7706 14.76 4.106 4.830e-02 2.149e-01 ## Endothelium 0.7519 14.29 3.912 5.371e-02 2.149e-01 ## Erythroid3 -0.6431 17.28 3.604 6.367e-02 2.183e-01 ## Haematoendothelial progenitors 0.6581 14.72 3.124 8.351e-02 2.505e-01 ## ExE mesoderm 0.3805 15.68 1.181 2.827e-01 6.258e-01 ## Pharyngeal mesoderm 0.3793 15.72 1.169 2.850e-01 6.258e-01 14.4.3 Handling composition effects 14.4.3.1 Background As mentioned above, we do not use calcNormFactors() in our default DA analysis. This normalization step assumes that most of the input features are not different between conditions. While this assumption is reasonable for most types of gene expression data, it is generally too strong for cell type abundance - most experiments consist of only a few cell types that may all change in abundance upon perturbation. Thus, our default approach is to only normalize based on the total number of cells in each sample, which means that we are effectively testing for differential proportions between conditions. Unfortunately, the use of the total number of cells leaves us susceptible to composition effects. For example, a large increase in abundance for one cell subpopulation will introduce decreases in proportion for all other subpopulations - which is technically correct, but may be misleading if one concludes that those other subpopulations are decreasing in abundance of their own volition. If composition biases are proving problematic for interpretation of DA results, we have several avenues for removing them or mitigating their impact by leveraging a priori biological knowledge. 14.4.3.2 Assuming most labels do not change If it is possible to assume that most labels (i.e., cell types) do not change in abundance, we can use calcNormFactors() to compute normalization factors. This seems to be a fairly reasonable assumption for the WT chimeras where the injection is expected to have only a modest effect at most. y.ab2 &lt;- calcNormFactors(y.ab) y.ab2$samples$norm.factors ## [1] 1.0055 1.0833 1.1658 0.7614 1.0616 0.9743 We then proceed with the remainder of the edgeR analysis, shown below in condensed format. Many of the positive log-fold changes are shifted towards zero, consistent with the removal of composition biases from the presence of extra-embryonic ectoderm in only background cells. In particular, the mesenchyme is no longer significantly DA after injection. y.ab2 &lt;- estimateDisp(y.ab2, design, trend=&quot;none&quot;) fit.ab2 &lt;- glmQLFit(y.ab2, design, robust=TRUE, abundance.trend=FALSE) res2 &lt;- glmQLFTest(fit.ab2, coef=ncol(design)) topTags(res2, n=10) ## Coefficient: factor(tomato)TRUE ## logFC logCPM F PValue FDR ## ExE ectoderm -6.9215 13.17 70.364 5.738e-11 1.377e-09 ## Mesenchyme 0.9513 16.27 6.787 1.219e-02 1.143e-01 ## Neural crest -1.0032 14.78 6.464 1.429e-02 1.143e-01 ## Erythroid3 -0.8504 17.35 5.517 2.299e-02 1.380e-01 ## Cardiomyocytes 0.6400 14.84 2.735 1.047e-01 4.809e-01 ## Allantois 0.6054 15.51 2.503 1.202e-01 4.809e-01 ## Forebrain/Midbrain/Hindbrain -0.4943 16.55 1.928 1.713e-01 5.178e-01 ## Endothelium 0.5482 14.27 1.917 1.726e-01 5.178e-01 ## Erythroid2 -0.4818 16.00 1.677 2.015e-01 5.373e-01 ## Haematoendothelial progenitors 0.4262 14.73 1.185 2.818e-01 6.240e-01 14.4.3.3 Removing the offending labels Another approach is to repeat the analysis after removing DA clusters containing many cells. This provides a clearer picture of the changes in abundance among the remaining clusters. Here, we remove the extra-embryonic ectoderm and reset the total number of cells for all samples with keep.lib.sizes=FALSE. offenders &lt;- &quot;ExE ectoderm&quot; y.ab3 &lt;- y.ab[setdiff(rownames(y.ab), offenders),, keep.lib.sizes=FALSE] y.ab3$samples ## group lib.size norm.factors batch cell barcode sample ## 5 1 2268 1 5 cell_9769 AAACCTGAGACTGTAA 5 ## 6 1 993 1 6 cell_12180 AAACCTGCAGATGGCA 6 ## 7 1 2708 1 7 cell_13227 AAACCTGAGACAAGCC 7 ## 8 1 2749 1 8 cell_16234 AAACCTGCAAACCCAT 8 ## 9 1 4009 1 9 cell_19332 AAACCTGCAACGATCT 9 ## 10 1 6224 1 10 cell_23875 AAACCTGAGGCATGTG 10 ## stage tomato pool stage.mapped celltype.mapped ## 5 E8.5 TRUE 3 E8.25 Mesenchyme ## 6 E8.5 FALSE 3 E8.25 Somitic mesoderm ## 7 E8.5 TRUE 4 E8.5 Somitic mesoderm ## 8 E8.5 FALSE 4 E8.25 ExE mesoderm ## 9 E8.5 TRUE 5 E8.0 ExE mesoderm ## 10 E8.5 FALSE 5 E8.5 Forebrain/Midbrain/Hindbrain ## closest.cell doub.density cluster ## 5 cell_24159 0.029850 20 ## 6 cell_63247 0.291916 6 ## 7 cell_25454 0.601740 17 ## 8 cell_139075 0.004733 24 ## 9 cell_116116 0.079415 13 ## 10 cell_39343 0.040747 1 y.ab3 &lt;- estimateDisp(y.ab3, design, trend=&quot;none&quot;) fit.ab3 &lt;- glmQLFit(y.ab3, design, robust=TRUE, abundance.trend=FALSE) res3 &lt;- glmQLFTest(fit.ab3, coef=ncol(design)) topTags(res3, n=10) ## Coefficient: factor(tomato)TRUE ## logFC logCPM F PValue FDR ## Mesenchyme 1.1274 16.32 11.501 0.001438 0.03308 ## Allantois 0.7950 15.54 5.231 0.026836 0.18284 ## Cardiomyocytes 0.8104 14.90 5.152 0.027956 0.18284 ## Neural crest -0.8085 14.80 4.903 0.031798 0.18284 ## Erythroid3 -0.6808 17.32 4.387 0.041743 0.19202 ## Endothelium 0.7151 14.32 3.830 0.056443 0.21636 ## Haematoendothelial progenitors 0.6189 14.76 2.993 0.090338 0.29683 ## Def. endoderm 0.4911 12.43 1.084 0.303347 0.67818 ## ExE mesoderm 0.3419 15.71 1.036 0.314058 0.67818 ## Pharyngeal mesoderm 0.3407 15.76 1.025 0.316623 0.67818 A similar strategy can be used to focus on proportional changes within a single subpopulation of a very heterogeneous data set. For example, if we collected a whole blood data set, we could subset to T cells and test for changes in T cell subtypes (memory, killer, regulatory, etc.) using the total number of T cells in each sample as the library size. This avoids detecting changes in T cell subsets that are driven by compositional effects from changes in abundance of, say, B cells in the same sample. 14.4.3.4 Testing against a log-fold change threshold Here, we assume that composition bias introduces a spurious log2-fold change of no more than \\(\\tau\\) for a non-DA label. This can be roughly interpreted as the maximum log-fold change in the total number of cells caused by DA in other labels. (By comparison, fold-differences in the totals due to differences in capture efficiency or the size of the original cell population are not attributable to composition bias and should not be considered when choosing \\(\\tau\\).) We then mitigate the effect of composition biases by testing each label for changes in abundance beyond \\(\\tau\\) (McCarthy and Smyth 2009; A. T. L. Lun, Richard, and Marioni 2017). res.lfc &lt;- glmTreat(fit.ab, coef=ncol(design), lfc=1) summary(decideTests(res.lfc)) ## factor(tomato)TRUE ## Down 1 ## NotSig 23 ## Up 0 topTags(res.lfc) ## Coefficient: factor(tomato)TRUE ## logFC unshrunk.logFC logCPM PValue ## ExE ectoderm -6.5663 -7.0015 13.02 2.626e-09 ## Mesenchyme 1.1652 1.1658 16.29 1.323e-01 ## Cardiomyocytes 0.8484 0.8498 14.86 3.796e-01 ## Allantois 0.8345 0.8354 15.51 3.975e-01 ## Neural crest -0.7706 -0.7719 14.76 4.501e-01 ## Endothelium 0.7519 0.7536 14.29 4.665e-01 ## Haematoendothelial progenitors 0.6581 0.6591 14.72 5.622e-01 ## Def. endoderm 0.5262 0.5311 12.40 5.934e-01 ## Erythroid3 -0.6431 -0.6432 17.28 6.118e-01 ## Caudal Mesoderm -0.3996 -0.4036 12.09 6.827e-01 ## FDR ## ExE ectoderm 6.303e-08 ## Mesenchyme 9.950e-01 ## Cardiomyocytes 9.950e-01 ## Allantois 9.950e-01 ## Neural crest 9.950e-01 ## Endothelium 9.950e-01 ## Haematoendothelial progenitors 9.950e-01 ## Def. endoderm 9.950e-01 ## Erythroid3 9.950e-01 ## Caudal Mesoderm 9.950e-01 The choice of \\(\\tau\\) can be loosely motivated by external experimental data. For example, if we observe a doubling of cell numbers in an in vitro system after treatment, we might be inclined to set \\(\\tau=1\\). This ensures that any non-DA subpopulation is not reported as being depleted after treatment. Some caution is still required, though - even if the external numbers are accurate, we need to assume that cell capture efficiency is (on average) equal between conditions to justify their use as \\(\\tau\\). And obviously, the use of a non-zero \\(\\tau\\) will reduce power to detect real changes when the composition bias is not present. 14.5 DE or DA? Two sides of the same coin While useful, the distinction between DA and DE analyses is inherently artificial for scRNA-seq data. This is because the labels used in the former are defined based on the genes to be tested in the latter. To illustrate, consider a scRNA-seq experiment involving two biological conditions with several shared cell types. We focus on a cell type \\(X\\) that is present in both conditions but contains some DEGs between conditions. This leads to two possible outcomes: The DE between conditions causes \\(X\\) to form two separate clusters (say, \\(X_1\\) and \\(X_2\\)) in expression space. This manifests as DA where \\(X_1\\) is enriched in one condition and \\(X_2\\) is enriched in the other condition. The DE between conditions is not sufficient to split \\(X\\) into two separate clusters, e.g., because the data integration procedure identifies them as corresponding cell types and merges them together. This means that the differences between conditions manifest as DE within the single cluster corresponding to \\(X\\). We have described the example above in terms of clustering, but the same arguments apply for any labelling strategy based on the expression profiles, e.g., automated cell type assignment (Chapter 12). Moreover, the choice between outcomes 1 and 2 is made implicitly by the combined effect of the data merging, clustering and label assignment procedures. For example, differences between conditions are more likely to manifest as DE for coarser clusters and as DA for finer clusters, but this is difficult to predict reliably. The moral of the story is that DA and DE analyses are simply two different perspectives on the same phenomena. For any comprehensive characterization of differences between populations, it is usually necessary to consider both analyses. Indeed, they complement each other almost by definition, e.g., clustering parameters that reduce DE will increase DA and vice versa. 14.6 Avoiding problems with ambient RNA 14.6.1 Motivation Ambient contamination is a phenomenon that is generally most pronounced in massively multiplexed scRNA-seq protocols. Differences in the ambient profile across samples are not uncommon when dealing with strong experimental perturbations. This is problematic for DE analyses between conditions, as DEGs detected for a particular cell type may be driven by differences in the ambient profiles rather than any intrinsic change in gene regulation. To illustrate, we consider the Tal1-knockout (KO) chimera data from Pijuan-Sala et al. (2019). This is very similar to the WT chimera dataset we previously examined, only differing in that the Tal1 gene was knocked out in the injected cells. Tal1 is a transcription factor that has known roles in erythroid differentiation; the aim of the experiment was to determine if blocking of the erythroid lineage diverted cells to other developmental fates. library(MouseGastrulationData) sce.tal1 &lt;- Tal1ChimeraData() rownames(sce.tal1) &lt;- uniquifyFeatureNames( rowData(sce.tal1)$ENSEMBL, rowData(sce.tal1)$SYMBOL) sce.tal1 ## class: SingleCellExperiment ## dim: 29453 56122 ## metadata(0): ## assays(1): counts ## rownames(29453): Xkr4 Gm1992 ... CAAA01147332.1 tomato-td ## rowData names(2): ENSEMBL SYMBOL ## colnames(56122): cell_1 cell_2 ... cell_56121 cell_56122 ## colData names(8): cell barcode ... celltype.mapped pool ## reducedDimNames(1): pca.corrected ## spikeNames(0): ## altExpNames(0): We will perform a DE analysis between WT and KO cells labelled as “neural crest”. We observe that the strongest DEGs are the hemoglobins, which are downregulated in the injected cells. This is rather surprising as cells undergoing neuronal development should not express hemoglobins in the first place. The most sober explanation is that the background samples contain more hemoglobin transcripts in the ambient solution due to leakage from erythrocytes (or their precursors) during sorting and dissociation. summed.tal1 &lt;- aggregateAcrossCells(sce.tal1, ids=DataFrame(sample=sce.tal1$sample, label=sce.tal1$celltype.mapped) ) summed.neural &lt;- summed.tal1[,summed.tal1$label==&quot;Neural crest&quot;] summed.neural ## class: SingleCellExperiment ## dim: 29453 4 ## metadata(0): ## assays(1): counts ## rownames(29453): Xkr4 Gm1992 ... CAAA01147332.1 tomato-td ## rowData names(2): ENSEMBL SYMBOL ## colnames: NULL ## colData names(10): cell barcode ... sample label ## reducedDimNames(1): pca.corrected ## spikeNames(0): ## altExpNames(0): # Standard edgeR analysis, as described above. y.neural &lt;- DGEList(counts(summed.neural), samples=colData(summed.neural)) keep.neural &lt;- filterByExpr(y.neural, group=y.neural$samples$tomato) y.neural &lt;- y.neural[keep.neural,] y.neural &lt;- calcNormFactors(y.neural) block &lt;- y.neural$samples$sample %% 2 == 0 design &lt;- model.matrix(~factor(block) + factor(tomato), y.neural$samples) y.neural &lt;- estimateDisp(y.neural, design) fit.neural &lt;- glmQLFit(y.neural, design, robust=TRUE) res.neural &lt;- glmQLFTest(fit.neural, coef=ncol(design)) summary(decideTests(res.neural)) ## factor(tomato)TRUE ## Down 351 ## NotSig 9818 ## Up 481 topTags(res.neural, n=10) ## Coefficient: factor(tomato)TRUE ## logFC logCPM F PValue FDR ## Hba-a1 -8.5967 6.744 2756.6 0.000e+00 0.000e+00 ## Hbb-y -8.4156 8.357 7364.3 0.000e+00 0.000e+00 ## Hbb-bh1 -8.0910 9.160 10758.3 0.000e+00 0.000e+00 ## Hba-x -7.7248 8.533 7896.5 0.000e+00 0.000e+00 ## Xist -7.5557 8.212 6657.3 0.000e+00 0.000e+00 ## Hba-a2 -8.8662 5.813 1517.7 1.724e-310 3.060e-307 ## Erdr1 1.8895 7.616 1407.1 2.347e-289 3.570e-286 ## Cdkn1c -8.8645 4.961 814.9 8.800e-173 1.171e-169 ## Uba52 -0.8797 8.386 424.2 1.866e-92 2.208e-89 ## Grb10 -1.4034 6.583 401.4 1.139e-87 1.213e-84 14.6.2 Discarding ambient DEGs The presence of ambient contamination makes it difficult to interpret multi-condition DE analyses. To mitigate its effects, we need to obtain an estimate of the ambient “expression” profile by going back to the raw count matrix for each sample. We follow the approach used in emptyDrops() (Lun et al. 2019) and consider all barcodes with total counts below 100 to represent empty droplets. raw.tal1 &lt;- Tal1ChimeraData(type=&quot;raw&quot;) library(Matrix) ambient &lt;- vector(&quot;list&quot;, length(raw.tal1)) for (i in seq_along(raw.tal1)) { curmat &lt;- counts(raw.tal1[[i]]) is.empty &lt;- colSums(curmat) &lt; 100 ambient[[i]] &lt;- rowSums(curmat[,is.empty]) } ambient &lt;- do.call(cbind, ambient) colnames(ambient) &lt;- names(raw.tal1) rownames(ambient) &lt;- uniquifyFeatureNames( rowData(raw.tal1[[1]])$ENSEMBL, rowData(raw.tal1[[1]])$SYMBOL) head(ambient) ## 1 2 3 4 ## Xkr4 1 0 0 0 ## Gm1992 0 0 0 0 ## Gm37381 1 0 1 0 ## Rp1 0 1 0 1 ## Sox17 75 76 31 53 ## Gm37323 0 0 0 0 Given prior knowledge of mutually exclusive gene expression profiles, we estimate the contribution of ambient RNA to each sample (Young and Behjati 2018) and subtract it to remove the effects of ambient contamination. In our case, we assume (reasonably) that hemoglobins should not be expressed in neural crest cells and use this to estimate the contamination rate in each sample. is.hbb &lt;- grep(&quot;^Hb[ab]-&quot;, rownames(summed.neural)) neural.hb &lt;- colSums(counts(summed.neural)[is.hbb,]) ambient.hb &lt;- colSums(ambient[is.hbb,]) con.rate &lt;- neural.hb/ambient.hb data.frame(neural=neural.hb, ambient=ambient.hb, rate=con.rate) ## neural ambient rate ## 1 47 13153 0.003573 ## 2 60 12933 0.004639 ## 3 23938 300274 0.079721 ## 4 26383 371826 0.070955 We scale the ambient counts by this rate to determine the proportion of ambient contribution to each gene. Genes in which over 10% of the counts are ambient-derived are discarded from our analysis. This yields a slightly smaller list of DEGs without the hemoglobins - by definition, but encouraging nonetheless as it suggests that any other (less obvious) effects of ambient contamination have also been removed. scaled.ambient &lt;- t(t(ambient) * con.rate) ratio &lt;- rowMeans(scaled.ambient) / rowMeans(counts(summed.neural)) non.ambient &lt;- ratio &lt; 0.1 summary(non.ambient) ## Mode FALSE TRUE NA&#39;s ## logical 4290 14869 10294 okay.genes &lt;- names(non.ambient)[which(non.ambient)] res.neural2 &lt;- res.neural[rownames(res.neural) %in% okay.genes,] summary(decideTests(res.neural2)) ## factor(tomato)TRUE ## Down 315 ## NotSig 9574 ## Up 452 topTags(res.neural2) ## Coefficient: factor(tomato)TRUE ## logFC logCPM F PValue FDR ## Xist -7.5557 8.212 6657.3 0.000e+00 0.000e+00 ## Erdr1 1.8895 7.616 1407.1 2.347e-289 1.213e-285 ## Uba52 -0.8797 8.386 424.2 1.866e-92 6.432e-89 ## Grb10 -1.4034 6.583 401.4 1.139e-87 2.945e-84 ## Gt(ROSA)26Sor 1.4813 5.716 351.9 2.801e-77 5.792e-74 ## Fdps 0.9814 7.218 337.2 3.677e-74 6.337e-71 ## Mest 0.5493 10.983 319.7 1.798e-70 2.657e-67 ## Impact 1.3967 5.718 314.7 2.051e-69 2.651e-66 ## H13 -1.4817 5.909 301.7 1.174e-66 1.349e-63 ## Msmo1 1.4938 5.439 301.1 1.580e-66 1.634e-63 14.6.3 Subtracting ambient counts It is worth commenting on the seductive idea of subtracting the ambient counts from the pseudo-bulk samples. This may seem like the most obvious approach for removing ambient contamination. Unfortunately, subtracted counts have unpredictable statistical properties due the distortion of the mean-variance relationship. Minor relative fluctuations at very large counts become large fold-changes after subtraction, manifesting as spurious DE in genes where a substantial proportion of counts is derived from the ambient solution. For example, several hemoglobin genes retain strong DE even after subtraction of the scaled ambient profile. subtracted &lt;- counts(summed.neural) - scaled.ambient subtracted &lt;- round(subtracted) subtracted[subtracted &lt; 0] &lt;- 0 subtracted[is.hbb,] ## 8 x 4 Matrix of class &quot;dgeMatrix&quot; ## [,1] [,2] [,3] [,4] ## Hbb-bt 0 0 7 18 ## Hbb-bs 1 2 31 42 ## Hbb-bh2 0 0 1 0 ## Hbb-bh1 2 0 0 0 ## Hbb-y 0 0 32 106 ## Hba-x 1 1 0 0 ## Hba-a1 0 0 365 451 ## Hba-a2 0 0 313 330 Another tempting approach is to use interaction models to implicitly subtract the ambient effect during GLM fitting. The assumption would be that, for genuine DEGs, the log-fold change within cells is larger in magnitude than those in the ambient solution (where the effect would be diluted by contributions from cell types where the gene is not DE). However, this is not always the case - a DE analysis of the ambient counts indicates that the hemoglobin log-fold change is actually stronger in the neural crest cells compared to the ambient solution, which leads to a rather awkward conclusion. # Re-using keep.neural to simplify comparison. y.ambient &lt;- DGEList(ambient) y.ambient &lt;- y.ambient[keep.neural,] y.ambient &lt;- calcNormFactors(y.ambient) y.ambient &lt;- estimateDisp(y.ambient, design) fit.ambient &lt;- glmQLFit(y.ambient, design, robust=TRUE) res.ambient &lt;- glmQLFTest(fit.ambient, coef=ncol(design)) summary(decideTests(res.ambient)) ## factor(tomato)TRUE ## Down 1581 ## NotSig 7742 ## Up 1327 topTags(res.ambient, n=10) ## Coefficient: factor(tomato)TRUE ## logFC logCPM F PValue FDR ## Hbb-y -5.244 12.797 16646 2.281e-28 2.430e-24 ## Hba-x -4.805 13.117 13773 1.272e-27 6.744e-24 ## Hbb-bh1 -5.049 13.716 13178 1.900e-27 6.744e-24 ## Hba-a1 -4.640 10.728 11847 4.992e-27 1.329e-23 ## Hba-a2 -4.498 9.473 8862 6.938e-26 1.478e-22 ## Blvrb -4.301 7.645 4073 7.931e-23 1.408e-19 ## Xist -4.361 7.489 4004 9.255e-23 1.408e-19 ## Gypa -5.113 7.208 3846 1.331e-22 1.695e-19 ## Car2 -3.492 8.532 3815 1.433e-22 1.695e-19 ## Hbb-bs -4.915 7.203 3418 3.869e-22 4.120e-19 Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] Matrix_1.2-17 MouseGastrulationData_0.99.12 [3] edgeR_3.27.13 limma_3.41.16 [5] scater_1.13.20 ggplot2_3.2.1 [7] BiocSingular_1.1.7 SingleCellExperiment_1.7.10 [9] SummarizedExperiment_1.15.9 DelayedArray_0.11.6 [11] BiocParallel_1.19.2 matrixStats_0.55.0 [13] Biobase_2.45.1 GenomicRanges_1.37.16 [15] GenomeInfoDb_1.21.1 IRanges_2.19.16 [17] S4Vectors_0.23.23 BiocGenerics_0.31.6 [19] Cairo_1.5-10 BiocStyle_2.13.2 [21] OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] bitops_1.0-6 bit64_0.9-7 [3] httr_1.4.1 RColorBrewer_1.1-2 [5] tools_3.6.1 backports_1.1.4 [7] R6_2.4.0 irlba_2.3.3 [9] vipor_0.4.5 DBI_1.0.0 [11] lazyeval_0.2.2 colorspace_1.4-1 [13] withr_2.1.2 tidyselect_0.2.5 [15] gridExtra_2.3 curl_4.2 [17] bit_1.1-14 compiler_3.6.1 [19] BiocNeighbors_1.3.5 labeling_0.3 [21] bookdown_0.13 scales_1.0.0 [23] rappdirs_0.3.1 stringr_1.4.0 [25] digest_0.6.21 rmarkdown_1.15 [27] XVector_0.25.0 pkgconfig_2.0.3 [29] htmltools_0.3.6 dbplyr_1.4.2 [31] highr_0.8 rlang_0.4.0 [33] RSQLite_2.1.2 shiny_1.3.2 [35] DelayedMatrixStats_1.7.2 dplyr_0.8.3 [37] RCurl_1.95-4.12 magrittr_1.5 [39] GenomeInfoDbData_1.2.1 Rcpp_1.0.2 [41] ggbeeswarm_0.6.0 munsell_0.5.0 [43] viridis_0.5.1 stringi_1.4.3 [45] yaml_2.2.0 zlibbioc_1.31.0 [47] BiocFileCache_1.9.1 AnnotationHub_2.17.9 [49] grid_3.6.1 blob_1.2.0 [51] promises_1.0.1 ExperimentHub_1.11.6 [53] crayon_1.3.4 lattice_0.20-38 [55] cowplot_1.0.0 splines_3.6.1 [57] locfit_1.5-9.1 zeallot_0.1.0 [59] knitr_1.25 pillar_1.4.2 [61] glue_1.3.1 evaluate_0.14 [63] BiocManager_1.30.4 httpuv_1.5.2 [65] vctrs_0.2.0 gtable_0.3.0 [67] purrr_0.3.2 assertthat_0.2.1 [69] xfun_0.9 mime_0.7 [71] rsvd_1.0.2 xtable_1.8-4 [73] later_0.8.0 viridisLite_0.3.0 [75] tibble_2.1.3 pheatmap_1.0.12 [77] AnnotationDbi_1.47.1 beeswarm_0.2.3 [79] memoise_1.1.0 statmod_1.4.32 [81] interactiveDisplayBase_1.23.0 Bibliography "],
["doublet-detection.html", "Chapter 15 Doublet detection 15.1 Overview 15.2 Doublet detection with clusters 15.3 Doublet detection by simulation 15.4 Strengths and weaknesses 15.5 Further comments Session Info 15.6 References", " Chapter 15 Doublet detection .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 15.1 Overview In single-cell RNA sequencing (scRNA-seq) experiments, doublets are artifactual libraries generated from two cells. They typically arise due to errors in cell sorting or capture, especially in droplet-based protocols (Zheng et al. 2017) involving thousands of cells. Doublets are obviously undesirable when the aim is to characterize populations at the single-cell level. In particular, doublets can be mistaken for intermediate populations or transitory states that do not actually exist. Thus, it is desirable to identify and remove doublet libraries so that they do not compromise interpretation of the results. Several experimental strategies are available for doublet removal. One approach exploits natural genetic variation when pooling cells from multiple donor individuals (Kang et al. 2018). Doublets can be identified as libraries with allele combinations that do not exist in any single donor. Another approach is to mark a subset of cells (e.g., all cells from one sample) with an antibody conjugated to a different oligonucleotide (Stoeckius et al. 2017). Upon pooling, libraries that are observed to have different oligonucleotides are considered to be doublets and removed. These approaches can be highly effective but rely on experimental information that may not be available. A more general approach is to infer doublets from the expression profiles alone (Dahlin et al. 2018). In this workflow, we will describe two purely computational approaches for detecting doublets from scRNA-seq data. The main difference between these two methods is whether or not they need cluster information beforehand. We will demonstrate the use of these methods on 10X Genomics data from a droplet-based scRNA-seq study of the mouse mammary gland (Bach et al. 2017). View history ### loading ### library(scRNAseq) sce.mam &lt;- BachMammaryData(samples=&quot;G_1&quot;) ### gene-annotation ### library(scater) rownames(sce.mam) &lt;- uniquifyFeatureNames( rowData(sce.mam)$Ensembl, rowData(sce.mam)$Symbol) library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] rowData(sce.mam)$SEQNAME &lt;- mapIds(ens.mm.v97, keys=rowData(sce.mam)$Ensembl, keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) ### quality-control ### is.mito &lt;- rowData(sce.mam)$SEQNAME == &quot;MT&quot; stats &lt;- perCellQCMetrics(sce.mam, subsets=list(Mito=which(is.mito))) qc &lt;- quickCellQC(stats, percent_subsets=&quot;subsets_Mito_percent&quot;, nmads=3) sce.mam &lt;- sce.mam[,!qc$discard] ### normalization ### library(scran) set.seed(101000110) clusters &lt;- quickCluster(sce.mam) sce.mam &lt;- computeSumFactors(sce.mam, clusters=clusters, min.mean=0.1) sce.mam &lt;- logNormCounts(sce.mam) ### variance-modelling ### set.seed(00010101) dec.mam &lt;- modelGeneVarByPoisson(sce.mam) ### dimensionality-reduction ### library(BiocSingular) set.seed(101010011) sce.mam &lt;- denoisePCA(sce.mam, technical=dec.mam, BSPARAM=IrlbaParam()) sce.mam &lt;- runTSNE(sce.mam, dimred=&quot;PCA&quot;) ### clustering ### snn.gr &lt;- buildSNNGraph(sce.mam, use.dimred=&quot;PCA&quot;, k=25) sce.mam$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) sce.mam ## class: SingleCellExperiment ## dim: 27998 2772 ## metadata(0): ## assays(2): counts logcounts ## rownames(27998): Xkr4 Gm1992 ... Vmn2r122 CAAA01147332.1 ## rowData names(3): Ensembl Symbol SEQNAME ## colnames: NULL ## colData names(4): Barcode Sample Condition cluster ## reducedDimNames(2): PCA TSNE ## spikeNames(0): ## altExpNames(0): 15.2 Doublet detection with clusters 15.2.1 Overview The doubletCluster() function will identify clusters that have intermediate expression profiles of two other clusters (Bach et al. 2017). Specifically, it will examine every possible triplet of clusters consisting of a query cluster and its two “parents”. It will then compute a number of statistics: The number of genes (N) that are differentially expressed in the same direction in the query cluster compared to both of the parent clusters. Such genes would be unique markers for the query cluster and provide evidence against the null hypothesis, i.e., that the query cluster consists of doublets from the two parents. Clusters with few unique genes are more likely to be composed of doublets. The ratio of the median library size in each parent to the median library size in the query (lib.size fields). Doublet libraries are generated from a larger initial pool of RNA compared to libraries for single cells, and thus the former should have larger library sizes. Library size ratios much greater than unity are inconsistent with a doublet identity for the query. The proportion of cells in the query cluster should also be reasonable - typically less than 5% of all cells, depending on how many cells were loaded onto the 10X Genomics device. For each query cluster, the best pair of parents is identified based solely on the lowest N. (This means that any lib.size* above unity is not definitive evidence against a doublet identity for a query cluster, as there may be a pair of parents with slightly higher N but both lib.size* values below unity.) If more detail is necessary, the all.pairs field contains statistics on all possible parent pairs for a given query cluster. library(scran) dbl.out &lt;- doubletCluster(sce.mam, sce.mam$cluster) dbl.out ## DataFrame with 11 rows and 9 columns ## source1 source2 N best p.value ## &lt;character&gt; &lt;character&gt; &lt;integer&gt; &lt;character&gt; &lt;numeric&gt; ## 10 11 1 0 Rfc1 0.304133297031587 ## 11 5 2 30 Ptn 1.35818791124658e-14 ## 1 10 3 117 Tinagl1 4.38558716805188e-17 ## 4 6 3 132 Pigr 3.04170568092603e-18 ## 5 11 8 134 Cd63 1.0483429284541e-13 ## 2 11 10 153 Ptma 1.9263161669515e-11 ## 6 9 5 197 Epcam 4.90533186350571e-20 ## 8 9 5 270 AF251705 3.296606994399e-24 ## 7 9 5 300 Fabp4 2.70725398963721e-32 ## 9 7 6 388 Dcn 4.93706079643116e-32 ## 3 11 4 517 Car2 1.89438943741351e-21 ## lib.size1 lib.size2 prop ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## 10 0.483225348362474 0.905387414573533 0.0256132756132756 ## 11 0.9924694645973 1.18853889246028 0.0216450216450216 ## 1 1.10449955886678 1.31840015684737 0.254689754689755 ## 4 0.679205503772747 1.49234354194407 0.184704184704185 ## 5 1.00758767465532 1.16785416859443 0.00865800865800866 ## 2 0.84136918559728 1.74115283572864 0.176406926406926 ## 6 0.882698905407613 0.882780591406633 0.00901875901875902 ## 8 0.856192060850963 0.856271293875287 0.0187590187590188 ## 7 0.666050295857988 0.666111932938856 0.0119047619047619 ## 9 1.50138811771238 1.13288913566537 0.0140692640692641 ## 3 0.404825637593873 0.670086995315637 0.274531024531025 ## all.pairs ## &lt;DataFrameList&gt; ## 10 11:1:0:...,2:1:4:...,4:2:27:...,... ## 11 5:2:30:...,7:2:111:...,10:5:136:...,... ## 1 10:3:117:...,10:4:168:...,10:6:251:...,... ## 4 6:3:132:...,10:6:181:...,7:3:205:...,... ## 5 11:8:134:...,8:6:140:...,8:7:157:...,... ## 2 11:10:153:...,11:7:186:...,11:9:261:...,... ## 6 9:5:197:...,5:4:219:...,10:5:239:...,... ## 8 9:5:270:...,7:5:338:...,6:5:366:...,... ## 7 9:5:300:...,9:6:329:...,5:2:334:...,... ## 9 7:6:388:...,8:7:403:...,11:8:417:...,... ## 3 11:4:517:...,5:1:627:...,5:4:634:...,... Clusters are then ranked by N in the output of doubletClusters(), allowing us to prioritize “high-risk” clusters that require careful investigation. If a more concrete threshold is necessary, we can identify clusters that have unusually low N using an outlier-based approach. library(scater) chosen.doublet &lt;- rownames(dbl.out)[isOutlier(dbl.out$N, type=&quot;lower&quot;, nmads=3, log=TRUE)] chosen.doublet ## [1] &quot;10&quot; 15.2.2 Application to the mammary data Examination of the output of doubletCluster() indicates that cluster 10 has the fewest unique genes and library sizes that are comparable to or greater than its parents. We see that every gene detected in this cluster is also expressed in either of the two proposed parent clusters (Figure 15.1). markers &lt;- findMarkers(sce.mam, sce.mam$cluster, direction=&quot;up&quot;) dbl.markers &lt;- markers[[&quot;10&quot;]] library(scater) chosen &lt;- rownames(dbl.markers)[dbl.markers$Top &lt;= 10] plotHeatmap(sce.mam, columns=order(sce.mam$cluster), colour_columns_by=&quot;cluster&quot;, features=chosen, cluster_cols=FALSE, center=TRUE, symmetric=TRUE, zlim=c(-5, 5), show_colnames=FALSE) Figure 15.1: Heatmap of mean-centred and normalized log-expression values for the top set of markers for cluster 10 in the mammary gland dataset. Column colours represent the cluster to which each cell is assigned, as indicated by the legend. Closer examination of some known markers suggests that the offending cluster consists of doublets of basal cells (Acta2) and alveolar cells (Csn2) (Figure 15.2). Indeed, no cell type is known to strongly express both of these genes at the same time, which supports the hypothesis that this cluster consists solely of doublets8. plotExpression(sce.mam, features=c(&quot;Acta2&quot;, &quot;Csn2&quot;), x=&quot;cluster&quot;, colour_by=&quot;cluster&quot;) Figure 15.2: Distribution of log-normalized expression values for Acta2 and Csn2 in each cluster. Each point represents a cell. The strength of doubletCluster() lies in its simplicity and ease of interpretation. Suspect clusters can be quickly flagged based on the metrics returned by the function. However, it is obviously dependent on the quality of the clustering. Clusters that are too coarse will fail to separate doublets from other cells, while clusters that are too fine will complicate interpretation. The method is also somewhat biased towards clusters with fewer cells, where the reduction in power is more likely to result in a low N. (Fortunately, this is a desirable effect as doublets should be rare in a properly performed scRNA-seq experiment.) 15.3 Doublet detection by simulation 15.3.1 Overview The other doublet detection strategy involves in silico simulation of doublets from the single-cell expression profiles (Dahlin et al. 2018). This is performed using the doubletCells() function from scran, which will: Simulate thousands of doublets by adding together two randomly chosen single-cell profiles. For each original cell, compute the density of simulated doublets in the surrounding neighbourhood. For each original cell, compute the density of other observed cells in the neighbourhood. Return the ratio between the two densities as a “doublet score” for each cell. This approach assumes that the simulated doublets are good approximations for real doublets. The use of random selection accounts for the relative abundances of different subpopulations, which affect the likelihood of their involvement in doublets; and the calculation of a ratio avoids high scores for non-doublet cells in highly abundant subpopulations. 15.3.2 Application to the mammary data We see the function in action below. To speed up the density calculations, doubletCells() will perform a PCA on the log-expression matrix. When BSPARAM=IrlbaParam(), methods from the irlba package are used to perform a fast approximate PCA - hence the use of set.seed() to ensure that results are reproducible. library(BiocSingular) set.seed(100) # Setting up the parameters for consistency with denoisePCA(); # this can be changed depending on your feature selection scheme. dbl.dens &lt;- doubletCells(sce.mam, BSPARAM=IrlbaParam(), subset.row=dec.mam$bio &gt; 0, d=ncol(reducedDim(sce.mam))) summary(dbl.dens) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0 4 14 335 48 56669 The highest doublet scores are concentrated in a single cluster of cells in the centre of Figure 15.3. sce.mam$DoubletScore &lt;- log10(dbl.dens+1) plotTSNE(sce.mam, colour_by=&quot;DoubletScore&quot;) Figure 15.3: t-SNE plot of the mammary gland data set. Each point is a cell coloured according to its doublet density. From the clustering information, we see that the affected cells belong to the same cluster that was identified using doubletCluster() (Figure 15.4)9. plotColData(sce.mam, x=&quot;cluster&quot;, y=&quot;DoubletScore&quot;, colour_by=&quot;cluster&quot;) Figure 15.4: Distribution of doublet scores for each cluster in the mammary gland data set. Each point is a cell. 15.4 Strengths and weaknesses The advantage of doubletCells() is that it does not depend on clusters, reducing the sensitivity of the results to clustering quality. The downside is that it requires some strong assumptions about how doublets form, such as the combining proportions and the sampling from pure subpopulations. In particular, doubletCells() treats the library size of each cell as an accurate proxy for its total RNA content. If this is not true, the simulation will not combine expression profiles from different cells in the correct proportions. This means that the simulated doublets will be systematically shifted away from the real doublets, resulting in doublet scores that are too low. Simply removing cells with high doublet scores will not be sufficient to eliminate real doublets from the data set. In some cases, only a subset of the cells in the putative doublet cluster actually have high scores. Removing these would still leave enough cells in that cluster to mislead downstream analyses. In fact, even defining a threshold on the doublet score is difficult as the interpretation of the score is relative. There is no general definition for a fixed threshold above which libraries are to be considered doublets. We recommend interpreting the doubletCells() scores in the context of cluster annotation. All cells from a cluster with a large average doublet score should be considered suspect, and close neighbours of problematic clusters should also be treated with caution. In contrast, a cluster containing a small proportion of high-scoring cells is probably safe provided that any interesting results are not being driven by those cells (e.g., checking that DE in an interesting gene is not driven solely by cells with high doublet scores). While clustering is still required, this approach is more robust than doubletClusters() to the quality of the clustering as the scores are computed on a per-cell basis. (As an aside, the issue of unknown combining proportions can be solved completely if spike-in information is available, e.g., in plate-based protocols. This will provide an accurate estimate of the total RNA content of each cell. To this end, spike-in-based size factors from Section 7.4 can be supplied to the doubletCells() function via the size.factors.content= argument. This will use the spike-in size factors to scale the contribution of each cell to a doublet library.) 15.5 Further comments Doublet detection procedures should only be applied to libraries generated in the same experimental batch. It is obviously impossible for doublets to form between two cells that were captured separately. Thus, some understanding of the experimental design is required prior to the use of the above functions. This avoids unnecessary concerns about the validity of batch-specific clusters that cannot possibly consist of doublets. It is also difficult to interpret doublet predictions in data containing cellular trajectories. By definition, cells in the middle of a trajectory are always intermediate between other cells and are liable to be incorrectly detected as doublets. Some protection is provided by the non-linear nature of many real trajectories, which reduces the risk of simulated doublets coinciding with real cells in doubletCells(). One can also put more weight on the relative library sizes in doubletCluster() instead of relying solely on N, under the assumption that sudden spikes in RNA content are unlikely in a continuous biological process. The best solution to the doublet problem is experimental - that is, to avoid generating them in the first place10. This should be a consideration when designing scRNA-seq experiments, where the desire to obtain large numbers of cells at minimum cost should be weighed against the general deterioration in data quality and reliability when doublets become more frequent. If cell labelling information is available (Kang et al. 2018; Stoeckius et al. 2018), we recommend using it to mark doublet cells for use in identification of problematic clusters or cellular states in downstream analyses. Direct removal fails to account for unlabelled intra-sample doublets that can still be present in sufficient numbers to drive misleading conclusions, while the marking approach uses “guilt by association” to identify neighboring unlabelled doublets. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] BiocSingular_1.1.7 scater_1.13.20 [3] ggplot2_3.2.1 scran_1.13.25 [5] SingleCellExperiment_1.7.10 SummarizedExperiment_1.15.9 [7] DelayedArray_0.11.6 BiocParallel_1.19.2 [9] matrixStats_0.55.0 Biobase_2.45.1 [11] GenomicRanges_1.37.16 GenomeInfoDb_1.21.1 [13] IRanges_2.19.16 S4Vectors_0.23.23 [15] BiocGenerics_0.31.6 Cairo_1.5-10 [17] BiocStyle_2.13.2 OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] viridis_0.5.1 edgeR_3.27.13 [3] viridisLite_0.3.0 DelayedMatrixStats_1.7.2 [5] assertthat_0.2.1 statmod_1.4.32 [7] BiocManager_1.30.4 highr_0.8 [9] dqrng_0.2.1 GenomeInfoDbData_1.2.1 [11] vipor_0.4.5 yaml_2.2.0 [13] pillar_1.4.2 lattice_0.20-38 [15] glue_1.3.1 limma_3.41.16 [17] digest_0.6.21 RColorBrewer_1.1-2 [19] XVector_0.25.0 colorspace_1.4-1 [21] cowplot_1.0.0 htmltools_0.3.6 [23] Matrix_1.2-17 pkgconfig_2.0.3 [25] pheatmap_1.0.12 bookdown_0.13 [27] zlibbioc_1.31.0 purrr_0.3.2 [29] scales_1.0.0 tibble_2.1.3 [31] withr_2.1.2 lazyeval_0.2.2 [33] magrittr_1.5 crayon_1.3.4 [35] evaluate_0.14 beeswarm_0.2.3 [37] tools_3.6.1 stringr_1.4.0 [39] munsell_0.5.0 locfit_1.5-9.1 [41] irlba_2.3.3 compiler_3.6.1 [43] rsvd_1.0.2 rlang_0.4.0 [45] grid_3.6.1 RCurl_1.95-4.12 [47] BiocNeighbors_1.3.5 igraph_1.2.4.1 [49] labeling_0.3 bitops_1.0-6 [51] rmarkdown_1.15 gtable_0.3.0 [53] R6_2.4.0 gridExtra_2.3 [55] knitr_1.25 dplyr_0.8.3 [57] stringi_1.4.3 ggbeeswarm_0.6.0 [59] Rcpp_1.0.2 tidyselect_0.2.5 [61] xfun_0.9 15.6 References Bibliography "],
["cell-cycle-assignment.html", "Chapter 16 Cell cycle assignment 16.1 Motivation 16.2 Using the cyclins 16.3 Using reference profiles 16.4 Using the cyclone() classifier 16.5 Regressing out cell cycle phase Session Info", " Chapter 16 Cell cycle assignment .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 16.1 Motivation On occasion, it can be desirable to determine cell cycle activity from scRNA-seq data. In and of itself, the distribution of cells across phases of the cell cycle is not usually informative, but we can use this to determine if there are differences in cell cycle progression between subpopulations or across treatment conditions. Many of the key events in the cell cycle (e.g., passage through checkpoints) are post-translational and thus not directly visible in transcriptomic data; nonetheless, there are enough changes in expression that can be exploited to determine cell cycle phase. We demonstrate using the 416B dataset, which is known to contain actively cycling cells after oncogene induction. View history ### loading ### library(scRNAseq) sce.416b &lt;- LunSpikeInData(which=&quot;416b&quot;) sce.416b$block &lt;- factor(sce.416b$block) ### gene-annotation ### library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] rowData(sce.416b)$ENSEMBL &lt;- rownames(sce.416b) rowData(sce.416b)$SYMBOL &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SYMBOL&quot;) rowData(sce.416b)$SEQNAME &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) library(scater) rownames(sce.416b) &lt;- uniquifyFeatureNames(rowData(sce.416b)$ENSEMBL, rowData(sce.416b)$SYMBOL) ### quality-control ### mito &lt;- which(rowData(sce.416b)$SEQNAME==&quot;MT&quot;) stats &lt;- perCellQCMetrics(sce.416b, subsets=list(Mt=mito)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;subsets_Mt_percent&quot;, &quot;altexps_ERCC_percent&quot;), nmads=3, batch=sce.416b$block) sce.416b &lt;- sce.416b[,!qc$discard] ### normalization ### library(scran) sce.416b &lt;- computeSumFactors(sce.416b) sce.416b &lt;- logNormCounts(sce.416b) ### variance-modelling ### dec.416b &lt;- modelGeneVarWithSpikes(sce.416b, &quot;ERCC&quot;, block=sce.416b$block) ### batch-correction ### library(limma) assay(sce.416b, &quot;corrected&quot;) &lt;- removeBatchEffect(logcounts(sce.416b), design=model.matrix(~sce.416b$phenotype), batch=sce.416b$block) ### dimensionality-reduction ### sce.416b &lt;- denoisePCA(sce.416b, technical=dec.416b, assay.type=&quot;corrected&quot;, BSPARAM=BiocSingular::ExactParam()) set.seed(1010) sce.416b &lt;- runTSNE(sce.416b, dimred=&quot;PCA&quot;, perplexity=10) ### clustering ### my.dist &lt;- dist(reducedDim(sce.416b, &quot;PCA&quot;)) my.tree &lt;- hclust(my.dist, method=&quot;ward.D2&quot;) library(dynamicTreeCut) my.clusters &lt;- unname(cutreeDynamic(my.tree, distM=as.matrix(my.dist), minClusterSize=10, verbose=0)) sce.416b$cluster &lt;- factor(my.clusters) sce.416b ## class: SingleCellExperiment ## dim: 46604 185 ## metadata(0): ## assays(3): counts logcounts corrected ## rownames(46604): 4933401J01Rik Gm26206 ... CAAA01147332.1 ## CBFB-MYH11-mcherry ## rowData names(4): Length ENSEMBL SYMBOL SEQNAME ## colnames(185): SLX-9555.N701_S502.C89V9ANXX.s_1.r_1 ## SLX-9555.N701_S503.C89V9ANXX.s_1.r_1 ... ## SLX-11312.N712_S507.H5H5YBBXX.s_8.r_1 ## SLX-11312.N712_S517.H5H5YBBXX.s_8.r_1 ## colData names(10): Source Name cell line ... block cluster ## reducedDimNames(2): PCA TSNE ## spikeNames(0): ## altExpNames(2): ERCC SIRV 16.2 Using the cyclins The cyclins control progression through the cell cycle and have well-characterized patterns of expression across cell cycle phases. Cyclin D is expressed throughout but peaks at G1; cyclin E is expressed highest in the G1/S transition; cyclin A is expressed across S and G2; and cyclin B is expressed highest in late G2 and mitosis. Inspection of the relative expression of cyclins across the population can often be sufficient to determine the relative cell cycle activity in each cluster (Figure 16.1). For example, cluster 1 is likely to be in G1 while the other clusters are scattered across the later phases. cyclin.genes &lt;- grep(&quot;^Ccn[abde][0-9]$&quot;, rowData(sce.416b)$SYMBOL) cyclin.genes &lt;- rownames(sce.416b)[cyclin.genes] cyclin.genes ## [1] &quot;Ccnb3&quot; &quot;Ccna2&quot; &quot;Ccna1&quot; &quot;Ccne2&quot; &quot;Ccnd2&quot; &quot;Ccne1&quot; &quot;Ccnd1&quot; &quot;Ccnb2&quot; ## [9] &quot;Ccnb1&quot; &quot;Ccnd3&quot; library(scater) plotHeatmap(sce.416b, colour_columns_by=&quot;cluster&quot;, cluster_cols=FALSE, columns=order(sce.416b$cluster), cluster_rows=FALSE, features=sort(cyclin.genes), show_colnames=FALSE) Figure 16.1: Heatmap of the log-normalized expression values of the cyclin genes in the 416B dataset. The 416B dataset is somewhat unusual as each cluster maps clealy onto a distinct phase of the cell cycle. Such separation is not typical in more heterogeneous datasets where the cell cycle is only a secondary factor of variation. However, it is not strictly necessary to know the exact phase of each cell or cluster to answer most cycle-related questions. For example, we can use standard DE methods (Chapter 29.2.8) to look for upregulation of each cyclin, allowing us to determine if there are more cells in the corresponding phase of the cell cycle between subpopulations. The same logic applies to comparisons between treatment conditions, as described in Chapter ??. library(scran) markers &lt;- findMarkers(sce.416b, subset.row=cyclin.genes, clusters=sce.416b$cluster, test.type=&quot;wilcox&quot;, direction=&quot;up&quot;) markers[[2]] ## DataFrame with 10 rows and 7 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## Ccnb1 1 2.37957533903471e-17 2.37957533903471e-16 ## Ccnb2 1 1.34341210453291e-12 4.47804034844303e-12 ## Ccnd2 1 0.0178162563867722 0.0356325127735445 ## Ccna2 2 7.90317047962163e-17 3.95158523981083e-16 ## Ccnd3 2 0.0381754305787045 0.0636257176311741 ## Ccnd1 3 0.0723589725759802 0.103369960822829 ## Ccna1 4 0.00143225677223033 0.00358064193057581 ## Ccne1 5 0.152911439222281 0.191139299027851 ## Ccne2 7 0.821459489933298 0.912732766592554 ## Ccnb3 10 1 1 ## AUC.1 AUC.3 AUC.4 ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Ccnb1 0.996180555555556 0.924479166666667 0.998842592592593 ## Ccnb2 0.918055555555556 0.936631944444444 0.796296296296296 ## Ccnd2 0.229861111111111 0.5859375 0.52662037037037 ## Ccna2 0.987847222222222 0.598958333333333 0.939814814814815 ## Ccnd3 0.561458333333333 0.495659722222222 0.472222222222222 ## Ccnd1 0.197569444444444 0.6484375 0.527777777777778 ## Ccna1 0.569444444444444 0.551649305555556 0.569444444444444 ## Ccne1 0.59375 0.161458333333333 0.482638888888889 ## Ccne2 0.540104166666667 0.207465277777778 0.357638888888889 ## Ccnb3 0.5 0.5 0.5 ## AUC.5 ## &lt;numeric&gt; ## Ccnb1 0.670940170940171 ## Ccnb2 0.354700854700855 ## Ccnd2 0.747863247863248 ## Ccna2 0.427350427350427 ## Ccnd3 0.722222222222222 ## Ccnd1 0.183760683760684 ## Ccna1 0.525641025641026 ## Ccne1 0.492521367521368 ## Ccne2 0.366452991452991 ## Ccnb3 0.5 Direct examination of cyclin expression is easily understood, interpreted and validated with other technologies. However, it is best suited for statements about relative cell cycle activity; for example, we would find it difficult to assign cell cycle phase in Figure 16.1 without the presence of clusters spanning all phases to provide benchmarks for “high” and “low” expression of each cyclin. We also assume that cyclin expression is not affected by biological processes other than the cell cycle, which may be a strong assumption in some cases, e.g., malignant cells. On a practical note, we rely on having good coverage of the cyclins (if they are present), which is not a problem for the whole-of-transcriptome methods described below. 16.3 Using reference profiles Cell cycle assignment can be considered a specialized case of cell annotation, which suggests that the strategies described in Chapter 12 can be applied here. For example, given a reference dataset containing mouse ESCs with known cell cycle phases (Buettner et al. 2015), we could use SingleR to determine the phase of each cell in a test dataset. # TODO: move to scRNAseq. library(BiocFileCache) bfc &lt;- BiocFileCache(ask=FALSE) zip.path &lt;- bfcrpath(bfc, file.path(&quot;https://www.ebi.ac.uk/arrayexpress&quot;, &quot;files/E-MTAB-2805/E-MTAB-2805.processed.1.zip&quot;)) exdir &lt;- tempdir() unzip(zip.path, exdir=exdir) g1 &lt;- read.delim(file.path(exdir, &quot;G1_singlecells_counts.txt&quot;), row.names=1) g1 &lt;- as.matrix(g1[,-(1:3)]) s &lt;- read.delim(file.path(exdir, &quot;S_singlecells_counts.txt&quot;), row.names=1) s &lt;- as.matrix(s[,-(1:3)]) g2m &lt;- read.delim(file.path(exdir, &quot;G2M_singlecells_counts.txt&quot;), row.names=1) g2m &lt;- as.matrix(g2m[,-(1:3)]) sce.ref &lt;- SingleCellExperiment(list(counts=cbind(g1, s, g2m))) sce.ref$phases &lt;- rep(c(&quot;G1&quot;, &quot;S&quot;, &quot;G2M&quot;), c(ncol(g1), ncol(s), ncol(g2m))) We identify phase-specific markers from the reference and use them to assign labels to the 416B data. Cluster 1 mostly consists of G1 cells while the other clusters are assigned to G2M, which is broadly consistent with our conclusions from the cyclin-based analysis. Unlike the cyclin-based analysis, this approach yields “absolute” assignments of cell cycle phase that do not need to be interpreted relative to other cells in the same dataset. This is often appealing to users but may not make much practical difference to the conclusions, as the phase assignment frequencies still need to be compared across clusters or conditions to be put into context. # Identifying markers between cell cycle phases. common &lt;- intersect(rownames(sce.ref), rowData(sce.416b)$ENSEMBL) sce.ref &lt;- logNormCounts(sce.ref) phase.stats &lt;- pairwiseWilcox(logcounts(sce.ref), sce.ref$phases, direction=&quot;up&quot;, subset.row=common) cycle.markers &lt;- getTopMarkers(phase.stats[[1]], phase.stats[[2]], n=20) # Switching row names back to Ensembl. library(SingleR) test.data &lt;- logcounts(sce.416b) rownames(test.data) &lt;- rowData(sce.416b)$ENSEMBL assignments &lt;- SingleR(test.data, ref=sce.ref, label=sce.ref$phases, genes=cycle.markers) table(assignments$labels, sce.416b$cluster) ## ## 1 2 3 4 5 ## G1 67 0 3 11 0 ## G2M 13 36 29 13 13 The key assumption here is that the cell cycle is orthogonal to cell type and other aspects of cell behavior. This justifies the use of a reference involving cell types that are quite different from the cells in the test dataset, provided that the cell cycle transcriptional program is conserved across datasets (Bertoli, Skotheim, and Bruin 2013; Conboy et al. 2007). However, it is not difficult to find routine violations of this assumption - for example, Dppa3 is detected as one of the top markers to distinguish between G1 from G2/M in the reference but has no detectable expression in the 416B dataset (Figure 16.2). gridExtra::grid.arrange( plotExpression(sce.ref, features=&quot;ENSMUSG00000080241&quot;, x=&quot;phases&quot;), plotExpression(sce.416b, features=&quot;Dppa3&quot;, x=&quot;cluster&quot;), ncol=2) Figure 16.2: Distribution of log-normalized expression values for Dppa3 in the reference dataset (left) and in the 416B dataset (right). Thus, a healthy dose of skepticism is required when interpreting these assignments. Our hope is that any systematic assignment error is consistent across clusters and conditions such that they cancel out in comparisons of phase frequencies, which is the more interesting analysis anyway. 16.4 Using the cyclone() classifier The prediction method described by Scialdone et al. (2015) is another approach for classifying cells into cell cycle phases. Using a reference dataset, we first compute the sign of the difference in expression between each pair of genes. Pairs with changes in the sign across cell cycle phases are chosen as markers. Cells in a test dataset can then be classified into the appropriate phase, based on whether the observed sign for each marker pair is consistent with one phase or another. This approach is implemented in the cyclone() function from the scran package, which also contains pre-trained set of marker pairs for mouse and human data. set.seed(100) library(scran) mm.pairs &lt;- readRDS(system.file(&quot;exdata&quot;, &quot;mouse_cycle_markers.rds&quot;, package=&quot;scran&quot;)) # Using Ensembl IDs to match up with the annotation in &#39;mm.pairs&#39;. assignments &lt;- cyclone(sce.416b, mm.pairs, gene.names=rowData(sce.416b)$ENSEMBL) The phase assignment result for each cell in the 416B dataset is shown in Figure 16.3. For each cell, a higher score for a phase corresponds to a higher probability that the cell is in that phase. We focus on the G1 and G2/M scores as these are the most informative for classification. plot(assignments$score$G1, assignments$score$G2M, xlab=&quot;G1 score&quot;, ylab=&quot;G2/M score&quot;, pch=16) Figure 16.3: Cell cycle phase scores from applying the pair-based classifier on the 416B dataset. Each point represents a cell, plotted according to its scores for G1 and G2/M phases. Cells are classified as being in G1 phase if the G1 score is above 0.5 and greater than the G2/M score; in G2/M phase if the G2/M score is above 0.5 and greater than the G1 score; and in S phase if neither score is above 0.5. Here, the majority of cells in cluster 1 are again classified as being in G1 phase. The main difference from the SingleR assignments is the distinction between G2/M and S phases, which is slightly more consistent with our cyclin-based results. (This is attributable to some additional manual curation, performed during the definition of marker pairs to focus on genes with known roles in cell cycle progression.) table(assignments$phases, sce.416b$cluster) ## ## 1 2 3 4 5 ## G1 75 0 8 19 0 ## G2M 2 36 12 0 12 ## S 3 0 12 5 1 The same considerations and caveats described for the previous SingleR-based cell approach are also applicable here. From a practical perspective, cyclone() takes longer but does not require an explicit reference as the marker pairs are already computed. 16.5 Regressing out cell cycle phase For some time, it was popular to regress out the cell cycle phase prior to downstream analyses. The aim was to remove uninteresting variation due to cell cycle, thus improving resolution of other biological processes of interest. We could implement this by performing cell cycle phase assignment as described above, treating each phase as a separate batch and applying any of the batch correction strategies described in Chapter 19.2.6. The most common approach is to use a linear model to simply regress out the phase effect, e.g., via removeBatchEffect(). That said, we do not consider adjusting for cell cycle to be a necessary step in routine scRNA-seq analyses. In most applications, the cell cycle is a minor factor of variation, secondary to differences between cell types. Any attempt at removal would also need to assume that the cell cycle effect is orthogonal to other biological processes. For example, regression would potentially remove interesting signal if cell cycle activity varied across clusters or conditions, with a prime example being the increased proliferation of activated T cells (Richard et al. 2018). We suggest only performing cell cycle adjustment on an as-needed basis in populations with clear cell cycle effects. Alternatively, users may consider excluding cell cycle-related genes (e.g., as defined in GO:0007049) from downstream analysis. This should remove most of the cell cycle effect without making strong assumptions about orthogonality. Of course, this will not remove the effect of the cell cycle in genes with no annotated role in the cell cycle, but in such cases, there is ambiguity over whether that effect is truly due to the cell cycle or from some other (interesting) biological process that happens to be correlated with the cell cycle. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] SingleR_0.99.12 BiocFileCache_1.9.1 [3] dbplyr_1.4.2 scran_1.13.25 [5] scater_1.13.20 ggplot2_3.2.1 [7] SingleCellExperiment_1.7.10 SummarizedExperiment_1.15.9 [9] DelayedArray_0.11.6 BiocParallel_1.19.2 [11] matrixStats_0.55.0 Biobase_2.45.1 [13] GenomicRanges_1.37.16 GenomeInfoDb_1.21.1 [15] IRanges_2.19.16 S4Vectors_0.23.23 [17] BiocGenerics_0.31.6 Cairo_1.5-10 [19] BiocStyle_2.13.2 OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] bitops_1.0-6 bit64_0.9-7 [3] RColorBrewer_1.1-2 httr_1.4.1 [5] tools_3.6.1 backports_1.1.4 [7] R6_2.4.0 irlba_2.3.3 [9] vipor_0.4.5 DBI_1.0.0 [11] lazyeval_0.2.2 colorspace_1.4-1 [13] withr_2.1.2 tidyselect_0.2.5 [15] gridExtra_2.3 curl_4.2 [17] bit_1.1-14 compiler_3.6.1 [19] BiocNeighbors_1.3.5 labeling_0.3 [21] bookdown_0.13 scales_1.0.0 [23] rappdirs_0.3.1 stringr_1.4.0 [25] digest_0.6.21 rmarkdown_1.15 [27] XVector_0.25.0 pkgconfig_2.0.3 [29] htmltools_0.3.6 limma_3.41.16 [31] highr_0.8 rlang_0.4.0 [33] RSQLite_2.1.2 shiny_1.3.2 [35] DelayedMatrixStats_1.7.2 dplyr_0.8.3 [37] RCurl_1.95-4.12 magrittr_1.5 [39] BiocSingular_1.1.7 GenomeInfoDbData_1.2.1 [41] Matrix_1.2-17 Rcpp_1.0.2 [43] ggbeeswarm_0.6.0 munsell_0.5.0 [45] viridis_0.5.1 stringi_1.4.3 [47] yaml_2.2.0 edgeR_3.27.13 [49] zlibbioc_1.31.0 AnnotationHub_2.17.9 [51] grid_3.6.1 blob_1.2.0 [53] promises_1.0.1 dqrng_0.2.1 [55] ExperimentHub_1.11.6 crayon_1.3.4 [57] lattice_0.20-38 cowplot_1.0.0 [59] locfit_1.5-9.1 zeallot_0.1.0 [61] knitr_1.25 pillar_1.4.2 [63] igraph_1.2.4.1 glue_1.3.1 [65] evaluate_0.14 BiocManager_1.30.4 [67] httpuv_1.5.2 vctrs_0.2.0 [69] gtable_0.3.0 purrr_0.3.2 [71] assertthat_0.2.1 xfun_0.9 [73] mime_0.7 rsvd_1.0.2 [75] xtable_1.8-4 later_0.8.0 [77] viridisLite_0.3.0 tibble_2.1.3 [79] pheatmap_1.0.12 AnnotationDbi_1.47.1 [81] beeswarm_0.2.3 memoise_1.1.0 [83] statmod_1.4.32 interactiveDisplayBase_1.23.0 Bibliography "],
["interactive-sharing.html", "Chapter 17 Interactive Interfaces and Sharing 17.1 Motivation 17.2 Quick start 17.3 Examples of usages for iSEE apps 17.4 Reproducibility 17.5 Additional resources Session Info", " Chapter 17 Interactive Interfaces and Sharing .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 17.1 Motivation Exploratory data analysis (EDA) and visualization are crucial for many aspects of data analysis, such as quality control, hypothesis generation, and contextual result interpretation. Modern high-throughput technologies have been used to generate biological datasets of increasing size and complexity, including single-cell genomics and multi-omics experiments. As a consequence, the need for flexible and interactive platforms to explore those data from various angles has contributed to the increasing popularity of interactive graphical user interfaces (GUI). In this chapter, we illustrate how the Bioconductor package iSEE can be used to perform some common exploratory tasks during single-cell analysis workflows. We note that these are examples only; in practice, EDA is often context-dependent and driven by distinct motivations and hypotheses for every new data set. To this end, iSEE provides a flexible framework immediately compatible with a wide range of genomics data modalities and offers tools for building custom interactive interfaces configured to draw special attention to key aspects of individual data sets. 17.2 Quick start In this chapter, we use the 10X PBMC dataset for demonstration purposes. View history ### loading ### library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) ### gene-annotation ### library(scater) rownames(sce.pbmc) &lt;- uniquifyFeatureNames( rowData(sce.pbmc)$ID, rowData(sce.pbmc)$Symbol) library(EnsDb.Hsapiens.v86) location &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce.pbmc)$ID, column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) ### cell-detection ### set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] ### quality-control ### stats &lt;- perCellQCMetrics(sce.pbmc, subsets=list(Mito=which(location==&quot;MT&quot;))) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) sce.pbmc &lt;- sce.pbmc[,!high.mito] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.pbmc) sce.pbmc &lt;- computeSumFactors(sce.pbmc, cluster=clusters) sce.pbmc &lt;- logNormCounts(sce.pbmc) ### variance-modelling ### set.seed(1001) dec.pbmc &lt;- modelGeneVarByPoisson(sce.pbmc) ### dimensionality-reduction ### set.seed(10000) sce.pbmc &lt;- denoisePCA(sce.pbmc, technical=dec.pbmc) set.seed(100000) sce.pbmc &lt;- runTSNE(sce.pbmc, use_dimred=&quot;PCA&quot;) set.seed(1000000) sce.pbmc &lt;- runUMAP(sce.pbmc, use_dimred=&quot;PCA&quot;) Then, we load the iSEE and shiny packages for use in the rest of this chapter. library(iSEE) library(shiny) An instance of an interactive iSEE application can be launched with any data set that is stored in an object of the SummarizedExperiment class (or any class that extends it; e.g., SingleCellExperiment, DESeqDataSet, MethylSet). In its simplest form, this is done simply by calling iSEE(sce) with the sce data object as the sole argument, as illustrated here with the sce.pbmc data set. iSEE(sce.pbmc) The default interface contains up to eight standard panels, each featuring a particular aspect of the data set. The names of standard panels are available in the panelTypes variable. The shorter panel codes are useful for the configuration of tours, described in the section Dissemination of analysis results. panelTypes ## redDimPlot colDataPlot ## &quot;Reduced dimension plot&quot; &quot;Column data plot&quot; ## featAssayPlot rowStatTable ## &quot;Feature assay plot&quot; &quot;Row statistics table&quot; ## rowDataPlot sampAssayPlot ## &quot;Row data plot&quot; &quot;Sample assay plot&quot; ## colStatTable customDataPlot ## &quot;Column statistics table&quot; &quot;Custom data plot&quot; ## customStatTable heatMapPlot ## &quot;Custom statistics table&quot; &quot;Heat map&quot; The layout of panels in the interface may be altered interactively: panels can be added, removed, resized or repositioned using the “Organize panels” menu in the top right corner of the interface. The initial layout in which an application is launched can also be altered programmatically (see section Examples of usages for iSEE apps). To familiarize themselves with the GUI, users can launch an interactive tour from the menu in the top right corner. In addition, custom tours can be written to substitute the default built-in tour. This feature is particularly useful to disseminate new data sets with accompanying bespoke explanations guiding users through the salient features of any given data set (see section Dissemination of analysis results). It is also possible to deploy “empty” instances of iSEE apps, where any SummarizedExperiment object stored in an RDS file may be uploaded to the running application. Once the file is uploaded, the application will import the sce object and initialize the GUI panels with the contents of the object for interactive exploration. This type of iSEE applications is launched without specifying the sce argument, as shown below. iSEE() 17.3 Examples of usages for iSEE apps In the following subsections, we demonstrate some examples of use cases that can be addressed with interactive iSEE applications to gain insights into a data set and inform decision-making for downstream analyses. In each case, we demonstrate how iSEE applications can be preconfigured to launch in a specific state and layout, to facilitate immediate exploration of key aspects of the data set, in a manner most directly relevant to each situation and objectives. We note that these are examples only; we encourage readers to consider them as templates for learning and developing applications adapted to their own specific needs and purposes. 17.3.1 Quality control Having previously computed quality control metrics (see section Quick start above), it is possible to launch an app instance that immediately displays a set of panels preconfigured to focus on selected quality control metrics. For example, a common view for initial inspection of single-cell RNA-sequencing data sets generated by microfluidics platforms plots the library size of each cell, in decreasing order. An elbow in this plot generally reveals the transition between good quality cells and low quality cells or empty droplets. Another common view is to overlay the library size (in log space) as a color gradient over the result of a dimensionality reduction method such as t-SNE, UMAP, or ivis (Van der Maaten and Hinton 2008; McInnes, Healy, and Melville 2018; Szubert et al. 2019). This view may reveal trajectories or clusters associated with library size. Depending on the experimental context, such observations may result from technical or biological phenomena. For instance, it may indicate that normalization was not completely effective at removing cell biases. Alternatively, it could also indicate the presence of multiple cell types or states that differ in total RNA content. In the example below, we demonstrate that an iSEE app can be preconfigured to immediately display the views described above. # Rank cells by decreasing library size colData(sce.pbmc)[[&quot;total_counts_rank&quot;]] &lt;- rank(colSums(counts(sce.pbmc))) # Configure a &quot;Column data plot&quot; panel colDataArgs &lt;- colDataPlotDefaults(sce.pbmc, 1) colDataArgs$YAxis &lt;- &quot;log10_total_counts&quot; colDataArgs$XAxis &lt;- &quot;Column data&quot; colDataArgs$XAxisColData &lt;- &quot;total_counts_rank&quot; colDataArgs$DataBoxOpen &lt;- TRUE # Configure a &quot;Reduced dimension plot &quot; panel redDimArgs &lt;- redDimPlotDefaults(sce.pbmc, 1) redDimArgs$Type &lt;- &quot;TSNE&quot; redDimArgs$ColorBy &lt;- &quot;Column data&quot; redDimArgs$ColorByColData &lt;- &quot;log10_total_counts&quot; redDimArgs$DataBoxOpen &lt;- TRUE redDimArgs$VisualBoxOpen &lt;- TRUE # Configure the set of panels initially visible initialPanels &lt;- DataFrame( Name = c(&quot;Column data plot 1&quot;, &quot;Reduced dimension plot 1&quot;), Width = c(6L, 6L) ) # Prepare the app app &lt;- iSEE(sce.pbmc, colDataArgs = colDataArgs, redDimArgs = redDimArgs, initialPanels = initialPanels) The preconfigured Shiny app can then be launched as show below. runApp(app) Note that preconfigured apps remain fully interactive, meaning that users can interactively control the settings and layout of the panels. For instance, users may select cells in one panel and choose to highlight the selected cells in the other using the “Selection parameters” collapsible box, in an effort to determine an adequate threshold on the library size to filter cells to retain for downstream analyses. Users may also change the information displayed in any panel. For instance, users may choose to color data points by percentage of UMI mapped to mitochondrial genes (“pct_counts_Mito”) in the “Reduced dimension plot 1”. Using the transfer of point selection between panels, users could select cells with small library sizes (in the “Column data plot 1” panel) and highlight them in the “Reduced dimension plot 1” panel, to investigate a possible relation between library size, clustering, and proportion of reads mapped to mitochondrial genes. 17.3.2 Annotation and identification of cell populations Recent efforts such as the Human Cell Atlas (HCA) and the NIH Human BioMolecular Atlas Program (HuBMAP) have initiated the creation of reference maps of cell types and states in the human body in health and disease. A direct challenge of such efforts lies in the curation and annotation of known and novel cell types in those data sets, and the subsequent transfer learning of those annotations to new data sets. This generally relies on unsupervised clustering of cells, followed by pairwise differential expression to identify gene markers for each cluster, and ultimately manual curation of gene signatures to assign a cell type identity - either known or novel - to each cluster. In this example, we show how iSEE can be used to interactively examine results from unsupervised clustering and pairwise differential expression to conveniently inspect and determine cell identities. In this first code chunk, we identify clusters of cells and their respective positive markers; that is, genes expressed at higher levels in the cluster of interest relative to other cells. The clusters are identified as densely connected subgraphs within a k-nearest-neighbors graph of cells based on their expression profiles. Positive markers are identified as genes with a significantly higher mean expression in each cluster using pairwise Welch t-tests. Finally, the log-transformed false discovery rate (FDR) of each marker for each cluster is stored in the rowData component of the sce object, which will then be accessible in the iSEE application. library(scran) # Compute cell clusters g &lt;- buildSNNGraph(sce.pbmc, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership sce.pbmc$cluster &lt;- factor(clust) # Identify positive markers for each cluster markers.pbmc.up &lt;- findMarkers( sce.pbmc, sce.pbmc$cluster, direction=&quot;up&quot;, log.p=TRUE, sorted=FALSE) # Collate the log-transformed FDR for each marker in a single table x &lt;- DataFrame( row.names = rownames(sce.pbmc), lapply(X = markers.pbmc.up, FUN = &quot;[[&quot;, i=&quot;log.FDR&quot;) ) colnames(x) &lt;- as.character(seq_len(ncol(x))) # Store the table of results as row metadata rowData(sce.pbmc)[[(paste0(&quot;log.FDR&quot;, &quot;.markers.up&quot;))]] &lt;- x The next code chunk preconfigures an app that shows: - A table of feature statistics (including the log-transformed FDR of cluster markers computed above), - A plot showing the distribution of expression values for a chosen gene in each cluster, - A plot showing the result of the UMAP dimensionality reduction method overlaid with the expression value of a chosen gene. Moreover, the code chunk below preconfigures the second and third panel to use the gene (i.e., row) selected in the first panel. This functionality is particularly convenient once the table is sorted by decreasing significance of the markers for a given cluster. For instance, once the application is launched, users can sort the table by ascending value of “log.FDR.markers.up:1” (where “:1” indicates cluster “1”). Then, users may select the first row in the “Row statistics table 1” and watch the second and third panel automatically regenerate to display the most significant marker gene on the y-axis (“Feature assay plot 1” panel), and as a color scale overlaid on the data points (“Reduced dimension plot 1” panel). # Configure a &quot;Row statistics table&quot; panel (NOTE: we leave all parameters to default) rowStatArgs &lt;- rowStatTableDefaults(sce.pbmc, 1) # Configure a &quot;Feature assay plot&quot; panel featAssayArgs &lt;- featAssayPlotDefaults(sce.pbmc, 1) featAssayArgs$YAxisRowTable &lt;- &quot;Row statistics table 1&quot; featAssayArgs$XAxis &lt;- &quot;Column data&quot; featAssayArgs$XAxisColData &lt;- &quot;cluster&quot; featAssayArgs$DataBoxOpen &lt;- TRUE # Configure a &quot;Reduced dimension plot&quot; panel redDimArgs &lt;- redDimPlotDefaults(sce.pbmc, 1) redDimArgs$Type &lt;- &quot;UMAP&quot; redDimArgs$ColorBy &lt;- &quot;Feature name&quot; redDimArgs$ColorByRowTable &lt;- &quot;Row statistics table 1&quot; redDimArgs$VisualBoxOpen &lt;- TRUE initialPanels &lt;- DataFrame( Name = c(&quot;Row statistics table 1&quot;, &quot;Feature assay plot 1&quot;, &quot;Reduced dimension plot 1&quot;), Width = c(4L, 4L, 4L) ) # Prepare the app app &lt;- iSEE(sce.pbmc, rowStatArgs = rowStatArgs, featAssayArgs = featAssayArgs, redDimArgs = redDimArgs, initialPanels = initialPanels) The preconfigured Shiny app can then be launched as show below. runApp(app) In addition to selecting the top genes by significance, it is also possible to search the table for arbitrary gene names and select any known marker gene. Practically, investigating the expression levels of known marker genes is a common approach to assigning cell type labels to inferred clusters. 17.3.3 Collaborative analysis Analysis and interpretation of complex data sets typically involves multiple analysts. Rather than sharing analysis results via multiple versions of static figures and reports, it is often helpful to share interactive plots, allowing the other involved parties to independently explore the data in further depth. With iSEE, this can be achieved at any time by clicking on the “Display panel settings” button under the “Diagnostics” tab in the top right corner, copying the displayed code into an R script, and sharing this chunk of code with collaborators. However, note that they will also need to have access to a copy of the original sce object used for the analysis. In that setup, executing the code in the script and launching iSEE with the following command will open an instance mimicking what was shown on the screen when the “Display panel settings” button was clicked. It is important to note that all iSEE applications remain interactive irrespective of their initial configuration; only the initial layout and state of the application is modified from the default setup. 17.3.4 Dissemination of analysis results Typically, results from single-cell data are disseminated as static figures in published papers and reports. However, those are unlikely to capture the full information content of a complex scRNA-seq data set, and do not allow further exploration by the reader. To complement this traditional mode of dissemination, it is becoming increasingly common to deploy web-based interactive data browsers, allowing interested readers to investigate their respective hypotheses using the published data. With iSEE, such interactive exploration is facilitated by small guided tours - step-by-step walkthroughs of the different panels with pointers to facilitate their interpretation, from the authors’ point of view. At any time, the viewer is still free to leave the interactive tour and explore the data from their own perspective. All that is needed to add a tour to an iSEE instance is a data frame with two columns named “element” and “intro”; the first column declares the UI element to highlight in each step of the tour, and the second one contains the text to display at that step. This data frame must then be provided to the iSEE() function via the tour argument. In the code chunk below, we demonstrate the implementation of a simple tour taking through the two panels that compose a GUI, and interactively train users to use the collapsible boxes. tour &lt;- data.frame( element = c( &quot;#Welcome&quot;, &quot;#redDimPlot1&quot;, &quot;#colDataPlot1&quot;, &quot;#colDataPlot1_DataBoxOpen&quot;, &quot;#Conclusion&quot;), intro = c( &quot;Welcome to this tour!&quot;, &quot;This is a &lt;i&gt;Reduced dimension plot.&lt;/i&gt;&quot;, &quot;And this is a &lt;i&gt;Column data plot.&lt;/i&gt;&quot;, &quot;&lt;b&gt;Action:&lt;/b&gt; Click on this collapsible box to open and close it.&quot;, &quot;Thank you for taking this tour!&quot;), stringsAsFactors = FALSE) initialPanels &lt;- DataFrame( Name = c(&quot;Reduced dimension plot 1&quot;, &quot;Column data plot 1&quot;), Width = c(6L, 6L) ) The preconfigured Shiny app can then be loaded with the tour and launched as show below. iSEE(sce.pbmc, initialPanels = initialPanels, tour = tour) Examples of advanced tours showcasing a selection of published data sets can be found at https://github.com/LTLA/iSEE2018. 17.4 Reproducibility Although this chapter focuses on interactive exploration of data, we note that it is important to retain reproducibility, and to have a record of how each figure was generated. With iSEE, this information is readily available via the “Export R code” button under the “Diagnostics” tab in the top-right corner of the GUI. At any time, copying the code displayed in the modal window and executing it in the R session from which the iSEE app was launched exactly reproduces all plots currently displayed in the GUI. 17.5 Additional resources For demontration and inspiration, we refer readers to the following examples of deployed applications: Use cases accompanying the published article: https://marionilab.cruk.cam.ac.uk/ (source code: https://github.com/LTLA/iSEE2018) Examples of iSEE in production: http://www.teichlab.org/singlecell-treg Other examples as source code: Gallery of examples notebooks to reproduce analyses on public data: https://github.com/federicomarini/iSEE_instances Gallery of example custom panels: https://github.com/kevinrue/iSEE_custom Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] scran_1.13.25 shiny_1.3.2 [3] iSEE_1.5.11 SingleCellExperiment_1.7.10 [5] SummarizedExperiment_1.15.9 DelayedArray_0.11.6 [7] BiocParallel_1.19.2 matrixStats_0.55.0 [9] Biobase_2.45.1 GenomicRanges_1.37.16 [11] GenomeInfoDb_1.21.1 IRanges_2.19.16 [13] S4Vectors_0.23.23 BiocGenerics_0.31.6 [15] Cairo_1.5-10 BiocStyle_2.13.2 [17] OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] nlme_3.1-141 bitops_1.0-6 [3] bit64_0.9-7 tools_3.6.1 [5] backports_1.1.4 irlba_2.3.3 [7] R6_2.4.0 DT_0.9 [9] vipor_0.4.5 DBI_1.0.0 [11] lazyeval_0.2.2 mgcv_1.8-29 [13] colorspace_1.4-1 gridExtra_2.3 [15] tidyselect_0.2.5 bit_1.1-14 [17] compiler_3.6.1 BiocNeighbors_1.3.5 [19] shinyjs_1.0 colourpicker_1.0 [21] bookdown_0.13 scales_1.0.0 [23] stringr_1.4.0 digest_0.6.21 [25] rmarkdown_1.15 rentrez_1.2.2 [27] XVector_0.25.0 scater_1.13.20 [29] pkgconfig_2.0.3 htmltools_0.3.6 [31] limma_3.41.16 htmlwidgets_1.3 [33] rlang_0.4.0 RSQLite_2.1.2 [35] DelayedMatrixStats_1.7.2 jsonlite_1.6 [37] dplyr_0.8.3 BiocSingular_1.1.7 [39] RCurl_1.95-4.12 magrittr_1.5 [41] GenomeInfoDbData_1.2.1 Matrix_1.2-17 [43] ggbeeswarm_0.6.0 Rcpp_1.0.2 [45] munsell_0.5.0 viridis_0.5.1 [47] edgeR_3.27.13 stringi_1.4.3 [49] yaml_2.2.0 rintrojs_0.2.2 [51] zlibbioc_1.31.0 plyr_1.8.4 [53] grid_3.6.1 blob_1.2.0 [55] dqrng_0.2.1 promises_1.0.1 [57] shinydashboard_0.7.1 crayon_1.3.4 [59] miniUI_0.1.1.1 lattice_0.20-38 [61] cowplot_1.0.0 splines_3.6.1 [63] locfit_1.5-9.1 zeallot_0.1.0 [65] knitr_1.25 pillar_1.4.2 [67] igraph_1.2.4.1 reshape2_1.4.3 [69] XML_3.98-1.20 glue_1.3.1 [71] evaluate_0.14 BiocManager_1.30.4 [73] vctrs_0.2.0 httpuv_1.5.2 [75] gtable_0.3.0 purrr_0.3.2 [77] assertthat_0.2.1 ggplot2_3.2.1 [79] xfun_0.9 rsvd_1.0.2 [81] mime_0.7 xtable_1.8-4 [83] later_0.8.0 viridisLite_0.3.0 [85] tibble_2.1.3 beeswarm_0.2.3 [87] AnnotationDbi_1.47.1 memoise_1.1.0 [89] statmod_1.4.32 shinyAce_0.4.1 Bibliography "],
["dealing-with-big-data.html", "Chapter 18 Dealing with big data 18.1 Motivation 18.2 Fast approximations 18.3 Parallelization 18.4 Out of memory representations Session Info", " Chapter 18 Dealing with big data .aaron-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .aaron-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 18.1 Motivation Advances in scRNA-seq technologies have increased the number of cells that can be assayed in routine experiments. Public databases such as GEO are continually expanding with more scRNA-seq studies, while large-scale projects such as the Human Cell Atlas are expected to generate data for billions of cells. For effective data analysis, the computational methods need to scale with the increasing size of scRNA-seq data sets. This section discusses how we can use various aspects of the Bioconductor ecosystem to tune our analysis pipelines for greater speed and efficiency. 18.2 Fast approximations 18.2.1 Nearest neighbor searching Identification of neighbouring cells in PC or expression space is a common procedure that is used in many functions, e.g., buildSNNGraph(), doubletCells(). The default is to favour accuracy over speed by using an exact nearest neighbour (NN) search, implemented with the \\(k\\)-means for \\(k\\)-nearest neighbours algorithm (Wang 2012). However, for large data sets, it may be preferable to use a faster approximate approach. The BiocNeighbors framework makes it easy to switch between search options by simply changing the BNPARAM= argument in compatible functions. To demonstrate, we will use the 10X PBMC data: View history ### loading ### library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) ### gene-annotation ### library(scater) rownames(sce.pbmc) &lt;- uniquifyFeatureNames( rowData(sce.pbmc)$ID, rowData(sce.pbmc)$Symbol) library(EnsDb.Hsapiens.v86) location &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce.pbmc)$ID, column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) ### cell-detection ### set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] ### quality-control ### stats &lt;- perCellQCMetrics(sce.pbmc, subsets=list(Mito=which(location==&quot;MT&quot;))) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) sce.pbmc &lt;- sce.pbmc[,!high.mito] ### normalization ### library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.pbmc) sce.pbmc &lt;- computeSumFactors(sce.pbmc, cluster=clusters) sce.pbmc &lt;- logNormCounts(sce.pbmc) ### variance-modelling ### set.seed(1001) dec.pbmc &lt;- modelGeneVarByPoisson(sce.pbmc) ### dimensionality-reduction ### set.seed(10000) sce.pbmc &lt;- denoisePCA(sce.pbmc, technical=dec.pbmc) set.seed(100000) sce.pbmc &lt;- runTSNE(sce.pbmc, use_dimred=&quot;PCA&quot;) set.seed(1000000) sce.pbmc &lt;- runUMAP(sce.pbmc, use_dimred=&quot;PCA&quot;) ### clustering ### g &lt;- buildSNNGraph(sce.pbmc, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership sce.pbmc$cluster &lt;- factor(clust) sce.pbmc ## class: SingleCellExperiment ## dim: 33694 3922 ## metadata(1): Samples ## assays(2): counts logcounts ## rownames(33694): RP11-34P13.3 FAM138A ... AC213203.1 FAM231B ## rowData names(2): ID Symbol ## colnames(3922): AAACCTGAGAAGGCCT-1 AAACCTGAGACAGACC-1 ... ## TTTGTCACAGGTCCAC-1 TTTGTCATCCCAAGAT-1 ## colData names(3): Sample Barcode cluster ## reducedDimNames(3): PCA TSNE UMAP ## spikeNames(0): ## altExpNames(0): We had previously clustered on a shared nearest neighbor graph generated with an exact neighbour search (Section 10.3). We repeat this below using an approximate search, implemented using the Annoy algorithm. This involves constructing a AnnoyParam object to specify the search algorithm and then passing it to the buildSNNGraph() function. The results from the exact and approximate searches are consistent with most clusters from the former re-appearing in the latter. This suggests that the inaccuracy from the approximation can be largely ignored. library(scran) library(BiocNeighbors) snn.gr &lt;- buildSNNGraph(sce.pbmc, BNPARAM=AnnoyParam(), use.dimred=&quot;PCA&quot;) clusters &lt;- igraph::cluster_walktrap(snn.gr) table(Exact=sce.pbmc$cluster, Approx=clusters$membership) ## Approx ## Exact 1 2 3 4 5 6 7 8 9 10 11 12 13 ## 1 783 0 0 1 0 0 0 0 1 0 0 0 0 ## 2 0 0 198 0 0 0 0 0 0 0 0 0 0 ## 3 5 49 0 0 0 0 0 0 0 0 2 0 0 ## 4 0 0 0 512 29 0 0 0 0 0 0 0 0 ## 5 0 0 0 5 511 0 0 1 0 12 0 0 0 ## 6 0 0 0 0 0 516 0 0 0 0 0 0 0 ## 7 0 0 0 0 0 0 128 0 0 0 0 0 0 ## 8 0 0 0 0 2 0 0 822 0 0 0 0 0 ## 9 0 0 0 0 0 0 0 0 45 0 0 0 0 ## 10 0 0 0 0 2 0 0 0 0 149 0 0 0 ## 11 0 0 0 0 0 0 0 0 0 0 92 0 0 ## 12 0 0 0 0 0 0 0 0 0 0 0 21 0 ## 13 0 0 0 0 0 0 0 0 0 0 0 0 36 Note that Annoy writes the NN index to disk prior to performing the search. Thus, it may not actually be faster than the default exact algorithm for small datasets, depending on whether the overhead of disk write is offset by the computational complexity of the search. It is also not difficult to find situations where the approximation deteriorates, especially at high dimensions, though this may not have an appreciable impact on the biological conclusions. set.seed(1000) y1 &lt;- matrix(rnorm(50000), nrow=1000) y2 &lt;- matrix(rnorm(50000), nrow=1000) Y &lt;- rbind(y1, y2) exact &lt;- findKNN(Y, k=20) approx &lt;- findKNN(Y, k=20, BNPARAM=AnnoyParam()) mean(exact$index!=approx$index) ## [1] 0.5619 18.2.2 Singular value decomposition The singular value decomposition (SVD) underlies the PCA used throughout our analyses, e.g., in denoisePCA(), fastMNN(), doubletCells(). (Briefly, the right singular vectors are the eigenvectors of the gene-gene covariance matrix, where each eigenvector represents the axis of maximum remaining variation in the PCA.) The default base::svd() function performs an exact SVD that is not performant for large datasets. Instead, we use fast approximate methods from the irlba and rsvd packages, conveniently wrapped into the BiocSingular package for ease of use and package development. Specifically, we can change the SVD algorithm used in any of these functions by simply specifying an alternative value for the BSPARAM= argument. library(scater) library(BiocSingular) # As the name suggests, it is random, so we need to set the seed. set.seed(101000) r.out &lt;- runPCA(sce.pbmc, ncomponents=20, BSPARAM=RandomParam()) str(reducedDim(r.out)) ## num [1:3922, 1:20] 15.29 13.36 -8.84 -7.83 6.36 ... ## - attr(*, &quot;dimnames&quot;)=List of 2 ## ..$ : chr [1:3922] &quot;AAACCTGAGAAGGCCT-1&quot; &quot;AAACCTGAGACAGACC-1&quot; &quot;AAACCTGAGGCATGGT-1&quot; &quot;AAACCTGCAAGGTTCT-1&quot; ... ## ..$ : chr [1:20] &quot;PC1&quot; &quot;PC2&quot; &quot;PC3&quot; &quot;PC4&quot; ... ## - attr(*, &quot;percentVar&quot;)= num [1:20] 20.27 10.04 5.34 2.19 1.41 ... set.seed(101001) i.out &lt;- runPCA(sce.pbmc, ncomponents=20, BSPARAM=IrlbaParam()) str(reducedDim(i.out)) ## num [1:3922, 1:20] 15.29 13.36 -8.84 -7.83 6.36 ... ## - attr(*, &quot;dimnames&quot;)=List of 2 ## ..$ : chr [1:3922] &quot;AAACCTGAGAAGGCCT-1&quot; &quot;AAACCTGAGACAGACC-1&quot; &quot;AAACCTGAGGCATGGT-1&quot; &quot;AAACCTGCAAGGTTCT-1&quot; ... ## ..$ : chr [1:20] &quot;PC1&quot; &quot;PC2&quot; &quot;PC3&quot; &quot;PC4&quot; ... ## - attr(*, &quot;percentVar&quot;)= num [1:20] 20.27 10.04 5.34 2.19 1.41 ... Both IRLBA and randomized SVD (RSVD) are much faster than the exact SVD with negligible loss of accuracy. This motivates their default use in many scran and scater functions, at the cost of requiring users to set the seed to guarantee reproducibility. IRLBA can occasionally fail to converge and require more iterations (passed via maxit= in IrlbaParam()), while RSVD involves an explicit trade-off between accuracy and speed based on its oversampling parameter (p=) and number of power iterations (q=). We tend to prefer IRLBA as its default behavior is more accurate, though RSVD is much faster for file-backed matrices (Section 19.2.6). 18.3 Parallelization Parallelization of calculations across genes or cells is an obvious strategy for speeding up scRNA-seq analysis workflows. The BiocParallel package provides a common interface for parallel computing throughout the Bioconductor ecosystem, manifesting as a BPPARAM= argument in compatible functions. We can pick from a diverse range of parallelization backends depending on the available hardware and operating system. For example, we might use forking across 2 cores to parallelize the variance calculations on a Unix system: dec.pbmc.mc &lt;- modelGeneVar(sce.pbmc, BPPARAM=MulticoreParam(2)) dec.pbmc.mc ## DataFrame with 33694 rows and 6 columns ## mean total ## &lt;numeric&gt; &lt;numeric&gt; ## RP11-34P13.3 0 0 ## FAM138A 0 0 ## OR4F5 0 0 ## RP11-34P13.7 0.00223806192235176 0.00234711395627082 ## RP11-34P13.8 0.000562049544395219 0.000628030706791975 ## ... ... ... ## AC233755.2 0 0 ## AC233755.1 0 0 ## AC240274.1 0.0101803017459632 0.0120232469216998 ## AC213203.1 0 0 ## FAM231B 0 0 ## tech bio p.value ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## RP11-34P13.3 0 0 NaN ## FAM138A 0 0 NaN ## OR4F5 0 0 NaN ## RP11-34P13.7 0.00230122682290578 4.58871333650392e-05 0.446738660345794 ## RP11-34P13.8 0.000577912671181739 5.01180356102363e-05 0.280158893973688 ## ... ... ... ... ## AC233755.2 0 0 NaN ## AC233755.1 0 0 NaN ## AC240274.1 0.0104674572643686 0.0015557896573312 0.159114062795961 ## AC213203.1 0 0 NaN ## FAM231B 0 0 NaN ## FDR ## &lt;numeric&gt; ## RP11-34P13.3 NaN ## FAM138A NaN ## OR4F5 NaN ## RP11-34P13.7 0.747547249944696 ## RP11-34P13.8 0.747547249944696 ## ... ... ## AC233755.2 NaN ## AC233755.1 NaN ## AC240274.1 0.747547249944696 ## AC213203.1 NaN ## FAM231B NaN Another approach would be to distribute jobs across a network of computers, which yields the same result: dec.pbmc.snow &lt;- modelGeneVar(sce.pbmc, BPPARAM=SnowParam(5)) dec.pbmc.snow ## DataFrame with 33694 rows and 6 columns ## mean total ## &lt;numeric&gt; &lt;numeric&gt; ## RP11-34P13.3 0 0 ## FAM138A 0 0 ## OR4F5 0 0 ## RP11-34P13.7 0.00223806192235176 0.00234711395627082 ## RP11-34P13.8 0.000562049544395219 0.000628030706791975 ## ... ... ... ## AC233755.2 0 0 ## AC233755.1 0 0 ## AC240274.1 0.0101803017459632 0.0120232469216998 ## AC213203.1 0 0 ## FAM231B 0 0 ## tech bio p.value ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## RP11-34P13.3 0 0 NaN ## FAM138A 0 0 NaN ## OR4F5 0 0 NaN ## RP11-34P13.7 0.00230122682290578 4.58871333650392e-05 0.446738660345794 ## RP11-34P13.8 0.000577912671181739 5.01180356102363e-05 0.280158893973688 ## ... ... ... ... ## AC233755.2 0 0 NaN ## AC233755.1 0 0 NaN ## AC240274.1 0.0104674572643686 0.0015557896573312 0.159114062795961 ## AC213203.1 0 0 NaN ## FAM231B 0 0 NaN ## FDR ## &lt;numeric&gt; ## RP11-34P13.3 NaN ## FAM138A NaN ## OR4F5 NaN ## RP11-34P13.7 0.747547249944696 ## RP11-34P13.8 0.747547249944696 ## ... ... ## AC233755.2 NaN ## AC233755.1 NaN ## AC240274.1 0.747547249944696 ## AC213203.1 NaN ## FAM231B NaN For high-performance computing (HPC) systems with a cluster of compute nodes, we can distribute jobs via the job scheduler using the BatchtoolsParam class. The example below assumes a SLURM cluster, though the settings can be easily configured for a particular system (see here for details). # 2 hours, 8 GB, 1 CPU per task, for 10 tasks. bpp &lt;- BatchtoolsParam(10, cluster=&quot;slurm&quot;, resources=list(walltime=7200, memory=8000, ncpus=1)) Parallelization is best suited for CPU-intensive calculations where the division of labor results in a concomitant reduction in compute time. It is not suited for tasks that are bounded by other compute resources, e.g., memory or file I/O (though the latter is less of an issue on HPC systems with parallel read/write). In particular, R itself is inherently single-core, so many of the parallelization backends involve (i) setting up one or more separate R sessions, (ii) loading the relevant packages and (iii) transmitting the data to that session. Depending on the nature and size of the task, this overhead may outweigh any benefit from parallel computing. 18.4 Out of memory representations The count matrix is the central structure around which our analyses are based. In most of the previous chapters, this has been held fully in memory as a dense matrix or as a sparse dgCMatrix. Howevever, in-memory representations may not be feasible for very large data sets, especially on machines with limited memory. For example, the 1.3 million brain cell data set from 10X Genomics (Zheng et al. 2017) would require over 100 GB of RAM to hold as a matrix and around 30 GB as a dgCMatrix. This makes it challenging to explore the data on anything less than a HPC system. The obvious solution is to use a file-backed matrix representation where the data are held on disk and subsets are retrieved into memory as requested. While a number of implementations of file-backed matrices are available (e.g., bigmemory, matter), we will be using the implementation from the HDF5Array package. This uses the popular HDF5 format as the underlying data store, which provides a measure of standardization and portability across systems. We demonstrate with a subset of 20,000 cells from the 1.3 million brain cell data set, as provided by the TENxBrainData package. library(TENxBrainData) sce.brain &lt;- TENxBrainData20k() sce.brain ## class: SingleCellExperiment ## dim: 27998 20000 ## metadata(0): ## assays(1): counts ## rownames: NULL ## rowData names(2): Ensembl Symbol ## colnames: NULL ## colData names(4): Barcode Sequence Library Mouse ## reducedDimNames(0): ## spikeNames(0): ## altExpNames(0): Examination of the SingleCellExperiment object indicates that the count matrix is a HDF5Matrix. From a comparison of the memory usage, it is clear that this matrix object is simply a stub that points to the much larger HDF5 file that actually contains the data. This avoids the need for large RAM availability during analyses. counts(sce.brain) ## &lt;27998 x 20000&gt; HDF5Matrix object of type &quot;integer&quot;: ## [,1] [,2] [,3] [,4] ... [,19997] [,19998] ## [1,] 0 0 0 0 . 0 0 ## [2,] 0 0 0 0 . 0 0 ## [3,] 0 0 0 0 . 0 0 ## [4,] 0 0 0 0 . 0 0 ## [5,] 0 0 0 0 . 0 0 ## ... . . . . . . . ## [27994,] 0 0 0 0 . 0 0 ## [27995,] 0 0 0 1 . 0 2 ## [27996,] 0 0 0 0 . 0 1 ## [27997,] 0 0 0 0 . 0 0 ## [27998,] 0 0 0 0 . 0 0 ## [,19999] [,20000] ## [1,] 0 0 ## [2,] 0 0 ## [3,] 0 0 ## [4,] 0 0 ## [5,] 0 0 ## ... . . ## [27994,] 0 0 ## [27995,] 0 0 ## [27996,] 0 0 ## [27997,] 0 0 ## [27998,] 0 0 object.size(counts(sce.brain)) ## 2160 bytes file.info(path(counts(sce.brain)))$size ## [1] 76264332 Manipulation of the count matrix will generally result in the creation of a DelayedArray object from the DelayedArray package. This remembers the operations to be applied to the counts and stores them in the object, to be executed when the modified matrix values are realized for use in calculations. The use of delayed operations avoids the need to write the modified values to a new file at every operation, which would unnecessarily require time-consuming disk I/O. tmp &lt;- counts(sce.brain) tmp &lt;- log2(tmp + 1) tmp ## &lt;27998 x 20000&gt; DelayedMatrix object of type &quot;double&quot;: ## [,1] [,2] [,3] ... [,19999] [,20000] ## [1,] 0 0 0 . 0 0 ## [2,] 0 0 0 . 0 0 ## [3,] 0 0 0 . 0 0 ## [4,] 0 0 0 . 0 0 ## [5,] 0 0 0 . 0 0 ## ... . . . . . . ## [27994,] 0 0 0 . 0 0 ## [27995,] 0 0 0 . 0 0 ## [27996,] 0 0 0 . 0 0 ## [27997,] 0 0 0 . 0 0 ## [27998,] 0 0 0 . 0 0 Many functions described in the previous workflows are capable of accepting HDF5Matrix objects. This is powered by the availability of common methods for all matrix representations (e.g., subsetting, combining, methods from DelayedMatrixStats) as well as representation-agnostic C++ code using beachmat (A. T. L. Lun, Pages, and Smith 2018). For example, we compute QC metrics below with the same calculateQCMetrics() function that we used in the other workflows. library(scater) is.mito &lt;- grepl(&quot;^mt-&quot;, rowData(sce.brain)$Symbol) qcstats &lt;- perCellQCMetrics(sce.brain, subsets=list(Mt=is.mito)) qcstats ## DataFrame with 20000 rows and 10 columns ## sum detected percent_top_50 percent_top_100 ## &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## 1 3060 1546 24.1830065359477 34.5751633986928 ## 2 3500 1694 22.7428571428571 33.2285714285714 ## 3 3092 1613 22.3479948253558 33.8292367399741 ## 4 4420 2050 24.7511312217195 33.7782805429864 ## 5 3771 1813 23.0442853354548 33.1742243436754 ## ... ... ... ... ... ## 19996 4431 2050 23.019634394042 32.7916948770029 ## 19997 6988 2704 18.6605609616485 28.5632512879222 ## 19998 8749 2988 23.9113041490456 33.6267001943079 ## 19999 3842 1711 24.7267048412285 36.8037480478917 ## 20000 1775 945 29.8591549295775 40.9014084507042 ## percent_top_200 percent_top_500 subsets_Mt_sum subsets_Mt_detected ## &lt;numeric&gt; &lt;numeric&gt; &lt;integer&gt; &lt;integer&gt; ## 1 46.5032679738562 65.8169934640523 123 10 ## 2 45.6571428571429 64.8285714285714 118 11 ## 3 45.7309184993532 64.0038809831824 58 9 ## 4 44.8190045248869 61.4705882352941 131 10 ## 5 45.0543622381331 63.1397507292495 100 8 ## ... ... ... ... ... ## 19996 44.5046264951478 60.9794628751975 127 9 ## 19997 40.5838580423583 58.2856325128792 60 9 ## 19998 44.4965138873014 60.9783975311464 305 11 ## 19999 48.750650702759 66.6840187402395 129 8 ## 20000 54.0845070422535 74.9295774647887 26 6 ## subsets_Mt_percent total ## &lt;numeric&gt; &lt;integer&gt; ## 1 4.01960784313725 3060 ## 2 3.37142857142857 3500 ## 3 1.875808538163 3092 ## 4 2.96380090497738 4420 ## 5 2.65181649429859 3771 ## ... ... ... ## 19996 2.86617016474836 4431 ## 19997 0.858614768174013 6988 ## 19998 3.48611269859413 8749 ## 19999 3.35762623633524 3842 ## 20000 1.46478873239437 1775 Needless to say, data access from file-backed representations is slower than that from in-memory representations. The time spent retrieving data from disk is an unavoidable cost of reducing memory usage. Whether this is tolerable depends on the application. One example usage pattern involves performing the heavy computing quickly with in-memory representations on HPC systems with plentiful memory, and then distributing file-backed counterparts to individual users for exploration and visualization on their personal machines. Session Info View session info R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 14.04.5 LTS Matrix products: default BLAS: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRblas.so LAPACK: /home/ramezqui/Rbuild/danbuild/R-3.6.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] parallel stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] TENxBrainData_1.5.0 HDF5Array_1.13.8 [3] rhdf5_2.29.3 BiocSingular_1.1.7 [5] scater_1.13.20 ggplot2_3.2.1 [7] BiocNeighbors_1.3.5 scran_1.13.25 [9] SingleCellExperiment_1.7.10 SummarizedExperiment_1.15.9 [11] DelayedArray_0.11.6 BiocParallel_1.19.2 [13] matrixStats_0.55.0 Biobase_2.45.1 [15] GenomicRanges_1.37.16 GenomeInfoDb_1.21.1 [17] IRanges_2.19.16 S4Vectors_0.23.23 [19] BiocGenerics_0.31.6 Cairo_1.5-10 [21] BiocStyle_2.13.2 OSCAUtils_0.0.1 loaded via a namespace (and not attached): [1] bitops_1.0-6 bit64_0.9-7 [3] httr_1.4.1 tools_3.6.1 [5] backports_1.1.4 R6_2.4.0 [7] irlba_2.3.3 vipor_0.4.5 [9] DBI_1.0.0 lazyeval_0.2.2 [11] colorspace_1.4-1 withr_2.1.2 [13] tidyselect_0.2.5 gridExtra_2.3 [15] curl_4.2 bit_1.1-14 [17] compiler_3.6.1 bookdown_0.13 [19] scales_1.0.0 rappdirs_0.3.1 [21] stringr_1.4.0 digest_0.6.21 [23] rmarkdown_1.15 XVector_0.25.0 [25] pkgconfig_2.0.3 htmltools_0.3.6 [27] dbplyr_1.4.2 limma_3.41.16 [29] rlang_0.4.0 RSQLite_2.1.2 [31] shiny_1.3.2 DelayedMatrixStats_1.7.2 [33] dplyr_0.8.3 RCurl_1.95-4.12 [35] magrittr_1.5 GenomeInfoDbData_1.2.1 [37] Matrix_1.2-17 Rcpp_1.0.2 [39] ggbeeswarm_0.6.0 munsell_0.5.0 [41] Rhdf5lib_1.7.5 viridis_0.5.1 [43] stringi_1.4.3 yaml_2.2.0 [45] edgeR_3.27.13 zlibbioc_1.31.0 [47] BiocFileCache_1.9.1 AnnotationHub_2.17.9 [49] grid_3.6.1 blob_1.2.0 [51] promises_1.0.1 dqrng_0.2.1 [53] ExperimentHub_1.11.6 crayon_1.3.4 [55] lattice_0.20-38 beachmat_2.1.2 [57] locfit_1.5-9.1 zeallot_0.1.0 [59] knitr_1.25 pillar_1.4.2 [61] igraph_1.2.4.1 glue_1.3.1 [63] evaluate_0.14 BiocManager_1.30.4 [65] httpuv_1.5.2 vctrs_0.2.0 [67] gtable_0.3.0 purrr_0.3.2 [69] assertthat_0.2.1 xfun_0.9 [71] mime_0.7 rsvd_1.0.2 [73] xtable_1.8-4 later_0.8.0 [75] viridisLite_0.3.0 tibble_2.1.3 [77] snow_0.4-3 AnnotationDbi_1.47.1 [79] beeswarm_0.2.3 memoise_1.1.0 [81] statmod_1.4.32 interactiveDisplayBase_1.23.0 Bibliography "],
["human-pancreas-dataset-grun.html", "Chapter 19 Human pancreas dataset (Grun) 19.1 Introduction 19.2 Analysis code 19.3 Results", " Chapter 19 Human pancreas dataset (Grun) 19.1 Introduction This performs an analysis of the Grun et al. (2016) CEL-seq2 dataset, consisting of human pancreas cells from various donors. 19.2 Analysis code 19.2.1 Data loading library(scRNAseq) sce.grun &lt;- GrunPancreasData() 19.2.2 Gene annotation We convert to Ensembl identifiers, and we remove duplicated genes or genes without Ensembl IDs. library(org.Hs.eg.db) gene.ids &lt;- mapIds(org.Hs.eg.db, keys=rowData(sce.grun)$symbol, keytype=&quot;SYMBOL&quot;, column=&quot;ENSEMBL&quot;) keep &lt;- !is.na(gene.ids) &amp; !duplicated(gene.ids) sce.grun &lt;- sce.grun[keep,] rownames(sce.grun) &lt;- gene.ids[keep] 19.2.3 Quality control This dataset lacks mitochondrial genes so we will do without. unfiltered &lt;- sce.grun library(scater) stats &lt;- perCellQCMetrics(sce.grun) qc &lt;- quickCellQC(stats, percent_subsets=&quot;altexps_ERCC_percent&quot;, nmads=3) sce.grun &lt;- sce.grun[,!qc$discard] 19.2.4 Normalization library(scran) set.seed(1000) # for irlba. clusters &lt;- quickCluster(sce.grun) sce.grun &lt;- computeSumFactors(sce.grun, min.mean=0.1, clusters=clusters) sce.grun &lt;- logNormCounts(sce.grun) 19.2.5 Variance modelling We block on a combined plate and donor factor. block &lt;- paste0(sce.grun$sample, &quot;_&quot;, sce.grun$donor) dec.grun &lt;- modelGeneVarWithSpikes(sce.grun, spikes=&quot;ERCC&quot;, block=block) 19.2.6 Data integration library(batchelor) set.seed(1001010) merged.grun &lt;- fastMNN(sce.grun, batch=sce.grun$donor) 19.2.7 Dimensionality reduction set.seed(100111) merged.grun &lt;- runTSNE(merged.grun, dimred=&quot;corrected&quot;) 19.2.8 Clustering snn.gr &lt;- buildSNNGraph(merged.grun, use.dimred=&quot;corrected&quot;) merged.grun$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) 19.3 Results 19.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- qc$discard gridExtra::grid.arrange( plotColData(unfiltered, x=&quot;donor&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, x=&quot;donor&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, x=&quot;donor&quot;, y=&quot;altexps_ERCC_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;ERCC percent&quot;), ncol=2 ) colSums(as.matrix(qc)) ## low_lib_size low_n_features ## 101 149 ## high_altexps_ERCC_percent discard ## NA 438 19.3.2 Normalization summary(sizeFactors(sce.grun)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.01 0.43 0.79 1.00 1.29 9.02 plot(librarySizeFactors(sce.grun), sizeFactors(sce.grun), pch=16, xlab=&quot;Library size factors&quot;, ylab=&quot;Deconvolution factors&quot;, log=&quot;xy&quot;) 19.3.3 Variance modelling par(mfrow=c(6,3)) blocked.stats &lt;- dec.grun$per.block for (i in colnames(blocked.stats)) { current &lt;- blocked.stats[[i]] plot(current$mean, current$total, main=i, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(current) points(curfit$mean, curfit$var, col=&quot;red&quot;, pch=16) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) } 19.3.4 Data integration metadata(merged.grun)$merge.info$lost.var ## D10 D17 D2 D3 D7 ## [1,] 0.05924 0.04442 0.00000 0.0000 0.0000 ## [2,] 0.00346 0.00611 0.02055 0.0000 0.0000 ## [3,] 0.01184 0.01218 0.00556 0.0582 0.0000 ## [4,] 0.00478 0.00774 0.00486 0.0103 0.0598 19.3.5 Clustering table(Cluster=merged.grun$cluster, Donor=merged.grun$batch) ## Donor ## Cluster D10 D17 D2 D3 D7 ## 1 33 73 34 121 28 ## 2 17 77 3 13 77 ## 3 14 130 0 12 61 ## 4 29 101 40 37 120 ## 5 22 33 9 22 14 ## 6 5 13 0 1 10 ## 7 4 14 0 3 1 ## 8 32 5 4 13 3 ## 9 6 17 0 7 32 plotTSNE(merged.grun, colour_by=&quot;cluster&quot;) plotTSNE(merged.grun, colour_by=&quot;batch&quot;) Bibliography "],
["b-smart-seq2-dataset.html", "Chapter 20 416B Smart-seq2 dataset 20.1 Introduction 20.2 Analysis code 20.3 Results", " Chapter 20 416B Smart-seq2 dataset 20.1 Introduction The A. T. L. Lun et al. (2017) dataset contains two 96-well plates of 416B cells (an immortalized mouse myeloid progenitor cell line), processed using the Smart-seq2 protocol (Picelli et al. 2014). A constant amount of spike-in RNA from the External RNA Controls Consortium (ERCC) was also added to each cell’s lysate prior to library preparation. High-throughput sequencing was performed and the expression of each gene was quantified by counting the total number of reads mapped to its exonic regions. Similarly, the quantity of each spike-in transcript was measured by counting the number of reads mapped to the spike-in reference sequences. 20.2 Analysis code 20.2.1 Data loading library(scRNAseq) sce.416b &lt;- LunSpikeInData(which=&quot;416b&quot;) sce.416b$block &lt;- factor(sce.416b$block) 20.2.2 Gene annotation Ensembl identifiers are stable but difficult to interpret compared to the gene symbols. Thus, we obtain the symbols corresponding to each row using the relevant annotation package. We also rename the rows of our SingleCellExperiment with the symbols, reverting to Ensembl identifiers for missing or duplicate symbols. library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] rowData(sce.416b)$ENSEMBL &lt;- rownames(sce.416b) rowData(sce.416b)$SYMBOL &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SYMBOL&quot;) rowData(sce.416b)$SEQNAME &lt;- mapIds(ens.mm.v97, keys=rownames(sce.416b), keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) library(scater) rownames(sce.416b) &lt;- uniquifyFeatureNames(rowData(sce.416b)$ENSEMBL, rowData(sce.416b)$SYMBOL) 20.2.3 Quality control We save an unfiltered copy of the SingleCellExperiment for later use. unfiltered &lt;- sce.416b Technically, we do not need to use the mitochondrial proportions as we already have the spike-in proportions (which serve a similar purpose) for this dataset. However, it probably doesn’t do any harm to include it anyway. mito &lt;- which(rowData(sce.416b)$SEQNAME==&quot;MT&quot;) stats &lt;- perCellQCMetrics(sce.416b, subsets=list(Mt=mito)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;subsets_Mt_percent&quot;, &quot;altexps_ERCC_percent&quot;), nmads=3, batch=sce.416b$block) sce.416b &lt;- sce.416b[,!qc$discard] 20.2.4 Normalization No pre-clustering is performed here, as the dataset is small and all cells are derived from the same cell line anyway. library(scran) sce.416b &lt;- computeSumFactors(sce.416b) sce.416b &lt;- logNormCounts(sce.416b) 20.2.5 Variance modelling We block on the plate of origin to minimize plate effects. dec.416b &lt;- modelGeneVarWithSpikes(sce.416b, &quot;ERCC&quot;, block=sce.416b$block) 20.2.6 Batch correction The composition of cells is expected to be the same across the two plates, hence the use of removeBatchEffect() rather than more complex methods. In fact, in situations where it is applicable, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector. library(limma) assay(sce.416b, &quot;corrected&quot;) &lt;- removeBatchEffect(logcounts(sce.416b), design=model.matrix(~sce.416b$phenotype), batch=sce.416b$block) 20.2.7 Dimensionality reduction denoisePCA() automatically does its own feature selection, so further subsetting is not strictly required unless we wanted to be more stringent. We use an exact SVD to avoid warnings from irlba about handling small datasets. sce.416b &lt;- denoisePCA(sce.416b, technical=dec.416b, assay.type=&quot;corrected&quot;, BSPARAM=BiocSingular::ExactParam()) set.seed(1010) sce.416b &lt;- runTSNE(sce.416b, dimred=&quot;PCA&quot;, perplexity=10) 20.2.8 Clustering my.dist &lt;- dist(reducedDim(sce.416b, &quot;PCA&quot;)) my.tree &lt;- hclust(my.dist, method=&quot;ward.D2&quot;) library(dynamicTreeCut) my.clusters &lt;- unname(cutreeDynamic(my.tree, distM=as.matrix(my.dist), minClusterSize=10, verbose=0)) sce.416b$cluster &lt;- factor(my.clusters) 20.3 Results 20.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$block &lt;- factor(unfiltered$block) unfiltered$discard &lt;- qc$discard gridExtra::grid.arrange( plotColData(unfiltered, x=&quot;block&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, x=&quot;block&quot;, y=&quot;subsets_Mt_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;Mito percent&quot;), plotColData(unfiltered, x=&quot;block&quot;, y=&quot;altexps_ERCC_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;ERCC percent&quot;), nrow=2, ncol=2 ) plotColData(unfiltered, x=&quot;sum&quot;, y=&quot;subsets_Mt_percent&quot;, colour_by=&quot;discard&quot;) + scale_x_log10() plotColData(unfiltered, x=&quot;altexps_ERCC_percent&quot;, y=&quot;subsets_Mt_percent&quot;, colour_by=&quot;discard&quot;) colSums(as.matrix(qc)) ## low_lib_size low_n_features ## 5 0 ## high_subsets_Mt_percent high_altexps_ERCC_percent ## 2 2 ## discard ## 7 20.3.2 Normalization summary(sizeFactors(sce.416b)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.35 0.71 0.92 1.00 1.15 3.60 We see that the induced cells have size factors that are systematically shifted from the uninduced cells, consistent with the presence of a composition bias. plot(librarySizeFactors(sce.416b), sizeFactors(sce.416b), pch=16, xlab=&quot;Library size factors&quot;, ylab=&quot;Deconvolution factors&quot;, col=c(&quot;black&quot;, &quot;red&quot;)[grepl(&quot;induced&quot;, sce.416b$phenotype)+1], log=&quot;xy&quot;) 20.3.3 Variance modelling par(mfrow=c(1,2)) blocked.stats &lt;- dec.416b$per.block for (i in colnames(blocked.stats)) { current &lt;- blocked.stats[[i]] plot(current$mean, current$total, main=i, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(current) points(curfit$mean, curfit$var, col=&quot;red&quot;, pch=16) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) } 20.3.4 Dimensionality reduction ncol(reducedDim(sce.416b, &quot;PCA&quot;)) ## [1] 27 20.3.5 Clustering We compare the clusters to the plate of origin. Each cluster is comprised of cells from both batches, indicating that the clustering is not driven by a batch effect. table(Cluster=sce.416b$cluster, Plate=sce.416b$block) ## Plate ## Cluster 20160113 20160325 ## 1 41 39 ## 2 19 17 ## 3 17 15 ## 4 11 13 ## 5 5 8 We compare the clusters to the oncogene induction status. We observe differences in in the composition of each cluster, consistent with a biological effect of oncogene induction. table(Cluster=sce.416b$cluster, Oncogene=sce.416b$phenotype) ## Oncogene ## Cluster induced CBFB-MYH11 oncogene expression wild type phenotype ## 1 80 0 ## 2 0 36 ## 3 0 32 ## 4 0 24 ## 5 13 0 plotTSNE(sce.416b, colour_by=&quot;cluster&quot;) Most cells have relatively small positive widths in the silhouette plot below, indicating that the separation between clusters is weak. This may be symptomatic of over-clustering where clusters that are clearly defined on oncogene induction status are further split into subsets that are less well separated. Nonetheless, we will proceed with the current clustering scheme as it provides reasonable partitions for further characterization of heterogeneity. library(cluster) clust.col &lt;- scater:::.get_palette(&quot;tableau10medium&quot;) # hidden scater colours sil &lt;- silhouette(my.clusters, dist = my.dist) sil.cols &lt;- clust.col[ifelse(sil[,3] &gt; 0, sil[,1], sil[,2])] sil.cols &lt;- sil.cols[order(-sil[,1], sil[,3])] plot(sil, main = paste(length(unique(my.clusters)), &quot;clusters&quot;), border=sil.cols, col=sil.cols, do.col.sort=FALSE) 20.3.6 Interpretation markers &lt;- findMarkers(sce.416b, my.clusters, block=sce.416b$block) marker.set &lt;- markers[[&quot;1&quot;]] head(marker.set, 10) ## DataFrame with 10 rows and 7 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## Aurkb 1 5.95332526213747e-73 2.77448770516654e-68 ## Tk1 1 2.34968141049837e-60 1.82507587424777e-56 ## Myh11 1 1.74075870733091e-49 6.24048606126538e-46 ## Cdca8 1 1.64319374171929e-46 4.50467065524031e-43 ## Pimreg 2 4.29719148373538e-65 1.00133155954001e-60 ## Rrm2 2 2.35706313002577e-55 1.3731071263965e-51 ## Cks1b 2 2.35198262477988e-39 2.88452100645372e-36 ## Pirb 2 7.97867684167661e-35 5.38896022506513e-32 ## Prc1 3 2.77571698479689e-62 4.31198381198247e-58 ## Top2a 3 6.37981250851822e-55 3.30360869052204e-51 ## logFC.2 logFC.3 logFC.4 ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Aurkb -7.38870232969503 -6.45246627887924 -1.94592909023535 ## Tk1 -4.80008673423898 -7.49682898861993 -3.32419418408724 ## Myh11 4.37171208286236 4.34848334450097 4.43794171786636 ## Cdca8 -6.88029151809243 -4.80356837704285 -2.27453901288709 ## Pimreg -7.31631659124917 -5.64211249589388 -0.898043903209096 ## Rrm2 -5.46946590602491 -7.73120719658484 -2.60268226552795 ## Cks1b -6.71963646641467 -5.85265581679635 -4.25406582958887 ## Pirb 5.1993790781606 5.32023696598345 5.85826261355943 ## Prc1 -7.02970492135388 -5.45842471653223 -0.397100497816819 ## Top2a -7.27863861505773 -7.07670103720884 -2.00748152103728 ## logFC.5 ## &lt;numeric&gt; ## Aurkb -6.91352870202181 ## Tk1 -4.63536765455945 ## Myh11 1.03450086628779 ## Cdca8 -7.1294117129039 ## Pimreg -7.02015527046628 ## Rrm2 -5.43021338684748 ## Cks1b -6.21893354494391 ## Pirb 0.0649700605553113 ## Prc1 -6.95949488593924 ## Top2a -7.43282374973199 We visualize the expression profiles of the top candidates in the heatmap below to verify that the DE signature is robust. Most of the top markers have strong and consistent up- or downregulation in cells of cluster 1 compared to some or all of the other clusters. A cursory examination of the heatmap indicates that cluster 1 contains oncogene-induced cells with strong downregulation of DNA replication and cell cycle genes. This is consistent with the potential induction of senescence as an anti-tumorigenic response (Wajapeyee et al. 2010). top.markers &lt;- rownames(marker.set)[marker.set$Top &lt;= 10] plotHeatmap(sce.416b, features=top.markers, columns=order(sce.416b$cluster), colour_columns_by=c(&quot;cluster&quot;, &quot;block&quot;, &quot;phenotype&quot;), cluster_cols=FALSE, center=TRUE, symmetric=TRUE, zlim=c(-5, 5)) Bibliography "],
["human-pancreas-dataset-segerstolpe.html", "Chapter 21 Human pancreas dataset (Segerstolpe) 21.1 Introduction 21.2 Analysis code 21.3 Results", " Chapter 21 Human pancreas dataset (Segerstolpe) 21.1 Introduction This performs an analysis of the (???) dataset, consisting of human pancreas cells from various donors. 21.2 Analysis code 21.2.1 Data loading library(scRNAseq) sce.seger &lt;- SegerstolpePancreasData() 21.2.2 Gene annotation library(AnnotationHub) edb &lt;- AnnotationHub()[[&quot;AH73881&quot;]] symbols &lt;- rowData(sce.seger)$symbol ens.id &lt;- mapIds(edb, keys=symbols, keytype=&quot;SYMBOL&quot;, column=&quot;GENEID&quot;) ens.id &lt;- ifelse(is.na(ens.id), symbols, ens.id) # Removing duplicated rows. keep &lt;- !duplicated(ens.id) sce.seger &lt;- sce.seger[keep,] rownames(sce.seger) &lt;- ens.id[keep] 21.2.3 Sample annotation We simplify the names of some of the relevant column metadata fields for ease of access. Some editing of the cell type labels is necessary for consistency with other data sets. emtab.meta &lt;- colData(sce.seger)[,c(&quot;cell type&quot;, &quot;individual&quot;, &quot;single cell well quality&quot;)] colnames(emtab.meta) &lt;- c(&quot;CellType&quot;, &quot;Donor&quot;, &quot;Quality&quot;) colData(sce.seger) &lt;- emtab.meta sce.seger$CellType &lt;- gsub(&quot; cell&quot;, &quot;&quot;, sce.seger$CellType) sce.seger$CellType &lt;- paste0( toupper(substr(sce.seger$CellType, 1, 1)), substring(sce.seger$CellType, 2)) 21.2.4 Quality control We remove low quality cells that were marked by the authors. We then perform additional quality control, as some of the remaining still have very low counts and numbers of detected features. unfiltered &lt;- sce.seger low.qual &lt;- sce.seger$Quality == &quot;low quality cell&quot; library(scater) stats &lt;- perCellQCMetrics(sce.seger) qc &lt;- quickCellQC(stats, nmads=3, percent_subsets=&quot;altexps_ERCC_percent&quot;) sce.seger &lt;- sce.seger[,!(qc$discard | low.qual)] 21.2.5 Normalization We don’t normalize the spike-ins as there are some cells with no spike-in counts. library(scran) clusters &lt;- quickCluster(sce.seger) sce.seger &lt;- computeSumFactors(sce.seger, clusters=clusters) sce.seger &lt;- logNormCounts(sce.seger, use_altexps=FALSE) 21.2.6 Variance modelling We do not use cells with no spike-ins for variance modelling. Donor AZ also has very low spike-in counts and is subsequently ignored. for.hvg &lt;- sce.seger[,librarySizeFactors(altExp(sce.seger)) &gt; 0 &amp; sce.seger$Donor!=&quot;AZ&quot;] dec.seger &lt;- modelGeneVarWithSpikes(for.hvg, &quot;ERCC&quot;, block=for.hvg$Donor) chosen.hvgs &lt;- head(order(dec.seger$bio, decreasing=TRUE), 2000) 21.2.7 Dimensionality reduction library(BiocSingular) set.seed(101011001) sce.seger &lt;- runPCA(sce.seger, subset_row=chosen.hvgs, ncomponents=25, BSPARAM=IrlbaParam()) sce.seger &lt;- runTSNE(sce.seger, dimred=&quot;PCA&quot;) 21.2.8 Clustering snn.gr &lt;- buildSNNGraph(sce.seger, use.dimred=&quot;PCA&quot;) sce.seger$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) 21.3 Results 21.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- qc$discard gridExtra::grid.arrange( plotColData(unfiltered, x=&quot;Donor&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, x=&quot;Donor&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, x=&quot;Donor&quot;, y=&quot;altexps_ERCC_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;ERCC percent&quot;), ncol=2 ) colSums(as.matrix(qc)) ## low_lib_size low_n_features ## 197 587 ## high_altexps_ERCC_percent discard ## 902 1028 21.3.2 Normalization summary(sizeFactors(sce.seger)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.01 0.39 0.71 1.00 1.32 11.24 plot(librarySizeFactors(sce.seger), sizeFactors(sce.seger), pch=16, xlab=&quot;Library size factors&quot;, ylab=&quot;Deconvolution factors&quot;, log=&quot;xy&quot;) 21.3.3 Variance modelling par(mfrow=c(3,3)) blocked.stats &lt;- dec.seger$per.block for (i in colnames(blocked.stats)) { current &lt;- blocked.stats[[i]] plot(current$mean, current$total, main=i, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(current) points(curfit$mean, curfit$var, col=&quot;red&quot;, pch=16) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) } 21.3.4 Dimensionality reduction ncol(reducedDim(sce.seger, &quot;PCA&quot;)) ## [1] 25 21.3.5 Clustering table(sce.seger$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## 124 125 104 361 330 137 300 181 68 49 94 39 14 79 42 26 34 17 ## 19 ## 45 plotTSNE(sce.seger, colour_by=&quot;cluster&quot;) plotTSNE(sce.seger, colour_by=&quot;Donor&quot;) "],
["mouse-brain-dataset.html", "Chapter 22 Mouse brain dataset 22.1 Introduction 22.2 Analysis 22.3 Results", " Chapter 22 Mouse brain dataset 22.1 Introduction Here, we examine a heterogeneous dataset from a study of cell types in the mouse brain (Zeisel et al. 2015). This contains approximately 3000 cells of varying types such as oligodendrocytes, microglia and neurons. Individual cells were isolated using the Fluidigm C1 microfluidics system (Pollen et al. 2014) and library preparation was performed on each cell using a UMI-based protocol. After sequencing, expression was quantified by counting the number of unique molecular identifiers (UMIs) mapped to each gene. 22.2 Analysis 22.2.1 Data loading We remove repeats and merge together redundant rows corresponding to alternative genomic locations for the same gene. Specifically, we sum the counts for all rows corresponding to a single gene for ease of interpretation, and create a new SingleCellExperiment with these aggregated counts. library(scRNAseq) sce.zeisel &lt;- ZeiselBrainData() sce.zeisel &lt;- sce.zeisel[rowData(sce.zeisel)$featureType!=&quot;repeat&quot;,] library(scater) sce.zeisel &lt;- aggregateAcrossFeatures(sce.zeisel, id=sub(&quot;_loc[0-9]+$&quot;, &quot;&quot;, rownames(sce.zeisel))) 22.2.2 Gene annotation library(org.Mm.eg.db) ensembl &lt;- mapIds(org.Mm.eg.db, keys=rownames(sce.zeisel), keytype=&quot;SYMBOL&quot;, column=&quot;ENSEMBL&quot;) rowData(sce.zeisel)$ENSEMBL &lt;- ensembl 22.2.3 Quality control unfiltered &lt;- sce.zeisel The original authors of the study have already removed low-quality cells prior to data publication. Nonetheless, we compute some quality control metrics to check whether the remaining cells are satisfactory. stats &lt;- perCellQCMetrics(sce.zeisel, subsets=list( Mt=rowData(sce.zeisel)$featureType==&quot;mito&quot;)) qc &lt;- quickCellQC(stats, percent_subsets=c(&quot;altexps_ERCC_percent&quot;, &quot;subsets_Mt_percent&quot;), nmads=3) sce.zeisel &lt;- sce.zeisel[,!qc$discard] 22.2.4 Normalization library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.zeisel) sce.zeisel &lt;- computeSumFactors(sce.zeisel, cluster=clusters) sce.zeisel &lt;- logNormCounts(sce.zeisel) 22.2.5 Variance modelling In theory, we should block on the plate of origin for each cell. However, only 20-40 cells are available on each plate, and the population is also highly heterogeneous. This means that we cannot assume that the distribution of sampled cell types on each plate is the same. Thus, to avoid regressing out potential biology, we will not block on any factors in this analysis. dec.zeisel &lt;- modelGeneVarWithSpikes(sce.zeisel, &quot;ERCC&quot;) 22.2.6 Dimensionality reduction Note that denoisePCA() automatically selects for genes with positive components, so explicit specification of subset.row= is not required. library(BiocSingular) set.seed(101011001) sce.zeisel &lt;- denoisePCA(sce.zeisel, technical=dec.zeisel, BSPARAM=IrlbaParam()) sce.zeisel &lt;- runTSNE(sce.zeisel, dimred=&quot;PCA&quot;) 22.2.7 Clustering snn.gr &lt;- buildSNNGraph(sce.zeisel, use.dimred=&quot;PCA&quot;) sce.zeisel$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) 22.3 Results 22.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- qc$discard gridExtra::grid.arrange( plotColData(unfiltered, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, y=&quot;altexps_ERCC_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;ERCC percent&quot;), plotColData(unfiltered, y=&quot;subsets_Mt_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;Mito percent&quot;), ncol=2 ) plotColData(unfiltered, x=&quot;sum&quot;, y=&quot;subsets_Mt_percent&quot;, colour_by=&quot;discard&quot;) + scale_x_log10() plotColData(unfiltered, x=&quot;altexps_ERCC_percent&quot;, y=&quot;subsets_Mt_percent&quot;, colour_by=&quot;discard&quot;) colSums(as.matrix(qc)) ## low_lib_size low_n_features ## 0 3 ## high_altexps_ERCC_percent high_subsets_Mt_percent ## 65 128 ## discard ## 189 22.3.2 Normalization summary(sizeFactors(sce.zeisel)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.13 0.48 0.82 1.00 1.32 4.81 plot(librarySizeFactors(sce.zeisel), sizeFactors(sce.zeisel), pch=16, xlab=&quot;Library size factors&quot;, ylab=&quot;Deconvolution factors&quot;, log=&quot;xy&quot;) 22.3.3 Variance modelling The technical and total variances are much smaller than those in the read-based datasets. This is due to the use of UMIs, which reduces the noise caused by variable PCR amplification. Furthermore, the spike-in trend is consistently lower than the variances of the endogenous genes. This reflects the heterogeneity in gene expression across cells of different types. plot(dec.zeisel$mean, dec.zeisel$total, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(dec.zeisel) points(curfit$mean, curfit$var, col=&quot;red&quot;, pch=16) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) 22.3.4 Dimensionality reduction ncol(reducedDim(sce.zeisel, &quot;PCA&quot;)) ## [1] 50 22.3.5 Clustering table(sce.zeisel$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## 72 534 167 195 206 101 197 593 129 203 85 14 200 42 53 25 plotTSNE(sce.zeisel, colour_by=&quot;cluster&quot;) 22.3.6 Interpretation We focus on upregulated marker genes as these can quickly provide positive identification of cell type in a heterogeneous population. We examine the table for cluster 4, in which log-fold changes are reported between cluster 4 and every other cluster. The same output is provided for each cluster in order to identify genes that discriminate between clusters. markers &lt;- findMarkers(sce.zeisel, sce.zeisel$cluster, direction=&quot;up&quot;) marker.set &lt;- markers[[&quot;4&quot;]] head(marker.set[,1:8], 10) # only first 8 columns, for brevity ## DataFrame with 10 rows and 8 columns ## Top p.value FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## Snap25 1 1.89250170367202e-271 3.75453412991493e-267 ## Mllt11 1 1.51143016587263e-198 5.9970526121495e-195 ## Gad1 1 7.61960907109413e-179 1.88956780451795e-175 ## Atp1a3 1 1.92427110285748e-168 2.54504096063934e-165 ## Celf4 1 8.34102774997996e-168 1.03423530957407e-164 ## Ndn 1 4.54700749300098e-144 3.75867006890193e-141 ## Vstm2a 1 9.51443787058121e-109 3.49549875767522e-106 ## Synpr 1 5.23099454814645e-72 6.25166872534203e-70 ## Slc32a1 1 2.59209368203047e-66 2.49633721154384e-64 ## Ndrg4 2 5.79430202499945e-236 5.74765789369854e-232 ## logFC.1 logFC.2 logFC.3 ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Snap25 3.88670036821469 4.30914890423118 3.79720866242651 ## Mllt11 3.16869973795579 3.00773025022756 3.10246654261723 ## Gad1 4.1809765772547 4.18474848049613 4.12829492170707 ## Atp1a3 3.26120492686749 3.56940415755333 3.29072198770609 ## Celf4 2.76807817623127 3.24872640870414 2.79332190468448 ## Ndn 3.04681475193341 2.61981616252683 2.79263185434029 ## Vstm2a 3.0289770812524 3.02829841624827 3.03503666373167 ## Synpr 3.20968070920293 3.00164389973715 3.32375802516086 ## Slc32a1 1.83319809501735 1.82038329280149 1.83319809501735 ## Ndrg4 3.8196774532832 4.03898665167331 3.74014483126438 ## logFC.5 logFC.6 ## &lt;numeric&gt; &lt;numeric&gt; ## Snap25 1.07670109293827 1.36615019990328 ## Mllt11 1.56572545246833 1.60598297934231 ## Gad1 3.74078692648299 4.03200792797037 ## Atp1a3 1.56550859133349 0.0980072282917517 ## Celf4 0.979799545755635 0.582277979848379 ## Ndn 1.74510569393716 1.20437448171661 ## Vstm2a 2.60017354688132 2.77643808672538 ## Synpr 2.70722616294867 3.17927305686069 ## Slc32a1 1.66697721376767 1.70366704904145 ## Ndrg4 1.63090136754525 1.0479643935403 The heatmap below indicates that most of the top markers are strongly DE in cells of cluster 4 compared to some or all of the other clusters. We can use these markers to identify cells from cluster 4 in validation studies with an independent population of cells. A quick look at the markers suggest that cluster 4 represents interneurons based on expression of Gad1 and Slc6a1 (Zeng et al. 2012), differing from closely related cells in cluster 11 by virtue of high Synpr expression. top.markers &lt;- rownames(marker.set)[marker.set$Top &lt;= 10] plotHeatmap(sce.zeisel, features=top.markers, columns=order(sce.zeisel$cluster), colour_columns_by=&quot;cluster&quot;, cluster_cols=FALSE, center=TRUE, symmetric=TRUE, zlim=c(-5, 5)) An alternative visualization approach is to plot the log-fold changes to all other clusters directly. This is more concise and is useful in situations involving many clusters that contain different numbers of cells. logFCs &lt;- as.matrix(marker.set[1:50,-(1:3)]) colnames(logFCs) &lt;- sub(&quot;logFC.&quot;, &quot;&quot;, colnames(logFCs)) library(pheatmap) max.lfc &lt;- max(abs(range(logFCs))) pheatmap(logFCs, breaks=seq(-5, 5, length.out=101)) Bibliography "],
["human-pancreas-dataset-lawlor.html", "Chapter 23 Human pancreas dataset (Lawlor) 23.1 Introduction 23.2 Analysis code 23.3 Results", " Chapter 23 Human pancreas dataset (Lawlor) 23.1 Introduction This performs an analysis of the Lawlor et al. (2017) dataset, consisting of human pancreas cells from various donors. 23.2 Analysis code 23.2.1 Data loading library(scRNAseq) sce.lawlor &lt;- LawlorPancreasData() 23.2.2 Gene annotation library(AnnotationHub) edb &lt;- AnnotationHub()[[&quot;AH73881&quot;]] anno &lt;- select(edb, keys=rownames(sce.lawlor), keytype=&quot;GENEID&quot;, columns=c(&quot;SYMBOL&quot;, &quot;SEQNAME&quot;)) rowData(sce.lawlor) &lt;- anno[match(rownames(sce.lawlor), anno[,1]),-1] 23.2.3 Quality control unfiltered &lt;- sce.lawlor library(scater) stats &lt;- perCellQCMetrics(sce.lawlor, subsets=list(Mito=which(rowData(sce.lawlor)$SEQNAME==&quot;MT&quot;))) qc &lt;- quickCellQC(stats, percent_subsets=&quot;subsets_Mito_percent&quot;, nmads=3) sce.lawlor &lt;- sce.lawlor[,!qc$discard] 23.2.4 Normalization library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.lawlor) sce.lawlor &lt;- computeSumFactors(sce.lawlor, clusters=clusters) sce.lawlor &lt;- logNormCounts(sce.lawlor) 23.2.5 Variance modelling Using age as a proxy for the donor. dec.lawlor &lt;- modelGeneVar(sce.lawlor, block=sce.lawlor$age) chosen.genes &lt;- head(order(dec.lawlor$bio, decreasing=TRUE), 2000) 23.2.6 Dimensionality reduction library(BiocSingular) set.seed(101011001) sce.lawlor &lt;- runPCA(sce.lawlor, subset_row=chosen.genes, ncomponents=25, BSPARAM=IrlbaParam()) sce.lawlor &lt;- runTSNE(sce.lawlor, dimred=&quot;PCA&quot;) 23.2.7 Clustering snn.gr &lt;- buildSNNGraph(sce.lawlor, use.dimred=&quot;PCA&quot;) sce.lawlor$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) 23.3 Results 23.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- qc$discard gridExtra::grid.arrange( plotColData(unfiltered, x=&quot;age&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, x=&quot;age&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, x=&quot;age&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;Mito percent&quot;), ncol=2 ) plotColData(unfiltered, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + scale_x_log10() colSums(as.matrix(qc)) ## low_lib_size low_n_features ## 3 0 ## high_subsets_Mito_percent discard ## 20 23 23.3.2 Normalization summary(sizeFactors(sce.lawlor)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.283 0.767 0.963 1.000 1.192 2.405 plot(librarySizeFactors(sce.lawlor), sizeFactors(sce.lawlor), pch=16, xlab=&quot;Library size factors&quot;, ylab=&quot;Deconvolution factors&quot;, log=&quot;xy&quot;) 23.3.3 Variance modelling par(mfrow=c(4,2)) blocked.stats &lt;- dec.lawlor$per.block for (i in colnames(blocked.stats)) { current &lt;- blocked.stats[[i]] plot(current$mean, current$total, main=i, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(current) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) } 23.3.4 Clustering table(sce.lawlor$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 ## 25 27 86 140 96 22 172 18 17 12 plotTSNE(sce.lawlor, colour_by=&quot;cluster&quot;) Bibliography "],
["human-pancreas-dataset-muraro.html", "Chapter 24 Human pancreas dataset (Muraro) 24.1 Introduction 24.2 Analysis code 24.3 Results", " Chapter 24 Human pancreas dataset (Muraro) 24.1 Introduction This performs an analysis of the Muraro et al. (2016) CEL-seq dataset, consisting of human pancreas cells from various donors. 24.2 Analysis code 24.2.1 Data loading library(scRNAseq) sce.muraro &lt;- MuraroPancreasData() 24.2.2 Gene annotation Converting back to Ensembl identifiers. library(AnnotationHub) edb &lt;- AnnotationHub()[[&quot;AH73881&quot;]] gene.symb &lt;- sub(&quot;__chr.*$&quot;, &quot;&quot;, rownames(sce.muraro)) gene.ids &lt;- mapIds(edb, keys=gene.symb, keytype=&quot;SYMBOL&quot;, column=&quot;GENEID&quot;) # Removing duplicated genes or genes without Ensembl IDs. keep &lt;- !is.na(gene.ids) &amp; !duplicated(gene.ids) sce.muraro &lt;- sce.muraro[keep,] rownames(sce.muraro) &lt;- gene.ids[keep] 24.2.3 Quality control This dataset lacks mitochondrial genes so we will do without. unfiltered &lt;- sce.muraro library(scater) stats &lt;- perCellQCMetrics(sce.muraro) qc &lt;- quickCellQC(stats, nmads=3, percent_subsets=&quot;altexps_ERCC_percent&quot;) sce.muraro &lt;- sce.muraro[,!qc$discard] 24.2.4 Normalization library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.muraro) sce.muraro &lt;- computeSumFactors(sce.muraro, min.mean=0.1, clusters=clusters) sce.muraro &lt;- logNormCounts(sce.muraro) 24.2.5 Variance modelling We block on a combined plate and donor factor. block &lt;- paste0(sce.muraro$plate, &quot;_&quot;, sce.muraro$donor) dec.muraro &lt;- modelGeneVarWithSpikes(sce.muraro, &quot;ERCC&quot;, block=block) 24.2.6 Data integration library(batchelor) set.seed(1001010) merged.muraro &lt;- fastMNN(sce.muraro, batch=sce.muraro$donor) 24.2.7 Dimensionality reduction set.seed(100111) merged.muraro &lt;- runTSNE(merged.muraro, dimred=&quot;corrected&quot;) 24.2.8 Clustering snn.gr &lt;- buildSNNGraph(merged.muraro, use.dimred=&quot;corrected&quot;) merged.muraro$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) 24.3 Results 24.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- qc$discard gridExtra::grid.arrange( plotColData(unfiltered, x=&quot;donor&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, x=&quot;donor&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, x=&quot;donor&quot;, y=&quot;altexps_ERCC_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;ERCC percent&quot;), ncol=2 ) colSums(as.matrix(qc)) ## low_lib_size low_n_features ## 611 669 ## high_altexps_ERCC_percent discard ## 696 726 24.3.2 Normalization summary(sizeFactors(sce.muraro)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.08 0.54 0.82 1.00 1.22 14.13 plot(librarySizeFactors(sce.muraro), sizeFactors(sce.muraro), pch=16, xlab=&quot;Library size factors&quot;, ylab=&quot;Deconvolution factors&quot;, log=&quot;xy&quot;) 24.3.3 Variance modelling par(mfrow=c(8,4)) blocked.stats &lt;- dec.muraro$per.block for (i in colnames(blocked.stats)) { current &lt;- blocked.stats[[i]] plot(current$mean, current$total, main=i, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(current) points(curfit$mean, curfit$var, col=&quot;red&quot;, pch=16) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) } 24.3.4 Data integration metadata(merged.muraro)$merge.info$lost.var ## D28 D29 D30 D31 ## [1,] 0.02794 0.02225 0.00000 0.0000 ## [2,] 0.00176 0.00271 0.03799 0.0000 ## [3,] 0.00203 0.00236 0.00201 0.0496 24.3.5 Clustering table(Cluster=merged.muraro$cluster, Donor=merged.muraro$batch) ## Donor ## Cluster D28 D29 D30 D31 ## 1 103 6 57 113 ## 2 30 155 139 163 ## 3 61 20 79 95 ## 4 88 265 280 220 ## 5 13 74 63 43 ## 6 7 6 6 5 ## 7 22 7 54 26 ## 8 11 69 6 39 ## 9 5 2 5 9 plotTSNE(merged.muraro, colour_by=&quot;cluster&quot;) plotTSNE(merged.muraro, colour_by=&quot;batch&quot;) 24.3.6 Clustering Bibliography "],
["pbmc-10x-dataset-unfiltered.html", "Chapter 25 PBMC 10X dataset (unfiltered) 25.1 Introduction 25.2 Analysis code 25.3 Results", " Chapter 25 PBMC 10X dataset (unfiltered) 25.1 Introduction Here, we describe a brief analysis of the peripheral blood mononuclear cell (PBMC) dataset from 10X Genomics (Zheng et al. 2017). The data are publicly available from the 10X Genomics website, from which we download the raw gene/barcode count matrices, i.e., before cell calling from the CellRanger pipeline. 25.2 Analysis code 25.2.1 Data loading library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) raw.path &lt;- bfcrpath(bfc, file.path(&quot;http://cf.10xgenomics.com/samples&quot;, &quot;cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz&quot;)) untar(raw.path, exdir=file.path(tempdir(), &quot;pbmc4k&quot;)) library(DropletUtils) fname &lt;- file.path(tempdir(), &quot;pbmc4k/raw_gene_bc_matrices/GRCh38&quot;) sce.pbmc &lt;- read10xCounts(fname, col.names=TRUE) 25.2.2 Gene annotation library(scater) rownames(sce.pbmc) &lt;- uniquifyFeatureNames( rowData(sce.pbmc)$ID, rowData(sce.pbmc)$Symbol) library(EnsDb.Hsapiens.v86) location &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce.pbmc)$ID, column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) 25.2.3 Cell detection set.seed(100) e.out &lt;- emptyDrops(counts(sce.pbmc)) sce.pbmc &lt;- sce.pbmc[,which(e.out$FDR &lt;= 0.001)] 25.2.4 Quality control unfiltered &lt;- sce.pbmc We use a relaxed QC strategy and only remove cells with large mitochondrial proportions, using it as a proxy for cell damage. This reduces the risk of removing cell types with low RNA content, especially in a heterogeneous PBMC population with many different cell types. stats &lt;- perCellQCMetrics(sce.pbmc, subsets=list(Mito=which(location==&quot;MT&quot;))) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) sce.pbmc &lt;- sce.pbmc[,!high.mito] 25.2.5 Normalization library(scran) set.seed(1000) clusters &lt;- quickCluster(sce.pbmc) sce.pbmc &lt;- computeSumFactors(sce.pbmc, cluster=clusters) sce.pbmc &lt;- logNormCounts(sce.pbmc) 25.2.6 Variance modelling set.seed(1001) dec.pbmc &lt;- modelGeneVarByPoisson(sce.pbmc) 25.2.7 Dimensionality reduction set.seed(10000) sce.pbmc &lt;- denoisePCA(sce.pbmc, technical=dec.pbmc) set.seed(100000) sce.pbmc &lt;- runTSNE(sce.pbmc, use_dimred=&quot;PCA&quot;) set.seed(1000000) sce.pbmc &lt;- runUMAP(sce.pbmc, use_dimred=&quot;PCA&quot;) 25.2.8 Clustering g &lt;- buildSNNGraph(sce.pbmc, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership sce.pbmc$cluster &lt;- factor(clust) 25.3 Results 25.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- high.mito gridExtra::grid.arrange( plotColData(unfiltered, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;Mito percent&quot;), ncol=2 ) plotColData(unfiltered, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + scale_x_log10() summary(high.mito) ## Mode FALSE TRUE ## logical 3922 311 25.3.2 Normalization summary(sizeFactors(sce.pbmc)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.01 0.71 0.87 1.00 1.09 13.96 plot(librarySizeFactors(sce.pbmc), sizeFactors(sce.pbmc), pch=16, xlab=&quot;Library size factors&quot;, ylab=&quot;Deconvolution factors&quot;, log=&quot;xy&quot;) 25.3.3 Variance modelling plot(dec.pbmc$mean, dec.pbmc$total, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(dec.pbmc) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) 25.3.4 Dimensionality reduction ncol(reducedDim(sce.pbmc, &quot;PCA&quot;)) ## [1] 14 25.3.5 Clustering table(sce.pbmc$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 13 ## 785 198 56 541 529 516 128 824 45 151 92 21 36 plotTSNE(sce.pbmc, colour_by=&quot;cluster&quot;) 25.3.6 Interpretation markers &lt;- findMarkers(sce.pbmc, clusters=sce.pbmc$cluster, pval.type=&quot;some&quot;, direction=&quot;up&quot;) We examine the markers for cluster 1 in more detail. High expression of CD14, CD68 and MNDA combined with low expression of CD16 suggests that this cluster contains monocytes, compared to macrophages in cluster 11. marker.set &lt;- markers[[&quot;1&quot;]] as.data.frame(marker.set[1:20,1:2]) ## p.value FDR ## CSTA 1.14e-288 3.86e-284 ## VCAN 1.34e-242 2.25e-238 ## FGL2 1.57e-224 1.76e-220 ## S100A12 3.72e-221 3.13e-217 ## FCN1 1.86e-217 1.26e-213 ## LGALS2 4.86e-210 2.73e-206 ## MS4A6A 7.35e-204 3.54e-200 ## CD14 1.09e-173 4.59e-170 ## TYMP 6.65e-173 2.49e-169 ## CLEC7A 8.62e-164 2.90e-160 ## MNDA 8.15e-160 2.50e-156 ## CD68 1.08e-152 3.04e-149 ## CFD 1.28e-150 3.31e-147 ## CFP 1.65e-141 3.96e-138 ## NAMPT 2.10e-140 4.71e-137 ## AIF1 1.20e-135 2.53e-132 ## KLF4 3.86e-134 7.65e-131 ## IFI30 4.16e-131 7.78e-128 ## TNFSF13B 5.09e-130 9.02e-127 ## LGALS3 6.78e-130 1.14e-126 plotExpression(sce.pbmc, features=c(&quot;CD14&quot;, &quot;CD68&quot;, &quot;MNDA&quot;, &quot;FCGR3A&quot;), x=&quot;cluster&quot;, colour_by=&quot;cluster&quot;) Bibliography "],
["pbmc-3k-10x-dataset-filtered.html", "Chapter 26 PBMC 3k 10X dataset (filtered) 26.1 Introduction 26.2 Analysis code 26.3 Results", " Chapter 26 PBMC 3k 10X dataset (filtered) 26.1 Introduction This performs an analysis of the public PBMC 3k dataset generated by 10X Genomics (Zheng et al. 2017), starting from the filtered count matrix. 26.2 Analysis code 26.2.1 Data loading library(TENxPBMCData) pbmc3k &lt;- TENxPBMCData(&#39;pbmc3k&#39;) 26.2.2 Quality control unfiltered &lt;- pbmc3k is.mito &lt;- grep(&quot;MT&quot;, rowData(pbmc3k)$Symbol_TENx) library(scater) stats &lt;- perCellQCMetrics(pbmc3k, subsets=list(Mito=is.mito)) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) pbmc3k &lt;- pbmc3k[,!high.mito] 26.2.3 Normalization pbmc3k &lt;- logNormCounts(pbmc3k) 26.2.4 Variance modelling library(scran) dec3k &lt;- modelGeneVar(pbmc3k) chosen.hvgs &lt;- which(dec3k$bio &gt; 0) 26.2.5 Dimensionality reduction # Using randomized SVD, which is more efficient for file-backed matrices. set.seed(10000) pbmc3k &lt;- runPCA(pbmc3k, subset_row=chosen.hvgs, ncomponents=25, BSPARAM=BiocSingular::RandomParam()) set.seed(100000) pbmc3k &lt;- runTSNE(pbmc3k, dimred=&quot;PCA&quot;) set.seed(1000000) pbmc3k &lt;- runUMAP(pbmc3k, dimred=&quot;PCA&quot;) 26.2.6 Clustering g &lt;- buildSNNGraph(pbmc3k, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership pbmc3k$cluster &lt;- factor(clust) 26.3 Results 26.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- high.mito gridExtra::grid.arrange( plotColData(unfiltered, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;Mito percent&quot;), ncol=2 ) plotColData(unfiltered, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + scale_x_log10() summary(high.mito) ## Mode FALSE TRUE ## logical 2609 91 26.3.2 Normalization summary(sizeFactors(pbmc3k)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.23 0.75 0.93 1.00 1.16 6.60 26.3.3 Variance modelling plot(dec3k$mean, dec3k$total, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(dec3k) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) 26.3.4 Clustering table(pbmc3k$cluster) ## ## 1 2 3 4 5 6 7 8 9 ## 471 329 510 610 34 152 160 332 11 plotTSNE(pbmc3k, colour_by=&quot;cluster&quot;) Bibliography "],
["pbmc-4k-10x-dataset-filtered.html", "Chapter 27 PBMC 4k 10X dataset (filtered) 27.1 Introduction 27.2 Analysis code 27.3 Results", " Chapter 27 PBMC 4k 10X dataset (filtered) 27.1 Introduction This performs an analysis of the public PBMC 4k dataset generated by 10X Genomics (Zheng et al. 2017), starting from the filtered count matrix. 27.2 Analysis code 27.2.1 Data loading library(TENxPBMCData) pbmc4k &lt;- TENxPBMCData(&#39;pbmc4k&#39;) 27.2.2 Quality control unfiltered &lt;- pbmc4k is.mito &lt;- grep(&quot;MT&quot;, rowData(pbmc4k)$Symbol_TENx) library(scater) stats &lt;- perCellQCMetrics(pbmc4k, subsets=list(Mito=is.mito)) high.mito &lt;- isOutlier(stats$subsets_Mito_percent, nmads=3, type=&quot;higher&quot;) pbmc4k &lt;- pbmc4k[,!high.mito] 27.2.3 Normalization pbmc4k &lt;- logNormCounts(pbmc4k) 27.2.4 Variance modelling library(scran) dec4k &lt;- modelGeneVar(pbmc4k) chosen.hvgs &lt;- which(dec4k$bio &gt; 0) 27.2.5 Dimensionality reduction # Using randomized SVD, which is more efficient for file-backed matrices. set.seed(10000) pbmc4k &lt;- runPCA(pbmc4k, subset_row=chosen.hvgs, ncomponents=25, BSPARAM=BiocSingular::RandomParam()) set.seed(100000) pbmc4k &lt;- runTSNE(pbmc4k, dimred=&quot;PCA&quot;) set.seed(1000000) pbmc4k &lt;- runUMAP(pbmc4k, dimred=&quot;PCA&quot;) 27.2.6 Clustering g &lt;- buildSNNGraph(pbmc4k, k=10, use.dimred = &#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership pbmc4k$cluster &lt;- factor(clust) 27.3 Results 27.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- high.mito gridExtra::grid.arrange( plotColData(unfiltered, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;Mito percent&quot;), ncol=2 ) plotColData(unfiltered, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + scale_x_log10() summary(high.mito) ## Mode FALSE TRUE ## logical 4182 158 27.3.2 Normalization summary(sizeFactors(pbmc4k)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.32 0.71 0.89 1.00 1.13 11.03 27.3.3 Variance modelling plot(dec4k$mean, dec4k$total, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(dec4k) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) 27.3.4 Clustering table(pbmc4k$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 ## 492 796 127 567 226 187 388 49 1036 201 77 36 plotTSNE(pbmc4k, colour_by=&quot;cluster&quot;) Bibliography "],
["chimeric-embryo-10x-dataset.html", "Chapter 28 Chimeric embryo 10X dataset 28.1 Introduction 28.2 Analysis code 28.3 Results", " Chapter 28 Chimeric embryo 10X dataset 28.1 Introduction This performs an analysis of the (???) dataset on mouse gastrulation. Here, we examine chimeric embryos at the E7.5 stage of development where td-Tomato-positive embryonic stem cells (ESCs) were injected into a wild-type blastocyst. 28.2 Analysis code 28.2.1 Data loading library(MouseGastrulationData) sce.chimera &lt;- WTChimeraData(samples=5:10) sce.chimera ## class: SingleCellExperiment ## dim: 29453 20935 ## metadata(0): ## assays(1): counts ## rownames(29453): ENSMUSG00000051951 ENSMUSG00000089699 ... ## ENSMUSG00000095742 tomato-td ## rowData names(2): ENSEMBL SYMBOL ## colnames(20935): cell_9769 cell_9770 ... cell_30702 cell_30703 ## colData names(10): cell barcode ... closest.cell doub.density ## reducedDimNames(2): pca.corrected.E7.5 pca.corrected.E8.5 ## spikeNames(0): ## altExpNames(0): 28.2.2 Feature annotation library(scater) rownames(sce.chimera) &lt;- uniquifyFeatureNames( rowData(sce.chimera)$ENSEMBL, rowData(sce.chimera)$SYMBOL) 28.2.3 Quality control Quality control on the cells has already been performed by the authors, so we will not repeat it here. We additionally remove cells that are labelled as stripped nuclei or doublets. drop &lt;- sce.chimera$celltype.mapped %in% c(&quot;stripped&quot;, &quot;Doublet&quot;) sce.chimera &lt;- sce.chimera[,!drop] 28.2.4 Normalization We use the pre-computed size factors in sce.chimera. sce.chimera &lt;- logNormCounts(sce.chimera) 28.2.5 Variance modelling Retaining all genes with any positive biological component, to preserve as much signal as possible across many samples. library(scran) dec.chimera &lt;- modelGeneVar(sce.chimera, block=sce.chimera$sample) chosen.hvgs &lt;- dec.chimera$bio &gt; 0 28.2.6 Merging We use a hierarchical merge to first merge together replicates with the same genotype, and then merge samples across different genotypes. library(batchelor) merged &lt;- correctExperiments(sce.chimera, batch=sce.chimera$sample, subset.row=chosen.hvgs, PARAM=FastMnnParam( merge.order=list( list( list(1, 3), # WT (3 replicates) 5 ), list( list(2, 4), # td-Tomato (3 replicates) 6 ) ) ) ) 28.2.7 Clustering g &lt;- buildSNNGraph(merged, use.dimred=&quot;corrected&quot;) clusters &lt;- igraph::cluster_louvain(g) merged$cluster &lt;- factor(clusters$membership) 28.2.8 Dimensionality reduction We use an external algorithm to compute nearest neighbors for greater speed. merged &lt;- runTSNE(merged, dimred=&quot;corrected&quot;, external_neighbors=TRUE) merged &lt;- runUMAP(merged, dimred=&quot;corrected&quot;, external_neighbors=TRUE) 28.3 Results 28.3.1 Variance modelling par(mfrow=c(1,2)) blocked.stats &lt;- dec.chimera$per.block for (i in colnames(blocked.stats)) { current &lt;- blocked.stats[[i]] plot(current$mean, current$total, main=i, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(current) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) } 28.3.2 Batch correction metadata(merged)$merge.info$lost.var ## 5 6 7 8 9 10 ## [1,] 0.00e+00 0.020443 0.00e+00 0.016957 0.00000 0.00000 ## [2,] 0.00e+00 0.000739 0.00e+00 0.000441 0.00000 0.01547 ## [3,] 3.09e-02 0.000000 2.01e-02 0.000000 0.00000 0.00000 ## [4,] 9.01e-05 0.000000 8.26e-05 0.000000 0.01805 0.00000 ## [5,] 4.32e-03 0.007253 4.12e-03 0.007830 0.00383 0.00779 28.3.3 Clustering table(merged$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## 947 476 112 867 681 507 2181 424 1269 104 727 1034 58 423 872 ## 16 17 18 19 20 21 22 23 24 25 ## 1039 414 1264 698 211 160 156 1942 567 2293 plotTSNE(merged, colour_by=&quot;cluster&quot;) plotUMAP(merged, colour_by=&quot;cluster&quot;) "],
["mammary-gland-dataset.html", "Chapter 29 Mammary gland dataset 29.1 Introduction 29.2 Analysis code 29.3 Results", " Chapter 29 Mammary gland dataset 29.1 Introduction This performs an analysis of the Bach et al. (2017) 10X Genomics dataset, from which we will consider a single sample of epithelial cells from the mouse mammary gland during gestation. 29.2 Analysis code 29.2.1 Data loading library(scRNAseq) sce.mam &lt;- BachMammaryData(samples=&quot;G_1&quot;) 29.2.2 Gene annotation library(scater) rownames(sce.mam) &lt;- uniquifyFeatureNames( rowData(sce.mam)$Ensembl, rowData(sce.mam)$Symbol) library(AnnotationHub) ens.mm.v97 &lt;- AnnotationHub()[[&quot;AH73905&quot;]] rowData(sce.mam)$SEQNAME &lt;- mapIds(ens.mm.v97, keys=rowData(sce.mam)$Ensembl, keytype=&quot;GENEID&quot;, column=&quot;SEQNAME&quot;) 29.2.3 Quality control unfiltered &lt;- sce.mam is.mito &lt;- rowData(sce.mam)$SEQNAME == &quot;MT&quot; stats &lt;- perCellQCMetrics(sce.mam, subsets=list(Mito=which(is.mito))) qc &lt;- quickCellQC(stats, percent_subsets=&quot;subsets_Mito_percent&quot;, nmads=3) sce.mam &lt;- sce.mam[,!qc$discard] 29.2.4 Normalization library(scran) set.seed(101000110) clusters &lt;- quickCluster(sce.mam) sce.mam &lt;- computeSumFactors(sce.mam, clusters=clusters, min.mean=0.1) sce.mam &lt;- logNormCounts(sce.mam) 29.2.5 Variance modelling We use a Poisson-based technical trend to capture more genuine biological variation in the biological component. set.seed(00010101) dec.mam &lt;- modelGeneVarByPoisson(sce.mam) 29.2.6 Dimensionality reduction library(BiocSingular) set.seed(101010011) sce.mam &lt;- denoisePCA(sce.mam, technical=dec.mam, BSPARAM=IrlbaParam()) sce.mam &lt;- runTSNE(sce.mam, dimred=&quot;PCA&quot;) 29.2.7 Clustering We use a higher k to obtain coarser clusters (for use in doubletCluster() later). snn.gr &lt;- buildSNNGraph(sce.mam, use.dimred=&quot;PCA&quot;, k=25) sce.mam$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) 29.2.8 Marker detection markers.mam &lt;- findMarkers(sce.mam, cluster=sce.mam$cluster, direction=&quot;up&quot;, lfc=1) 29.3 Results 29.3.1 Quality control statistics colData(unfiltered) &lt;- cbind(colData(unfiltered), stats) unfiltered$discard &lt;- qc$discard gridExtra::grid.arrange( plotColData(unfiltered, y=&quot;sum&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(unfiltered, y=&quot;detected&quot;, colour_by=&quot;discard&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(unfiltered, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + ggtitle(&quot;Mito percent&quot;), ncol=2 ) plotColData(unfiltered, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) + scale_x_log10() colSums(as.matrix(qc)) ## low_lib_size low_n_features ## 0 0 ## high_subsets_Mito_percent discard ## 143 143 29.3.2 Normalization summary(sizeFactors(sce.mam)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.27 0.52 0.76 1.00 1.21 10.74 plot(librarySizeFactors(sce.mam), sizeFactors(sce.mam), pch=16, xlab=&quot;Library size factors&quot;, ylab=&quot;Deconvolution factors&quot;, log=&quot;xy&quot;) 29.3.3 Variance modelling plot(dec.mam$mean, dec.mam$total, pch=16, cex=0.5, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curfit &lt;- metadata(dec.mam) curve(curfit$trend(x), col=&#39;dodgerblue&#39;, add=TRUE, lwd=2) 29.3.4 Dimensionality reduction ncol(reducedDim(sce.mam, &quot;PCA&quot;)) ## [1] 11 29.3.5 Clustering table(sce.mam$cluster) ## ## 1 2 3 4 5 6 7 8 9 10 11 ## 706 489 761 512 24 25 33 52 39 71 60 plotTSNE(sce.mam, colour_by=&quot;cluster&quot;) Bibliography "],
["human-cell-atlas-quickstart.html", "Chapter 30 Human Cell Atlas Quickstart 30.1 Introduction 30.2 Code 30.3 Visualizations", " Chapter 30 Human Cell Atlas Quickstart 30.1 Introduction To make it as easy as possible to get started, here we simply provide a script that walks through a typical, basic scRNA-seq analysis in code, with prose as comments (#), and all visualization held until the end of the script. Here, we use an example dataset from the Human Cell Atlas immune cell profiling project on bone marrow. This dataset is loaded via the HCAData package, which provides a ready to use SingleCellExperiment object. Note that the HCAData bone marrow dataset is comprised of 8 donors, so we have added an integration step to ameliorate batch effects caused by different donors. However, for use cases where integration is not necessary (e.g. no expected batch effects), we note in the code what to skip and relevant arguments to replace. Lastly, note that some arguments are added for the sake of reducing computational runtime and can be modified or removed. These include parallelization via BPPARAM, and different algorithms for SVD and nearest-neighbor via BSPARAM and BNPARAM. See the “Adaptations for Large-scale Data” chapter for more information on these arguments. 30.2 Code ## Setup --------------------------------------------------- ## not run - uncomment these lines to install necessary pkgs ## install.packages(&#39;BiocManager&#39;) ## BiocManager::install(version = &#39;devel&#39;) # devel=3.10 ## BiocManager::install(c( ## &#39;HCAData&#39;, # dataset ## &#39;scater&#39;, &#39;scran&#39;, &#39;batchelor&#39;, # processing + DE + batch correction ## &#39;igraph&#39;, # clustering ## &#39;slingshot&#39;, # Trajectory ## &#39;iSEE&#39; # interactive viz ## )) ## Import data into R -------------------------------------- ## For reading in data directly from CellRanger output ## use the lines below and replace with proper paths to data ## append any cell metadata as needed to colData() ## library(DropletUtils) ## sce &lt;- read10xCounts(&#39;/path/to/cellranger/outs/&#39;) ## For this quick-start: Human Cell Atlas (HCA) data library(HCAData) sce &lt;- HCAData(&#39;ica_bone_marrow&#39;) ## subsample for better brevity of compilation set.seed(1234) sce &lt;- sce[, sample(ncol(sce), 10000)] ## Split out donor based on barcode Donor &lt;- lapply(sce$Barcode, strsplit, &#39;_&#39;) Donor &lt;- unlist(lapply(Donor, function(x) { x[[1]][1] })) sce$Donor &lt;- Donor ## Convert DelayedArray to regular matrix counts(sce) &lt;- as.matrix(counts(sce)) ## Quality Control ----------------------------------------- library(scater) sce &lt;- calculateQCMetrics(sce, BPPARAM = BiocParallel::MulticoreParam()) ## remove &quot;bad&quot; cells by total counts/features per cell filt &lt;- sce$total_counts &gt; 500 &amp; sce$total_features_by_counts &gt; 100 sce &lt;- sce[, filt] ## to ease computation, remove low frequency genes from `sce` num_reads &lt;- 1 # minimum 1 read num_cells &lt;- 0.025 * ncol(sce) # in at least 2.5% of all cells keep &lt;- rowSums(counts(sce) &gt;= num_reads) &gt;= num_cells sce &lt;- sce[keep, ] ## for readability, use Symbols in lieu of IDs as rownames uniq_feats &lt;- uniquifyFeatureNames(ID = rowData(sce)$ID, names = rowData(sce)$Symbol) rownames(sce) &lt;- uniq_feats ## Normalization ------------------------------------------- sce &lt;- normalize(sce) ## Feature Selection --------------------------------------- library(scran) fit &lt;- trendVar(sce, use.spikes = FALSE) dec &lt;- decomposeVar(sce, fit) hvg &lt;- rownames(dec)[dec$bio &gt; 0] # save gene names ## Integration --------------------------------------------- ## only perform this section if there is a batch effect library(batchelor) set.seed(1234) mnn &lt;- fastMNN(sce, batch = sce$Donor, subset.row = hvg, BSPARAM = BiocSingular::IrlbaParam(deferred = TRUE), BNPARAM = BiocNeighbors::AnnoyParam(), BPPARAM = BiocParallel::MulticoreParam()) reducedDim(sce, &#39;MNN&#39;) &lt;- reducedDim(mnn, &#39;corrected&#39;) ## Dimensionality Reduction -------------------------------- ## note on `use_dimred` arg: specifies which precomputed ## dimension reduction to use in `sce`; if there is none, ## it will first calculate and save PCA to `sce` then UMAP set.seed(1234) sce &lt;- runUMAP(sce, use_dimred = &#39;MNN&#39;, # omit if `fastMNN()` not run BNPARAM = BiocNeighbors::AnnoyParam(), BPPARAM = BiocParallel::MulticoreParam(), ## unnecessary options, only used to make a pretty graph min_dist = 0.5, repulsion_strength = 0.25, spread = 0.7, n_neighbors = 15) ## Clustering ---------------------------------------------- library(igraph) ## replace `use.dimred` with &#39;PCA&#39; if no integration was performed ## this will be automatically added via `runUMAP` above set.seed(1234) g &lt;- buildSNNGraph(sce, use.dimred = &#39;MNN&#39;, k = 30, # higher = bigger clusters BNPARAM = BiocNeighbors::AnnoyParam(), BPPARAM = BiocParallel::MulticoreParam()) clusters &lt;- as.factor(igraph::cluster_louvain(g)$membership) sce$clusters &lt;- clusters ## Differential Expression --------------------------------- ## pval.type = &#39;all&#39; : only get globally unique markers markers &lt;- findMarkers(sce, clusters = sce$clusters, block = sce$Donor, # use to get within-donor DE direction = &#39;up&#39;, lfc = 1.5, pval.type = &quot;all&quot;, # get cluster-unique markers subset.row = hvg, BPPARAM = BiocParallel::MulticoreParam()) ## pval.type = &#39;any&#39; : get all potential markers of any direction/comparison markers_any &lt;- findMarkers(sce, clusters = sce$clusters, block = sce$Donor, # use to get within-donor DE direction = &#39;any&#39;, lfc = 0, pval.type = &quot;any&quot;, # get all potential markers subset.row = hvg, BPPARAM = BiocParallel::MulticoreParam()) ## Annotation ---------------------------------------------- ## Get mappings of ENTREZID to Symbol library(org.Hs.eg.db) keys_entrez &lt;- keys(org.Hs.eg.db, &#39;ENTREZID&#39;) mapping_es &lt;- AnnotationDbi::select(org.Hs.eg.db, keys = keys_entrez, columns = c(&#39;ENTREZID&#39;, &#39;SYMBOL&#39;), keytype = &#39;ENTREZID&#39;) mapping_es$ENTREZID &lt;- as.integer(mapping_es$ENTREZID) ## Get pathways of interest - convert to list with symbol ## devtools::install_github(&#39;stephenturner/msigdf&#39;) library(msigdf) library(dplyr) mdb &lt;- dplyr::inner_join(msigdf.human, mapping_es, by = c(&#39;entrez&#39; = &#39;ENTREZID&#39;)) %&gt;% dplyr::filter(collection == &#39;c7&#39;) %&gt;% dplyr::select(-collection, -entrez) %&gt;% dplyr::group_nest(geneset) pathways &lt;- purrr::map(mdb$data, function(x) { as.character(x$SYMBOL) }) names(pathways) &lt;- mdb$geneset ## Get stats based on markers search - compare clusters 3 vs 2 stats &lt;- markers_any[[3]]$logFC.2 names(stats) &lt;- rownames(markers_any[[3]]) ## Run fast gene set enrichment analysis (see plot at bottom) library(fgsea) fgseaRes &lt;- fgsea(pathways = pathways, stats = stats, minSize = 15, maxSize = 500, nperm = 10000) ## Trajectory Analysis ------------------------------------- library(slingshot) slc &lt;- slingshot(sce[, sce$clusters %in% c(3, 5, 9)], clusterLabels = &#39;clusters&#39;, reducedDim = &#39;UMAP&#39;) ## Interactive Exploration --------------------------------- ## library(iSEE) ## iSEE(sce) ## not run; opens a web browser GUI 30.3 Visualizations ## Trajectory analysis ------------------------------------- ## Slingshot trajectory plot library(RColorBrewer) colors &lt;- colorRampPalette(brewer.pal(11, &#39;Spectral&#39;)[-6])(100) plotcol &lt;- colors[cut(slc$slingPseudotime_1, breaks = 100)] plot(reducedDims(slc)$UMAP, col = plotcol, pch=16, asp = 1) lines(SlingshotDataSet(slc), lwd = 2, col = &#39;black&#39;) ## UMAP based plots ---------------------------------------- ## UMAP (no colours) plotUMAP(sce) ## Pre vs post batch correction tmp &lt;- runPCA(sce, BSPARAM = BiocSingular::IrlbaParam(), BPPARAM = BiocParallel::MulticoreParam()) tmp &lt;- runUMAP(tmp, BNPARAM = BiocNeighbors::AnnoyParam(), BPPARAM = BiocParallel::MulticoreParam(), ## unnecessary options, only used to make a pretty graph min_dist = 0.5, repulsion_strength = 0.25, spread = 0.7, n_neighbors = 15) p0 &lt;- plotUMAP(tmp, colour_by = &#39;Donor&#39;) p1 &lt;- plotUMAP(sce, colour_by = &#39;Donor&#39;) patchwork::wrap_plots(p0, p1, nrow = 2) ## Gene expression on UMAP plots p2 &lt;- plotUMAP(sce, colour_by = &#39;CD3E&#39;) p3 &lt;- plotUMAP(sce, colour_by = &#39;CD79A&#39;) p4 &lt;- plotUMAP(sce, colour_by = &#39;LYZ&#39;) p5 &lt;- plotUMAP(sce, colour_by = &#39;NKG7&#39;) patchwork::wrap_plots(p2, p3, p4, p5, nrow = 2) ## Clusters on UMAP plotUMAP(sce, colour_by = &#39;clusters&#39;, text_by = &#39;clusters&#39;) ## Gene expression plots ----------------------------------- ## Heatmap: Top global markers per cluster top_markers &lt;- lapply(markers, function(x) { rownames(x)[1:20] }) top_markers &lt;- sort(unique(unlist(top_markers))) top_markers &lt;- top_markers[!grepl(&#39;MT-|^RP&#39;, top_markers)] set.seed(1234) plotHeatmap(sce[, sample(ncol(sce), 5000)], features = top_markers, color = viridis::viridis(101, option = &#39;A&#39;), ## symmetric = TRUE, zlim = c(-5, 5), colour_columns_by = &#39;clusters&#39;, clustering_method = &#39;ward.D2&#39;, show_colnames = FALSE, fontsize_row = 6 ) ## Volcano plot marker_tbl_3 &lt;- as.data.frame(markers_any[[3]]) marker_tbl_3 %&gt;% ggplot(aes(x = logFC.2, y = -log10(FDR))) + geom_point() + geom_vline(xintercept = c(-log(1.5), log(1.5)), linetype = &#39;dashed&#39;) + theme_classic() + coord_cartesian(xlim = c(-2, 2), expand = FALSE) ## Gene set enrichment ------------------------------------- ## Plot multiple pathways enrichment plots topPathwaysUp &lt;- fgseaRes[ES &gt; 0][head(order(pval), n=10), pathway] topPathwaysDown &lt;- fgseaRes[ES &lt; 0][head(order(pval), n=10), pathway] topPathways &lt;- c(topPathwaysUp, rev(topPathwaysDown)) plotGseaTable(pathways[topPathways], stats, fgseaRes, gseaParam = 0.5) ## Traditional GSEA plot plotEnrichment(pathways[[&quot;GSE29618_MONOCYTE_VS_PDC_UP&quot;]], stats) "],
["contributors.html", "Chapter 31 Contributors", " Chapter 31 Contributors Aaron Lun, PhD When one thinks of single-cell bioinformatics, one thinks of several titans who bestride the field. Unfortunately, they weren’t available, so we had to make do with Aaron instead. He likes long walks on the beach (as long as there’s Wifi) and travelling (but only in business class). His friends say that he is “absolutely insane” and “needs to get a life”, or they would if they weren’t mostly imaginary. His GitHub account is his Facebook and his Slack is his Twitter. He maintains more Bioconductor packages than he has phone numbers on his cell. He has a recurring event on his Google Calender to fold his laundry. He is - the most boring man in the world. (“I don’t often cry when I watch anime, but when I do, my tears taste like Dos Equis.”) He currently works as a Scientist at Genentech after a stint as a research associate in John Marioni’s group at the CRUK Cambridge Institute, which was preceded by a PhD with Gordon Smyth at the Walter and Eliza Hall Institute for Medical Research. Robert Amezquita, PhD Robert Amezquita is a Postdoctoral Fellow in the Immunotherapy Integrated Research Center (IIRC) at Fred Hutch under the mentorship of Raphael Gottardo. His current research focuses on utilizing computational approaches leveraging transcriptional and epigenomic profiling at single-cell resolution to understand how novel anti-cancer therapeutics - ranging from small molecule therapies to biologics such as CAR-T cells - affect immune response dynamics. Extending from his graduate work at Yale’s Dept. of Immunobiology, Robert’s research aims to better understand the process of immune cell differentiation under the duress of cancer as a means to inform future immunotherapies. To accomplish this, Robert works collaboratively across the Fred Hutch IIRC with experimental collaborators, extensively utilizing R and Bioconductor for data analysis. Stephanie Hicks, PhD Stephanie Hicks is an Assistant Professor in the Department of Biostatistics at Johns Hopkins Bloomberg School of Public Health. Her research interests focus around developing statistical methods, tools and software for the analysis of genomics data. Specifically, her research addresses statistical challenges in epigenomics, functional genomics and single-cell genomics such as the pre-processing, normalization, analysis of noisy high-throughput data leading to an improved quantification and understanding of biological variability. She actively contributes software packages to Bioconductor and is involved in teaching courses for data science and the analysis of genomics data. She is also a faculty member of the Johns Hopkins Data Science Lab, co-host of The Corresponding Author podcast and co-founder of R-Ladies Baltimore. For more information, please see http://www.stephaniehicks.com Raphael Gottardo, PhD Raphael Gottardo is the Scientific Director of the Translational Data Science Integrated Research Center (TDS IRC) at Fred Hutch, J. Ordin Edson Foundation Endowed Chair, and Full Member within the Vaccine and Infectious Disease and Public Health Sciences Division. A pioneer in developing and applying statistical methods and software tools to distill actionable insights from large and complex biological data sets.In partnership with scientists and clinicians, he works to understand such diseases as cancer, HIV, malaria, and tuberculosis and inform the development of vaccines and treatments. He is a leader in forming interdisciplinary collaborations across the Hutch, as well as nationally and internationally, to address important research questions, particularly in the areas of vaccine research, human immunology, and immunotherapy. As director of the Translational Data Science Integrated Research Center, he fosters interaction between the Hutch’s experimental and clinical researchers and their computational and quantitative science colleagues with the goal of transforming patient care through data-driven research. Dr. Gottardo partners closely with the cancer immunotherapy program at Fred Hutch to improve treatments. For example, his team is harnessing cutting-edge computational methods to determine how cancers evade immunotherapy. He has made significant contributions to vaccine research and is the principal investigator of the Vaccine and Immunology Statistical Center of the Collaboration for AIDS Vaccine Discovery. "],
["bibliography.html", "Chapter 32 Bibliography", " Chapter 32 Bibliography "]
]
